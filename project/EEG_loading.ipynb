{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9trg6idGKRl"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "runningOnColab = 'google.colab' in sys.modules\n",
        "if runningOnColab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    os.chdir(\"/content/drive/MyDrive/2022-23 Year/Winter 2023/ECE C147/Final Project\")\n",
        "    %ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLVSJxtXJn9r",
        "outputId": "4bc8e16b-8c62-47e9-c66a-a910c79aae60"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "EEG_loading.html       person_test.npy         X_train_valid.npy\n",
            "EEG_loading.ipynb      person_train_valid.npy  y_test.npy\n",
            "EEG_loading_old.ipynb  X_test.npy              y_train_valid.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "xMisdpDcGKRp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf                                \n",
        "from tensorflow import keras             \n",
        "import numpy as np                       \n",
        "from sklearn.model_selection import train_test_split   \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten,Dropout\n",
        "from keras.layers import Conv2D,BatchNormalization,MaxPooling2D,Reshape, LSTM, ConvLSTM2D, Permute, TimeDistributed\n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Dense, Reshape, Conv2DTranspose, LeakyReLU, BatchNormalization, Input, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGa7AcyoGKR3"
      },
      "source": [
        "# Default Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMDSSA3fGKR3"
      },
      "source": [
        "## 1. Optimize the classification accuracy for subject 1. Does it help to train across all subjects?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bD3to0v6GKR3"
      },
      "source": [
        "#### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0CabJRqokrSB"
      },
      "outputs": [],
      "source": [
        "def data_prep(X,y,sub_sample,average,noise):\n",
        "    \n",
        "    total_X = None\n",
        "    total_y = None\n",
        "    \n",
        "    # Trimming the data (sample,22,1000) -> (sample,22,500)\n",
        "    X = X[:,:,0:500]\n",
        "    # print('Shape of X after trimming:',X.shape)\n",
        "    \n",
        "    # Maxpooling the data (sample,22,1000) -> (sample,22,500/sub_sample)\n",
        "    X_max = np.max(X.reshape(X.shape[0], X.shape[1], -1, sub_sample), axis=3)\n",
        "    \n",
        "    \n",
        "    total_X = X_max\n",
        "    total_y = y\n",
        "    # print('Shape of X after maxpooling:',total_X.shape)\n",
        "    \n",
        "    # Averaging + noise \n",
        "    X_average = np.mean(X.reshape(X.shape[0], X.shape[1], -1, average),axis=3)\n",
        "    X_average = X_average + np.random.normal(0.0, 0.5, X_average.shape)\n",
        "    \n",
        "    total_X = np.vstack((total_X, X_average))\n",
        "    total_y = np.hstack((total_y, y))\n",
        "    # print('Shape of X after averaging+noise and concatenating:',total_X.shape)\n",
        "    \n",
        "    # Subsampling\n",
        "    \n",
        "    for i in range(sub_sample):\n",
        "        \n",
        "        X_subsample = X[:, :, i::sub_sample] + \\\n",
        "                            (np.random.normal(0.0, 0.5, X[:, :,i::sub_sample].shape) if noise else 0.0)\n",
        "            \n",
        "        total_X = np.vstack((total_X, X_subsample))\n",
        "        total_y = np.hstack((total_y, y))\n",
        "        \n",
        "    \n",
        "    # print('Shape of X after subsampling and concatenating:',total_X.shape)\n",
        "    return total_X,total_y\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "f69cLbtZGKR4",
        "outputId": "870245cb-ae62-4aa7-a8a1-ec857525c3d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test Shape for Subject 0: (50, 22, 1000)\n",
            "y_test Shape for Subject 0: (50,)\n",
            "X_train_valid Shape for Subject 0: (237, 22, 1000)\n",
            "y_train_valid Shape for Subject 0: (237,)\n"
          ]
        }
      ],
      "source": [
        "X_test = np.load(\"X_test.npy\")\n",
        "y_test = np.load(\"y_test.npy\")\n",
        "person_train_valid = np.load(\"person_train_valid.npy\")\n",
        "X_train_valid = np.load(\"X_train_valid.npy\")\n",
        "y_train_valid = np.load(\"y_train_valid.npy\")\n",
        "person_test = np.load(\"person_test.npy\")\n",
        "\n",
        "## Adjusting the labels so that \n",
        "\n",
        "# Cue onset left - 0\n",
        "# Cue onset right - 1\n",
        "# Cue onset foot - 2\n",
        "# Cue onset tongue - 3\n",
        "\n",
        "y_train_valid -= 769\n",
        "y_test -= 769\n",
        "\n",
        "subject = 0\n",
        "subject_test_idx = np.where(person_test==subject)[0]\n",
        "subject_valid_idx = np.where(person_train_valid==subject)[0]\n",
        "\n",
        "\n",
        "subject_X_test = X_test[subject_test_idx]\n",
        "suject_y_test = y_test[subject_test_idx]\n",
        "suject_X_train_valid = X_train_valid[subject_valid_idx]\n",
        "suject_y_train_valid = y_train_valid[subject_valid_idx]\n",
        "\n",
        "print(f'X_test Shape for Subject {subject}: {subject_X_test.shape}')\n",
        "print(f'y_test Shape for Subject {subject}: {suject_y_test.shape}')\n",
        "print(f'X_train_valid Shape for Subject {subject}: {suject_X_train_valid.shape}')\n",
        "print(f'y_train_valid Shape for Subject {subject}: {suject_y_train_valid.shape}')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iP8GfInMGKR4",
        "outputId": "332ece7f-ea2f-4242-db99-19db0c77064c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training set: (760, 22, 250)\n",
            "Shape of validation set: (188, 22, 250)\n",
            "Shape of training labels: (760,)\n",
            "Shape of validation labels: (188,)\n",
            "Shape of testing set: (200, 22, 250)\n",
            "Shape of testing labels: (200,)\n",
            "Shape of training labels after categorical conversion: (760, 4)\n",
            "Shape of validation labels after categorical conversion: (188, 4)\n",
            "Shape of test labels after categorical conversion: (200, 4)\n",
            "Shape of training set after adding width info: (760, 22, 250, 1)\n",
            "Shape of validation set after adding width info: (188, 22, 250, 1)\n",
            "Shape of test set after adding width info: (200, 22, 250, 1)\n",
            "Shape of training set after dimension reshaping: (760, 250, 1, 22)\n",
            "Shape of validation set after dimension reshaping: (188, 250, 1, 22)\n",
            "Shape of test set after dimension reshaping: (200, 250, 1, 22)\n"
          ]
        }
      ],
      "source": [
        "# shuffle with 5 fold\n",
        "indicies_valid = np.random.choice(suject_X_train_valid.shape[0], suject_X_train_valid.shape[0] // 5, replace=False)\n",
        "indicies_train = np.array(list(set(range(suject_X_train_valid.shape[0])).difference(set(indicies_valid))))\n",
        "\n",
        "# Creating the training and validation sets using the generated indices\n",
        "X_train, X_valid = suject_X_train_valid[indicies_train], suject_X_train_valid[indicies_valid] \n",
        "y_train, y_valid = suject_y_train_valid[indicies_train], suject_y_train_valid[indicies_valid]\n",
        "\n",
        "\n",
        "# Preprocessing the dataset\n",
        "x_train,y_train = data_prep(X_train,y_train,2,2,True)\n",
        "x_valid,y_valid = data_prep(X_valid,y_valid,2,2,True)\n",
        "X_test_prep,y_test_prep = data_prep(subject_X_test,suject_y_test,2,2,True)\n",
        "\n",
        "\n",
        "\n",
        "print('Shape of training set:',x_train.shape)\n",
        "print('Shape of validation set:',x_valid.shape)\n",
        "print('Shape of training labels:',y_train.shape)\n",
        "print('Shape of validation labels:',y_valid.shape)\n",
        "print('Shape of testing set:',X_test_prep.shape)\n",
        "print('Shape of testing labels:',y_test_prep.shape)\n",
        "\n",
        "\n",
        "# Converting the labels to categorical variables for multiclass classification\n",
        "y_train = to_categorical(y_train, 4)\n",
        "y_valid = to_categorical(y_valid, 4)\n",
        "y_test = to_categorical(y_test_prep, 4)\n",
        "print('Shape of training labels after categorical conversion:',y_train.shape)\n",
        "print('Shape of validation labels after categorical conversion:',y_valid.shape)\n",
        "print('Shape of test labels after categorical conversion:',y_test.shape)\n",
        "\n",
        "# Adding width of the segment to be 1\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
        "x_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n",
        "print('Shape of training set after adding width info:',x_train.shape)\n",
        "print('Shape of validation set after adding width info:',x_valid.shape)\n",
        "print('Shape of test set after adding width info:',x_test.shape)\n",
        "\n",
        "\n",
        "# Reshaping the training and validation dataset\n",
        "x_train = np.swapaxes(x_train, 1,3)\n",
        "x_train = np.swapaxes(x_train, 1,2)\n",
        "x_valid = np.swapaxes(x_valid, 1,3)\n",
        "x_valid = np.swapaxes(x_valid, 1,2)\n",
        "x_test = np.swapaxes(x_test, 1,3)\n",
        "x_test = np.swapaxes(x_test, 1,2)\n",
        "print('Shape of training set after dimension reshaping:',x_train.shape)\n",
        "print('Shape of validation set after dimension reshaping:',x_valid.shape)\n",
        "print('Shape of test set after dimension reshaping:',x_test.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYd42N1tGKR4"
      },
      "source": [
        "#### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Z2FGJl9hGKR4",
        "outputId": "2ad7d5cc-f4b4-4321-92db-0efbf7061488",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 250, 1, 10)        1110      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 84, 1, 10)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 84, 1, 10)        40        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 84, 1, 10)         0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 84, 1, 10)         1510      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 28, 1, 10)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 28, 1, 10)        40        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 28, 1, 10)         0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 280)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 4)                 1124      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,824\n",
            "Trainable params: 3,784\n",
            "Non-trainable params: 40\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Building the CNN model using sequential class\n",
        "cnn_subject_model = Sequential()\n",
        "\n",
        "# Conv. block 1\n",
        "cnn_subject_model.add(Conv2D(filters=10, kernel_size=(5,1), padding='same', activation='elu', input_shape=(250,1,22)))\n",
        "cnn_subject_model.add(MaxPooling2D(pool_size=(3,1), padding='same')) \n",
        "cnn_subject_model.add(BatchNormalization())\n",
        "cnn_subject_model.add(Dropout(0.5))\n",
        "\n",
        "# Conv. block 2\n",
        "cnn_subject_model.add(Conv2D(filters=10, kernel_size=(15,1), padding='same', activation='elu'))\n",
        "cnn_subject_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
        "cnn_subject_model.add(BatchNormalization())\n",
        "cnn_subject_model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer with Softmax activation\n",
        "cnn_subject_model.add(Flatten()) # Flattens the input\n",
        "cnn_subject_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
        "\n",
        "\n",
        "# Printing the model summary\n",
        "cnn_subject_model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioTUpE9GGKR5"
      },
      "source": [
        "#### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "px5d_FleGKR5"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "epochs = 100\n",
        "cnn_subject_model_optimizer = keras.optimizers.Adam(learning_rate=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u95L4saOGKR5"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Rft3Ig-mGKR5",
        "outputId": "8fac1bd2-bc27-45db-e729-7c74ecdd0d43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "12/12 [==============================] - 2s 95ms/step - loss: 2.3069 - accuracy: 0.2895 - val_loss: 3.8317 - val_accuracy: 0.2766\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 2.0846 - accuracy: 0.3013 - val_loss: 2.6311 - val_accuracy: 0.3032\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 1.8197 - accuracy: 0.3513 - val_loss: 2.1702 - val_accuracy: 0.3404\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 1.6823 - accuracy: 0.3658 - val_loss: 1.9053 - val_accuracy: 0.3617\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1.5617 - accuracy: 0.4197 - val_loss: 1.8077 - val_accuracy: 0.3511\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 1.4581 - accuracy: 0.4250 - val_loss: 1.6759 - val_accuracy: 0.3457\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1.3595 - accuracy: 0.4658 - val_loss: 1.4916 - val_accuracy: 0.3670\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1.3660 - accuracy: 0.4382 - val_loss: 1.4310 - val_accuracy: 0.3883\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1.2812 - accuracy: 0.4921 - val_loss: 1.3779 - val_accuracy: 0.4255\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1.1968 - accuracy: 0.5039 - val_loss: 1.2293 - val_accuracy: 0.4681\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1.1873 - accuracy: 0.4921 - val_loss: 1.2500 - val_accuracy: 0.4574\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1.1167 - accuracy: 0.5487 - val_loss: 1.2408 - val_accuracy: 0.4468\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1.0594 - accuracy: 0.5684 - val_loss: 1.1991 - val_accuracy: 0.4894\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1.0167 - accuracy: 0.5605 - val_loss: 1.1750 - val_accuracy: 0.5000\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.9928 - accuracy: 0.6039 - val_loss: 1.1618 - val_accuracy: 0.5266\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.9769 - accuracy: 0.5934 - val_loss: 1.1306 - val_accuracy: 0.5160\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.9369 - accuracy: 0.6171 - val_loss: 1.1341 - val_accuracy: 0.5372\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.9010 - accuracy: 0.6408 - val_loss: 1.1678 - val_accuracy: 0.5426\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.8366 - accuracy: 0.6592 - val_loss: 1.1518 - val_accuracy: 0.5479\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.8631 - accuracy: 0.6618 - val_loss: 1.1550 - val_accuracy: 0.5319\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.8069 - accuracy: 0.6789 - val_loss: 1.1866 - val_accuracy: 0.5160\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.7624 - accuracy: 0.6789 - val_loss: 1.1611 - val_accuracy: 0.5691\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.7693 - accuracy: 0.6763 - val_loss: 1.0860 - val_accuracy: 0.6064\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.7409 - accuracy: 0.7026 - val_loss: 1.1289 - val_accuracy: 0.6011\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.7118 - accuracy: 0.7145 - val_loss: 1.1078 - val_accuracy: 0.5904\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.6519 - accuracy: 0.7539 - val_loss: 1.0626 - val_accuracy: 0.6223\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.6252 - accuracy: 0.7526 - val_loss: 1.1193 - val_accuracy: 0.5904\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.6412 - accuracy: 0.7474 - val_loss: 1.1092 - val_accuracy: 0.5745\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 0.5793 - accuracy: 0.7632 - val_loss: 1.1269 - val_accuracy: 0.6011\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 0.5867 - accuracy: 0.7684 - val_loss: 1.0753 - val_accuracy: 0.5851\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 0.5372 - accuracy: 0.7987 - val_loss: 1.0432 - val_accuracy: 0.6277\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 0.5691 - accuracy: 0.7829 - val_loss: 1.0778 - val_accuracy: 0.6011\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 0.5548 - accuracy: 0.7855 - val_loss: 1.0256 - val_accuracy: 0.6436\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.5225 - accuracy: 0.7947 - val_loss: 0.9979 - val_accuracy: 0.6383\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 0.5499 - accuracy: 0.7947 - val_loss: 1.0212 - val_accuracy: 0.6489\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 0.5449 - accuracy: 0.7921 - val_loss: 0.9773 - val_accuracy: 0.6383\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.4864 - accuracy: 0.8237 - val_loss: 1.0024 - val_accuracy: 0.6383\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.4654 - accuracy: 0.8250 - val_loss: 0.9586 - val_accuracy: 0.6330\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 0.4763 - accuracy: 0.8211 - val_loss: 1.0072 - val_accuracy: 0.6064\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.4624 - accuracy: 0.8447 - val_loss: 1.0464 - val_accuracy: 0.6117\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.4683 - accuracy: 0.8184 - val_loss: 0.9555 - val_accuracy: 0.6489\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.4867 - accuracy: 0.8092 - val_loss: 1.0232 - val_accuracy: 0.6223\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.4002 - accuracy: 0.8395 - val_loss: 0.9477 - val_accuracy: 0.6543\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.4459 - accuracy: 0.8342 - val_loss: 0.9253 - val_accuracy: 0.6702\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.4479 - accuracy: 0.8197 - val_loss: 1.0625 - val_accuracy: 0.5585\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.4086 - accuracy: 0.8487 - val_loss: 0.9849 - val_accuracy: 0.6649\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.4018 - accuracy: 0.8474 - val_loss: 0.9962 - val_accuracy: 0.6011\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.4023 - accuracy: 0.8500 - val_loss: 1.0364 - val_accuracy: 0.6223\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.3877 - accuracy: 0.8553 - val_loss: 0.9787 - val_accuracy: 0.6809\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 0.3491 - accuracy: 0.8737 - val_loss: 1.0707 - val_accuracy: 0.5691\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.4029 - accuracy: 0.8579 - val_loss: 0.9346 - val_accuracy: 0.6596\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.3409 - accuracy: 0.8553 - val_loss: 0.9462 - val_accuracy: 0.6330\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.4074 - accuracy: 0.8382 - val_loss: 0.8943 - val_accuracy: 0.7074\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.3601 - accuracy: 0.8592 - val_loss: 0.8647 - val_accuracy: 0.6862\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.3834 - accuracy: 0.8605 - val_loss: 0.8801 - val_accuracy: 0.6862\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.3321 - accuracy: 0.8750 - val_loss: 0.8997 - val_accuracy: 0.6809\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.3541 - accuracy: 0.8750 - val_loss: 0.8632 - val_accuracy: 0.7021\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.2892 - accuracy: 0.8803 - val_loss: 0.8739 - val_accuracy: 0.6755\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.3262 - accuracy: 0.8842 - val_loss: 0.8788 - val_accuracy: 0.6862\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.3303 - accuracy: 0.8829 - val_loss: 0.8124 - val_accuracy: 0.7128\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 0.3512 - accuracy: 0.8763 - val_loss: 0.9419 - val_accuracy: 0.6596\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 0.3196 - accuracy: 0.8842 - val_loss: 0.8526 - val_accuracy: 0.6968\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 0.3068 - accuracy: 0.8803 - val_loss: 0.8846 - val_accuracy: 0.6702\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 0.3040 - accuracy: 0.8855 - val_loss: 0.9548 - val_accuracy: 0.6436\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 0.2807 - accuracy: 0.9039 - val_loss: 0.8917 - val_accuracy: 0.6702\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.2578 - accuracy: 0.9079 - val_loss: 0.8095 - val_accuracy: 0.6915\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 0.2935 - accuracy: 0.8908 - val_loss: 0.8951 - val_accuracy: 0.6649\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 0.2948 - accuracy: 0.9026 - val_loss: 0.9265 - val_accuracy: 0.6489\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.2517 - accuracy: 0.9092 - val_loss: 0.7835 - val_accuracy: 0.6649\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.2851 - accuracy: 0.8921 - val_loss: 0.9544 - val_accuracy: 0.6436\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.2631 - accuracy: 0.9039 - val_loss: 0.7914 - val_accuracy: 0.7021\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.3153 - accuracy: 0.8816 - val_loss: 0.7585 - val_accuracy: 0.6968\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.2490 - accuracy: 0.9105 - val_loss: 0.8021 - val_accuracy: 0.7287\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.2676 - accuracy: 0.8987 - val_loss: 0.7916 - val_accuracy: 0.6862\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.2597 - accuracy: 0.9092 - val_loss: 0.8114 - val_accuracy: 0.6915\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.2383 - accuracy: 0.9105 - val_loss: 0.7820 - val_accuracy: 0.6968\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.2217 - accuracy: 0.9303 - val_loss: 0.8849 - val_accuracy: 0.6649\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.2724 - accuracy: 0.8961 - val_loss: 0.8284 - val_accuracy: 0.6862\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.2641 - accuracy: 0.9053 - val_loss: 0.8426 - val_accuracy: 0.6862\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.2656 - accuracy: 0.9026 - val_loss: 0.7727 - val_accuracy: 0.7021\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.2754 - accuracy: 0.8974 - val_loss: 0.7682 - val_accuracy: 0.6809\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.2255 - accuracy: 0.9224 - val_loss: 0.7711 - val_accuracy: 0.6436\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.2051 - accuracy: 0.9211 - val_loss: 0.7801 - val_accuracy: 0.6809\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.2197 - accuracy: 0.9171 - val_loss: 0.7601 - val_accuracy: 0.6968\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.2190 - accuracy: 0.9237 - val_loss: 0.7805 - val_accuracy: 0.6702\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.1846 - accuracy: 0.9316 - val_loss: 0.8107 - val_accuracy: 0.6755\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.2064 - accuracy: 0.9158 - val_loss: 0.8354 - val_accuracy: 0.6543\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.2069 - accuracy: 0.9276 - val_loss: 0.7517 - val_accuracy: 0.6862\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.1819 - accuracy: 0.9342 - val_loss: 0.7861 - val_accuracy: 0.7074\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.2240 - accuracy: 0.9158 - val_loss: 0.8216 - val_accuracy: 0.6809\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.1958 - accuracy: 0.9355 - val_loss: 0.7609 - val_accuracy: 0.7021\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.2260 - accuracy: 0.9132 - val_loss: 0.7666 - val_accuracy: 0.7074\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 0.1949 - accuracy: 0.9329 - val_loss: 0.8275 - val_accuracy: 0.7021\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 0.2149 - accuracy: 0.9276 - val_loss: 0.7889 - val_accuracy: 0.7128\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.2037 - accuracy: 0.9250 - val_loss: 0.8887 - val_accuracy: 0.6915\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 0.1765 - accuracy: 0.9355 - val_loss: 0.8387 - val_accuracy: 0.6755\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 0.2169 - accuracy: 0.9237 - val_loss: 0.8560 - val_accuracy: 0.6702\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.1907 - accuracy: 0.9368 - val_loss: 0.8485 - val_accuracy: 0.6968\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 0.1849 - accuracy: 0.9342 - val_loss: 0.8133 - val_accuracy: 0.7074\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 0.2250 - accuracy: 0.9224 - val_loss: 0.7541 - val_accuracy: 0.7234\n"
          ]
        }
      ],
      "source": [
        "cnn_subject_model.compile(loss='categorical_crossentropy',\n",
        "                 optimizer=cnn_subject_model_optimizer,\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "cnn_subject_model_results = cnn_subject_model.fit(x_train,\n",
        "             y_train,\n",
        "             batch_size=64,\n",
        "             epochs=epochs,\n",
        "             validation_data=(x_valid, y_valid), verbose=True\n",
        "             )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kFaoUrLdkrSG",
        "outputId": "0f63f54d-415d-4804-f3d5-9cb3cf756e97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(cnn_subject_model_results.history['accuracy'])\n",
        "plt.plot(cnn_subject_model_results.history['val_accuracy'])\n",
        "plt.title('CNN Model Accuracy for Subject 1')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(cnn_subject_model_results.history['loss'])\n",
        "plt.plot(cnn_subject_model_results.history['val_loss'])\n",
        "plt.title('CNN Model Loss for Subject 1')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yxvYcfjGKR6"
      },
      "source": [
        "#### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QwZMjkCEGKR6",
        "outputId": "7b9b2aa9-32fa-4822-a7fe-0434e7585462",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy of the CNN model for subject 0: 0.699999988079071\n"
          ]
        }
      ],
      "source": [
        "cnn_subject_model_score = cnn_subject_model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f'Test accuracy of the CNN model for subject {subject}:',cnn_subject_model_score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTD25eBSGKR6"
      },
      "source": [
        "## 1.2 Now Training across all subjects"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krzQennDGKR6"
      },
      "source": [
        "#### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sEOEH8rRGKR6",
        "outputId": "db7420aa-41dd-4a2b-950e-c4530760dd6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test Shape for Subject 0: (50, 22, 1000)\n",
            "y_test Shape for Subject 0: (50,)\n",
            "X_train_valid Shape for Subject 0: (237, 22, 1000)\n",
            "y_train_valid Shape for Subject 0: (237,)\n",
            "Shape of training set: (6768, 22, 250)\n",
            "Shape of validation set: (1692, 22, 250)\n",
            "Shape of training labels: (6768,)\n",
            "Shape of validation labels: (1692,)\n",
            "Shape of testing set: (200, 22, 250)\n",
            "Shape of testing labels: (200,)\n",
            "Shape of training labels after categorical conversion: (6768, 4)\n",
            "Shape of validation labels after categorical conversion: (1692, 4)\n",
            "Shape of test labels after categorical conversion: (200, 4)\n",
            "Shape of training set after adding width info: (6768, 22, 250, 1)\n",
            "Shape of validation set after adding width info: (1692, 22, 250, 1)\n",
            "Shape of test set after adding width info: (200, 22, 250, 1)\n",
            "Shape of training set after dimension reshaping: (6768, 250, 1, 22)\n",
            "Shape of validation set after dimension reshaping: (1692, 250, 1, 22)\n",
            "Shape of test set after dimension reshaping: (200, 250, 1, 22)\n"
          ]
        }
      ],
      "source": [
        "X_test = np.load(\"X_test.npy\")\n",
        "y_test = np.load(\"y_test.npy\")\n",
        "person_train_valid = np.load(\"person_train_valid.npy\")\n",
        "X_train_valid = np.load(\"X_train_valid.npy\")\n",
        "y_train_valid = np.load(\"y_train_valid.npy\")\n",
        "person_test = np.load(\"person_test.npy\")\n",
        "\n",
        "## Adjusting the labels so that \n",
        "\n",
        "# Cue onset left - 0\n",
        "# Cue onset right - 1\n",
        "# Cue onset foot - 2\n",
        "# Cue onset tongue - 3\n",
        "\n",
        "y_train_valid -= 769\n",
        "y_test -= 769\n",
        "\n",
        "subject = 0\n",
        "subject_test_idx = np.where(person_test==subject)[0]\n",
        "subject_valid_idx = np.where(person_train_valid==subject)[0]\n",
        "\n",
        "\n",
        "subject_X_test = X_test[subject_test_idx]\n",
        "suject_y_test = y_test[subject_test_idx]\n",
        "suject_X_train_valid = X_train_valid[subject_valid_idx]\n",
        "suject_y_train_valid = y_train_valid[subject_valid_idx]\n",
        "\n",
        "print(f'X_test Shape for Subject {subject}: {subject_X_test.shape}')\n",
        "print(f'y_test Shape for Subject {subject}: {suject_y_test.shape}')\n",
        "print(f'X_train_valid Shape for Subject {subject}: {suject_X_train_valid.shape}')\n",
        "print(f'y_train_valid Shape for Subject {subject}: {suject_y_train_valid.shape}')\n",
        "\n",
        "# shuffle with 5 fold\n",
        "indicies_valid = np.random.choice(X_train_valid.shape[0], X_train_valid.shape[0] // 5, replace=False)\n",
        "indicies_train = np.array(list(set(range(X_train_valid.shape[0])).difference(set(indicies_valid))))\n",
        "\n",
        "# Creating the training and validation sets using the generated indices\n",
        "X_train, X_valid = X_train_valid[indicies_train], X_train_valid[indicies_valid] \n",
        "y_train, y_valid = y_train_valid[indicies_train], y_train_valid[indicies_valid]\n",
        "\n",
        "\n",
        "# Preprocessing the dataset\n",
        "x_train,y_train = data_prep(X_train,y_train,2,2,True)\n",
        "x_valid,y_valid = data_prep(X_valid,y_valid,2,2,True)\n",
        "X_test_prep,y_test_prep = data_prep(subject_X_test,suject_y_test,2,2,True)\n",
        "\n",
        "\n",
        "\n",
        "print('Shape of training set:',x_train.shape)\n",
        "print('Shape of validation set:',x_valid.shape)\n",
        "print('Shape of training labels:',y_train.shape)\n",
        "print('Shape of validation labels:',y_valid.shape)\n",
        "print('Shape of testing set:',X_test_prep.shape)\n",
        "print('Shape of testing labels:',y_test_prep.shape)\n",
        "\n",
        "\n",
        "# Converting the labels to categorical variables for multiclass classification\n",
        "y_train = to_categorical(y_train, 4)\n",
        "y_valid = to_categorical(y_valid, 4)\n",
        "y_test = to_categorical(y_test_prep, 4)\n",
        "print('Shape of training labels after categorical conversion:',y_train.shape)\n",
        "print('Shape of validation labels after categorical conversion:',y_valid.shape)\n",
        "print('Shape of test labels after categorical conversion:',y_test.shape)\n",
        "\n",
        "# Adding width of the segment to be 1\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
        "x_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n",
        "print('Shape of training set after adding width info:',x_train.shape)\n",
        "print('Shape of validation set after adding width info:',x_valid.shape)\n",
        "print('Shape of test set after adding width info:',x_test.shape)\n",
        "\n",
        "\n",
        "# Reshaping the training and validation dataset\n",
        "x_train = np.swapaxes(x_train, 1,3)\n",
        "x_train = np.swapaxes(x_train, 1,2)\n",
        "x_valid = np.swapaxes(x_valid, 1,3)\n",
        "x_valid = np.swapaxes(x_valid, 1,2)\n",
        "x_test = np.swapaxes(x_test, 1,3)\n",
        "x_test = np.swapaxes(x_test, 1,2)\n",
        "print('Shape of training set after dimension reshaping:',x_train.shape)\n",
        "print('Shape of validation set after dimension reshaping:',x_valid.shape)\n",
        "print('Shape of test set after dimension reshaping:',x_test.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCKBSGgSGKR7"
      },
      "source": [
        "#### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tVI4PzObGKR7",
        "outputId": "9114a1da-bfb1-4061-91f6-cf436835327f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 250, 1, 10)        1110      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 84, 1, 10)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 84, 1, 10)        40        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 84, 1, 10)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 84, 1, 10)         1510      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 28, 1, 10)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 28, 1, 10)        40        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 28, 1, 10)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 280)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 1124      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,824\n",
            "Trainable params: 3,784\n",
            "Non-trainable params: 40\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Building the CNN model using sequential class\n",
        "cnn_subject_model = Sequential()\n",
        "\n",
        "# Conv. block 1\n",
        "cnn_subject_model.add(Conv2D(filters=10, kernel_size=(5,1), padding='same', activation='elu', input_shape=(250,1,22)))\n",
        "cnn_subject_model.add(MaxPooling2D(pool_size=(3,1), padding='same')) \n",
        "cnn_subject_model.add(BatchNormalization())\n",
        "cnn_subject_model.add(Dropout(0.5))\n",
        "\n",
        "# Conv. block 2\n",
        "cnn_subject_model.add(Conv2D(filters=10, kernel_size=(15,1), padding='same', activation='elu'))\n",
        "cnn_subject_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
        "cnn_subject_model.add(BatchNormalization())\n",
        "cnn_subject_model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "# Output layer with Softmax activation\n",
        "cnn_subject_model.add(Flatten()) # Flattens the input\n",
        "cnn_subject_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
        "\n",
        "\n",
        "# Printing the model summary\n",
        "cnn_subject_model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MtxVA-PGKR7"
      },
      "source": [
        "#### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "vUCxzbm6GKR8"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "epochs = 100\n",
        "cnn_subject_model_optimizer = keras.optimizers.Adam(learning_rate=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erljC2VLGKR8"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "56QXs7HFGKR8",
        "outputId": "1b5cc4c2-bfd4-46b9-8199-18b9f2d95270",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "106/106 [==============================] - 4s 34ms/step - loss: 1.9501 - accuracy: 0.2883 - val_loss: 1.3919 - val_accuracy: 0.3582\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 1.5720 - accuracy: 0.3299 - val_loss: 1.2895 - val_accuracy: 0.3824\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 4s 33ms/step - loss: 1.4010 - accuracy: 0.3754 - val_loss: 1.2405 - val_accuracy: 0.4433\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 1.3106 - accuracy: 0.3975 - val_loss: 1.2004 - val_accuracy: 0.4734\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 1.2353 - accuracy: 0.4360 - val_loss: 1.1897 - val_accuracy: 0.4752\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 5s 50ms/step - loss: 1.1955 - accuracy: 0.4697 - val_loss: 1.1509 - val_accuracy: 0.4829\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 1.1430 - accuracy: 0.4962 - val_loss: 1.1123 - val_accuracy: 0.5024\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 1.1208 - accuracy: 0.5148 - val_loss: 1.0745 - val_accuracy: 0.5313\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 1.0847 - accuracy: 0.5369 - val_loss: 1.0467 - val_accuracy: 0.5550\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 5s 49ms/step - loss: 1.0779 - accuracy: 0.5340 - val_loss: 1.0311 - val_accuracy: 0.5520\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 1.0569 - accuracy: 0.5488 - val_loss: 1.0185 - val_accuracy: 0.5898\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 1.0371 - accuracy: 0.5622 - val_loss: 0.9890 - val_accuracy: 0.5845\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 4s 35ms/step - loss: 1.0147 - accuracy: 0.5674 - val_loss: 0.9674 - val_accuracy: 0.6135\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 0.9992 - accuracy: 0.5788 - val_loss: 0.9406 - val_accuracy: 0.6147\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.9890 - accuracy: 0.5906 - val_loss: 0.9134 - val_accuracy: 0.6454\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.9712 - accuracy: 0.5941 - val_loss: 0.8962 - val_accuracy: 0.6489\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 4s 39ms/step - loss: 0.9606 - accuracy: 0.6043 - val_loss: 0.9046 - val_accuracy: 0.6212\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 0.9296 - accuracy: 0.6201 - val_loss: 0.8412 - val_accuracy: 0.6850\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.9249 - accuracy: 0.6194 - val_loss: 0.8344 - val_accuracy: 0.6939\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.9217 - accuracy: 0.6234 - val_loss: 0.8230 - val_accuracy: 0.6909\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 0.8993 - accuracy: 0.6322 - val_loss: 0.8362 - val_accuracy: 0.6661\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 4s 39ms/step - loss: 0.8882 - accuracy: 0.6424 - val_loss: 0.8164 - val_accuracy: 0.6761\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.8869 - accuracy: 0.6423 - val_loss: 0.8260 - val_accuracy: 0.6797\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.8633 - accuracy: 0.6467 - val_loss: 0.7782 - val_accuracy: 0.7175\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 5s 45ms/step - loss: 0.8677 - accuracy: 0.6467 - val_loss: 0.7689 - val_accuracy: 0.7057\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 4s 36ms/step - loss: 0.8602 - accuracy: 0.6491 - val_loss: 0.7698 - val_accuracy: 0.6933\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.8451 - accuracy: 0.6582 - val_loss: 0.7724 - val_accuracy: 0.7027\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.8506 - accuracy: 0.6543 - val_loss: 0.7762 - val_accuracy: 0.7027\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 5s 50ms/step - loss: 0.8281 - accuracy: 0.6687 - val_loss: 0.7960 - val_accuracy: 0.6743\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.8344 - accuracy: 0.6673 - val_loss: 0.7764 - val_accuracy: 0.6980\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.8242 - accuracy: 0.6683 - val_loss: 0.7551 - val_accuracy: 0.7039\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.8324 - accuracy: 0.6656 - val_loss: 0.7561 - val_accuracy: 0.6891\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 5s 50ms/step - loss: 0.8101 - accuracy: 0.6758 - val_loss: 0.7543 - val_accuracy: 0.7175\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.8308 - accuracy: 0.6670 - val_loss: 0.7544 - val_accuracy: 0.7021\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.8218 - accuracy: 0.6711 - val_loss: 0.7432 - val_accuracy: 0.7051\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 4s 33ms/step - loss: 0.8085 - accuracy: 0.6776 - val_loss: 0.7491 - val_accuracy: 0.7092\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 5s 48ms/step - loss: 0.8112 - accuracy: 0.6755 - val_loss: 0.7374 - val_accuracy: 0.7080\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.8035 - accuracy: 0.6733 - val_loss: 0.7353 - val_accuracy: 0.7086\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.8143 - accuracy: 0.6727 - val_loss: 0.7413 - val_accuracy: 0.7033\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 4s 37ms/step - loss: 0.7942 - accuracy: 0.6769 - val_loss: 0.7304 - val_accuracy: 0.7169\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 5s 44ms/step - loss: 0.8001 - accuracy: 0.6761 - val_loss: 0.7249 - val_accuracy: 0.7252\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.7861 - accuracy: 0.6755 - val_loss: 0.7307 - val_accuracy: 0.7128\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.7937 - accuracy: 0.6834 - val_loss: 0.7268 - val_accuracy: 0.7187\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 4s 40ms/step - loss: 0.7871 - accuracy: 0.6856 - val_loss: 0.7267 - val_accuracy: 0.7169\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 0.7774 - accuracy: 0.6847 - val_loss: 0.7433 - val_accuracy: 0.6998\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.7855 - accuracy: 0.6916 - val_loss: 0.7242 - val_accuracy: 0.7199\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.7972 - accuracy: 0.6746 - val_loss: 0.7305 - val_accuracy: 0.7246\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 5s 44ms/step - loss: 0.7801 - accuracy: 0.6903 - val_loss: 0.7253 - val_accuracy: 0.7045\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 4s 38ms/step - loss: 0.7745 - accuracy: 0.6888 - val_loss: 0.7378 - val_accuracy: 0.7128\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.7600 - accuracy: 0.6890 - val_loss: 0.7017 - val_accuracy: 0.7210\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.7795 - accuracy: 0.6894 - val_loss: 0.7046 - val_accuracy: 0.7281\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 5s 48ms/step - loss: 0.7657 - accuracy: 0.6978 - val_loss: 0.6891 - val_accuracy: 0.7441\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 4s 34ms/step - loss: 0.7737 - accuracy: 0.6881 - val_loss: 0.7012 - val_accuracy: 0.7258\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.7660 - accuracy: 0.6933 - val_loss: 0.6999 - val_accuracy: 0.7311\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.7645 - accuracy: 0.6974 - val_loss: 0.7060 - val_accuracy: 0.7335\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 5s 50ms/step - loss: 0.7718 - accuracy: 0.6928 - val_loss: 0.7088 - val_accuracy: 0.7287\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.7616 - accuracy: 0.6955 - val_loss: 0.7186 - val_accuracy: 0.7193\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.7651 - accuracy: 0.6940 - val_loss: 0.7130 - val_accuracy: 0.7240\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 4s 35ms/step - loss: 0.7428 - accuracy: 0.7079 - val_loss: 0.6961 - val_accuracy: 0.7370\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 5s 48ms/step - loss: 0.7567 - accuracy: 0.6967 - val_loss: 0.7088 - val_accuracy: 0.7134\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.7572 - accuracy: 0.6986 - val_loss: 0.6961 - val_accuracy: 0.7382\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.7574 - accuracy: 0.6961 - val_loss: 0.7262 - val_accuracy: 0.7210\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 4s 38ms/step - loss: 0.7479 - accuracy: 0.6990 - val_loss: 0.6881 - val_accuracy: 0.7346\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 5s 44ms/step - loss: 0.7548 - accuracy: 0.7014 - val_loss: 0.7092 - val_accuracy: 0.7264\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.7619 - accuracy: 0.6955 - val_loss: 0.6973 - val_accuracy: 0.7287\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.7374 - accuracy: 0.7017 - val_loss: 0.7054 - val_accuracy: 0.7252\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 4s 40ms/step - loss: 0.7458 - accuracy: 0.6965 - val_loss: 0.6843 - val_accuracy: 0.7352\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 0.7522 - accuracy: 0.7007 - val_loss: 0.6988 - val_accuracy: 0.7394\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.7615 - accuracy: 0.7004 - val_loss: 0.7153 - val_accuracy: 0.7110\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.7713 - accuracy: 0.6899 - val_loss: 0.7009 - val_accuracy: 0.7376\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 5s 44ms/step - loss: 0.7457 - accuracy: 0.7040 - val_loss: 0.7108 - val_accuracy: 0.7323\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 4s 38ms/step - loss: 0.7664 - accuracy: 0.6896 - val_loss: 0.6866 - val_accuracy: 0.7506\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.7352 - accuracy: 0.7026 - val_loss: 0.6941 - val_accuracy: 0.7370\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.7470 - accuracy: 0.7029 - val_loss: 0.6802 - val_accuracy: 0.7441\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 5s 48ms/step - loss: 0.7494 - accuracy: 0.7051 - val_loss: 0.6965 - val_accuracy: 0.7329\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 4s 36ms/step - loss: 0.7459 - accuracy: 0.7033 - val_loss: 0.6988 - val_accuracy: 0.7340\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.7382 - accuracy: 0.7004 - val_loss: 0.7160 - val_accuracy: 0.7216\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.7525 - accuracy: 0.6996 - val_loss: 0.6882 - val_accuracy: 0.7311\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 5s 50ms/step - loss: 0.7419 - accuracy: 0.7076 - val_loss: 0.6961 - val_accuracy: 0.7382\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.7524 - accuracy: 0.6989 - val_loss: 0.6858 - val_accuracy: 0.7411\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.7353 - accuracy: 0.7098 - val_loss: 0.6982 - val_accuracy: 0.7204\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 3s 33ms/step - loss: 0.7353 - accuracy: 0.7100 - val_loss: 0.6912 - val_accuracy: 0.7240\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 5s 50ms/step - loss: 0.7368 - accuracy: 0.7103 - val_loss: 0.6850 - val_accuracy: 0.7358\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.7420 - accuracy: 0.7042 - val_loss: 0.6700 - val_accuracy: 0.7453\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.7305 - accuracy: 0.7113 - val_loss: 0.7056 - val_accuracy: 0.7187\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 4s 38ms/step - loss: 0.7355 - accuracy: 0.7125 - val_loss: 0.6980 - val_accuracy: 0.7293\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 5s 45ms/step - loss: 0.7319 - accuracy: 0.7061 - val_loss: 0.6898 - val_accuracy: 0.7299\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.7298 - accuracy: 0.7120 - val_loss: 0.6971 - val_accuracy: 0.7264\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 4s 38ms/step - loss: 0.7432 - accuracy: 0.7057 - val_loss: 0.7040 - val_accuracy: 0.7210\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 6s 61ms/step - loss: 0.7393 - accuracy: 0.7060 - val_loss: 0.6778 - val_accuracy: 0.7429\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 4s 40ms/step - loss: 0.7355 - accuracy: 0.7027 - val_loss: 0.6861 - val_accuracy: 0.7370\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 3s 33ms/step - loss: 0.7324 - accuracy: 0.7042 - val_loss: 0.6949 - val_accuracy: 0.7335\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 3s 33ms/step - loss: 0.7191 - accuracy: 0.7122 - val_loss: 0.6821 - val_accuracy: 0.7370\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 5s 49ms/step - loss: 0.7173 - accuracy: 0.7188 - val_loss: 0.6725 - val_accuracy: 0.7417\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 4s 35ms/step - loss: 0.7262 - accuracy: 0.7095 - val_loss: 0.6901 - val_accuracy: 0.7287\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 3s 33ms/step - loss: 0.7426 - accuracy: 0.7023 - val_loss: 0.6826 - val_accuracy: 0.7346\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.7174 - accuracy: 0.7135 - val_loss: 0.6764 - val_accuracy: 0.7376\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 5s 51ms/step - loss: 0.7237 - accuracy: 0.7150 - val_loss: 0.6873 - val_accuracy: 0.7275\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 3s 33ms/step - loss: 0.7507 - accuracy: 0.7018 - val_loss: 0.6803 - val_accuracy: 0.7411\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.7294 - accuracy: 0.7055 - val_loss: 0.6775 - val_accuracy: 0.7388\n"
          ]
        }
      ],
      "source": [
        "cnn_subject_model.compile(loss='categorical_crossentropy',\n",
        "                 optimizer=cnn_subject_model_optimizer,\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "cnn_subject_model_results = cnn_subject_model.fit(x_train,\n",
        "             y_train,\n",
        "             batch_size=64,\n",
        "             epochs=epochs,\n",
        "             validation_data=(x_valid, y_valid), verbose=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-acbUx1PGKR8"
      },
      "source": [
        "#### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "iiZDDFgUGKR9",
        "outputId": "cf5bbe0b-53bf-4baf-de60-9cba9c1bc6a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy of the CNN model for subject 0: 0.7400000095367432\n"
          ]
        }
      ],
      "source": [
        "cnn_subject_model_score = cnn_subject_model.evaluate(x_test, y_test, verbose=False)\n",
        "print(f'Test accuracy of the CNN model for subject {subject}:',cnn_subject_model_score[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APp4GfXiGKR9"
      },
      "source": [
        "## 2. Optimize the classification accuracy across all subjects. How does the classifier do? Do you notice any interesting trends?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWKBf2NdGKR9"
      },
      "source": [
        "#### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "g6_qnCAcGKR9"
      },
      "outputs": [],
      "source": [
        "def preprocess_subjects(subject):\n",
        "    X_test = np.load(\"X_test.npy\")\n",
        "    y_test = np.load(\"y_test.npy\")\n",
        "    person_train_valid = np.load(\"person_train_valid.npy\")\n",
        "    X_train_valid = np.load(\"X_train_valid.npy\")\n",
        "    y_train_valid = np.load(\"y_train_valid.npy\")\n",
        "    person_test = np.load(\"person_test.npy\")\n",
        "\n",
        "    ## Adjusting the labels so that \n",
        "\n",
        "    # Cue onset left - 0\n",
        "    # Cue onset right - 1\n",
        "    # Cue onset foot - 2\n",
        "    # Cue onset tongue - 3\n",
        "\n",
        "    y_train_valid -= 769\n",
        "    y_test -= 769\n",
        "    \n",
        "\n",
        "\n",
        "    subject_test_idx = np.where(person_test==subject)[0]\n",
        "    subject_valid_idx = np.where(person_train_valid==subject)[0]\n",
        "\n",
        "\n",
        "    subject_X_test = X_test[subject_test_idx]\n",
        "    suject_y_test = y_test[subject_test_idx]\n",
        "    suject_X_train_valid = X_train_valid[subject_valid_idx]\n",
        "    suject_y_train_valid = y_train_valid[subject_valid_idx]\n",
        "\n",
        "\n",
        "    # shuffle with 5 fold\n",
        "    indicies_valid = np.random.choice(X_train_valid.shape[0], X_train_valid.shape[0] // 5, replace=False)\n",
        "    indicies_train = np.array(list(set(range(X_train_valid.shape[0])).difference(set(indicies_valid))))\n",
        "\n",
        "    # Creating the training and validation sets using the generated indices\n",
        "    X_train, X_valid = X_train_valid[indicies_train], X_train_valid[indicies_valid] \n",
        "    y_train, y_valid = y_train_valid[indicies_train], y_train_valid[indicies_valid]\n",
        "\n",
        "\n",
        "    # Preprocessing the dataset\n",
        "    x_train,y_train = data_prep(X_train,y_train,2,2,True)\n",
        "    x_valid,y_valid = data_prep(X_valid,y_valid,2,2,True)\n",
        "    X_test_prep,y_test_prep = data_prep(subject_X_test,suject_y_test,2,2,True)\n",
        "\n",
        "\n",
        "\n",
        "    # Converting the labels to categorical variables for multiclass classification\n",
        "    y_train = to_categorical(y_train, 4)\n",
        "    y_valid = to_categorical(y_valid, 4)\n",
        "    y_test = to_categorical(y_test_prep, 4)\n",
        "\n",
        "\n",
        "    # Adding width of the segment to be 1\n",
        "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "    x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
        "    x_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n",
        "\n",
        "\n",
        "    # Reshaping the training and validation dataset\n",
        "    x_train = np.swapaxes(x_train, 1,3)\n",
        "    x_train = np.swapaxes(x_train, 1,2)\n",
        "    x_valid = np.swapaxes(x_valid, 1,3)\n",
        "    x_valid = np.swapaxes(x_valid, 1,2)\n",
        "    x_test = np.swapaxes(x_test, 1,3)\n",
        "    x_test = np.swapaxes(x_test, 1,2)\n",
        "\n",
        "    return (x_train, y_train, x_valid, y_valid, x_test, y_test)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJC849YUGKR-"
      },
      "source": [
        "#### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZIF9FVOqGKR-"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "epochs = 100\n",
        "cnn_subject_model_optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "x_train, y_train, x_valid, y_valid, _, _ = preprocess_subjects(subject=2)\n",
        "\n",
        "# Building the CNN model using sequential class\n",
        "cnn_subject_model = Sequential()\n",
        "\n",
        "# Conv. block 1\n",
        "cnn_subject_model.add(Conv2D(filters=20, kernel_size=(5,1), padding='same', activation='elu', input_shape=(250,1,22)))\n",
        "cnn_subject_model.add(MaxPooling2D(pool_size=(3,1), padding='same')) \n",
        "cnn_subject_model.add(BatchNormalization())\n",
        "cnn_subject_model.add(Dropout(0.5))\n",
        "\n",
        "# Conv. block 2\n",
        "cnn_subject_model.add(Conv2D(filters=20, kernel_size=(15,1), padding='same', activation='elu'))\n",
        "cnn_subject_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
        "cnn_subject_model.add(BatchNormalization())\n",
        "cnn_subject_model.add(Dropout(0.5))\n",
        "\n",
        "# Conv. block 3\n",
        "cnn_subject_model.add(Conv2D(filters=10, kernel_size=(10,1), padding='same', activation='elu'))\n",
        "cnn_subject_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
        "cnn_subject_model.add(BatchNormalization())\n",
        "cnn_subject_model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "# Output layer with Softmax activation\n",
        "cnn_subject_model.add(Flatten()) # Flattens the input\n",
        "cnn_subject_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb4dCbGpGKR_"
      },
      "source": [
        "#### Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "zMrbBgE5GKR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f3a9900-381a-4ae0-a179-ddd249c5e903"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "106/106 [==============================] - 7s 51ms/step - loss: 1.9099 - accuracy: 0.2868 - val_loss: 1.4295 - val_accuracy: 0.3552\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 5s 51ms/step - loss: 1.5653 - accuracy: 0.3181 - val_loss: 1.2727 - val_accuracy: 0.3972\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 7s 67ms/step - loss: 1.4125 - accuracy: 0.3608 - val_loss: 1.2560 - val_accuracy: 0.4137\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 1.3310 - accuracy: 0.3837 - val_loss: 1.2192 - val_accuracy: 0.4586\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 7s 67ms/step - loss: 1.2753 - accuracy: 0.4060 - val_loss: 1.1750 - val_accuracy: 0.4982\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 1.2281 - accuracy: 0.4409 - val_loss: 1.1275 - val_accuracy: 0.5396\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 1.1862 - accuracy: 0.4668 - val_loss: 1.0875 - val_accuracy: 0.5674\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 7s 70ms/step - loss: 1.1605 - accuracy: 0.4898 - val_loss: 1.0759 - val_accuracy: 0.5650\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 5s 46ms/step - loss: 1.1388 - accuracy: 0.4972 - val_loss: 1.0415 - val_accuracy: 0.5822\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 6s 61ms/step - loss: 1.1131 - accuracy: 0.5192 - val_loss: 1.0257 - val_accuracy: 0.5827\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 6s 53ms/step - loss: 1.1079 - accuracy: 0.5164 - val_loss: 1.0126 - val_accuracy: 0.6093\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 1.0793 - accuracy: 0.5369 - val_loss: 1.0276 - val_accuracy: 0.5556\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 7s 68ms/step - loss: 1.0540 - accuracy: 0.5439 - val_loss: 0.9853 - val_accuracy: 0.5869\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 1.0508 - accuracy: 0.5564 - val_loss: 0.9681 - val_accuracy: 0.6229\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 6s 54ms/step - loss: 1.0315 - accuracy: 0.5656 - val_loss: 0.9827 - val_accuracy: 0.5969\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 6s 60ms/step - loss: 1.0058 - accuracy: 0.5786 - val_loss: 0.9491 - val_accuracy: 0.6324\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 1.0086 - accuracy: 0.5745 - val_loss: 0.9491 - val_accuracy: 0.6253\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 7s 67ms/step - loss: 0.9930 - accuracy: 0.5819 - val_loss: 0.9193 - val_accuracy: 0.6418\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 0.9877 - accuracy: 0.5823 - val_loss: 0.8956 - val_accuracy: 0.6602\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 5s 50ms/step - loss: 0.9718 - accuracy: 0.6006 - val_loss: 0.9194 - val_accuracy: 0.6164\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.9709 - accuracy: 0.6005 - val_loss: 0.9047 - val_accuracy: 0.6359\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 0.9476 - accuracy: 0.6085 - val_loss: 0.8854 - val_accuracy: 0.6507\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 7s 66ms/step - loss: 0.9294 - accuracy: 0.6195 - val_loss: 0.8627 - val_accuracy: 0.6696\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 5s 50ms/step - loss: 0.9270 - accuracy: 0.6220 - val_loss: 0.8602 - val_accuracy: 0.6726\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 0.9174 - accuracy: 0.6262 - val_loss: 0.8600 - val_accuracy: 0.6507\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 7s 68ms/step - loss: 0.9059 - accuracy: 0.6275 - val_loss: 0.8305 - val_accuracy: 0.6732\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 5s 48ms/step - loss: 0.8935 - accuracy: 0.6396 - val_loss: 0.8389 - val_accuracy: 0.6673\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 6s 58ms/step - loss: 0.8953 - accuracy: 0.6309 - val_loss: 0.8295 - val_accuracy: 0.6921\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 6s 59ms/step - loss: 0.8759 - accuracy: 0.6404 - val_loss: 0.7982 - val_accuracy: 0.6998\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 0.8785 - accuracy: 0.6392 - val_loss: 0.8152 - val_accuracy: 0.6862\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 7s 68ms/step - loss: 0.8691 - accuracy: 0.6546 - val_loss: 0.8310 - val_accuracy: 0.6743\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 5s 48ms/step - loss: 0.8606 - accuracy: 0.6455 - val_loss: 0.8165 - val_accuracy: 0.6755\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 6s 55ms/step - loss: 0.8541 - accuracy: 0.6631 - val_loss: 0.8226 - val_accuracy: 0.6785\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 6s 60ms/step - loss: 0.8416 - accuracy: 0.6602 - val_loss: 0.8068 - val_accuracy: 0.6962\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 0.8423 - accuracy: 0.6671 - val_loss: 0.8295 - val_accuracy: 0.6619\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 7s 67ms/step - loss: 0.8345 - accuracy: 0.6572 - val_loss: 0.8029 - val_accuracy: 0.6785\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 0.8230 - accuracy: 0.6689 - val_loss: 0.7862 - val_accuracy: 0.7187\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 5s 49ms/step - loss: 0.8381 - accuracy: 0.6585 - val_loss: 0.8082 - val_accuracy: 0.6980\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.8152 - accuracy: 0.6779 - val_loss: 0.8100 - val_accuracy: 0.6862\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 0.8197 - accuracy: 0.6664 - val_loss: 0.8157 - val_accuracy: 0.6702\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.8052 - accuracy: 0.6752 - val_loss: 0.7976 - val_accuracy: 0.7021\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 6s 53ms/step - loss: 0.8162 - accuracy: 0.6729 - val_loss: 0.8103 - val_accuracy: 0.7039\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 5s 50ms/step - loss: 0.8107 - accuracy: 0.6715 - val_loss: 0.7802 - val_accuracy: 0.7098\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 7s 68ms/step - loss: 0.8022 - accuracy: 0.6823 - val_loss: 0.8073 - val_accuracy: 0.6720\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 0.8045 - accuracy: 0.6801 - val_loss: 0.7669 - val_accuracy: 0.7080\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 6s 60ms/step - loss: 0.7940 - accuracy: 0.6838 - val_loss: 0.7706 - val_accuracy: 0.6962\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 6s 54ms/step - loss: 0.7890 - accuracy: 0.6847 - val_loss: 0.7822 - val_accuracy: 0.6939\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 5s 46ms/step - loss: 0.7926 - accuracy: 0.6801 - val_loss: 0.7799 - val_accuracy: 0.7051\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 7s 67ms/step - loss: 0.7878 - accuracy: 0.6875 - val_loss: 0.8085 - val_accuracy: 0.6673\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 0.7848 - accuracy: 0.6857 - val_loss: 0.7693 - val_accuracy: 0.7063\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 6s 55ms/step - loss: 0.7736 - accuracy: 0.6931 - val_loss: 0.7389 - val_accuracy: 0.7204\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 6s 60ms/step - loss: 0.7827 - accuracy: 0.6896 - val_loss: 0.7948 - val_accuracy: 0.6962\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 0.7714 - accuracy: 0.6885 - val_loss: 0.7890 - val_accuracy: 0.6755\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 7s 67ms/step - loss: 0.7724 - accuracy: 0.6919 - val_loss: 0.7473 - val_accuracy: 0.7234\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 5s 48ms/step - loss: 0.7613 - accuracy: 0.7014 - val_loss: 0.7692 - val_accuracy: 0.6992\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 5s 50ms/step - loss: 0.7650 - accuracy: 0.6973 - val_loss: 0.7847 - val_accuracy: 0.6838\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 7s 65ms/step - loss: 0.7597 - accuracy: 0.6958 - val_loss: 0.7606 - val_accuracy: 0.6897\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 5s 50ms/step - loss: 0.7597 - accuracy: 0.6947 - val_loss: 0.7545 - val_accuracy: 0.7134\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 7s 66ms/step - loss: 0.7689 - accuracy: 0.6943 - val_loss: 0.7096 - val_accuracy: 0.7305\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 5s 48ms/step - loss: 0.7493 - accuracy: 0.6996 - val_loss: 0.7749 - val_accuracy: 0.6944\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 0.7792 - accuracy: 0.6851 - val_loss: 0.7243 - val_accuracy: 0.7246\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 7s 68ms/step - loss: 0.7465 - accuracy: 0.7035 - val_loss: 0.7658 - val_accuracy: 0.7092\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 0.7351 - accuracy: 0.7126 - val_loss: 0.7690 - val_accuracy: 0.6944\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 6s 60ms/step - loss: 0.7391 - accuracy: 0.7105 - val_loss: 0.7530 - val_accuracy: 0.7116\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 6s 54ms/step - loss: 0.7679 - accuracy: 0.7032 - val_loss: 0.7654 - val_accuracy: 0.7015\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 5s 48ms/step - loss: 0.7374 - accuracy: 0.7064 - val_loss: 0.7667 - val_accuracy: 0.7116\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 7s 68ms/step - loss: 0.7485 - accuracy: 0.7046 - val_loss: 0.7639 - val_accuracy: 0.6998\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 5s 48ms/step - loss: 0.7441 - accuracy: 0.7015 - val_loss: 0.7405 - val_accuracy: 0.7080\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 6s 54ms/step - loss: 0.7370 - accuracy: 0.7057 - val_loss: 0.7583 - val_accuracy: 0.7033\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 6s 60ms/step - loss: 0.7174 - accuracy: 0.7116 - val_loss: 0.7410 - val_accuracy: 0.7175\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 0.7043 - accuracy: 0.7191 - val_loss: 0.7855 - val_accuracy: 0.6933\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 7s 70ms/step - loss: 0.7237 - accuracy: 0.7114 - val_loss: 0.7554 - val_accuracy: 0.7116\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 5s 48ms/step - loss: 0.7264 - accuracy: 0.7116 - val_loss: 0.7668 - val_accuracy: 0.6980\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 5s 52ms/step - loss: 0.7202 - accuracy: 0.7126 - val_loss: 0.7531 - val_accuracy: 0.7074\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 7s 63ms/step - loss: 0.7153 - accuracy: 0.7153 - val_loss: 0.7510 - val_accuracy: 0.7033\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 0.7116 - accuracy: 0.7145 - val_loss: 0.7640 - val_accuracy: 0.7145\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 7s 67ms/step - loss: 0.7212 - accuracy: 0.7160 - val_loss: 0.7673 - val_accuracy: 0.7086\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 6s 52ms/step - loss: 0.7028 - accuracy: 0.7233 - val_loss: 0.7665 - val_accuracy: 0.7128\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 5s 50ms/step - loss: 0.7183 - accuracy: 0.7191 - val_loss: 0.7439 - val_accuracy: 0.7193\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 7s 65ms/step - loss: 0.7345 - accuracy: 0.7132 - val_loss: 0.7514 - val_accuracy: 0.7134\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 5s 48ms/step - loss: 0.7182 - accuracy: 0.7122 - val_loss: 0.7181 - val_accuracy: 0.7352\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 7s 65ms/step - loss: 0.7029 - accuracy: 0.7234 - val_loss: 0.7541 - val_accuracy: 0.7116\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 5s 50ms/step - loss: 0.7054 - accuracy: 0.7227 - val_loss: 0.7483 - val_accuracy: 0.7021\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 0.7128 - accuracy: 0.7111 - val_loss: 0.7352 - val_accuracy: 0.7293\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 7s 71ms/step - loss: 0.6937 - accuracy: 0.7308 - val_loss: 0.7195 - val_accuracy: 0.7222\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 0.6960 - accuracy: 0.7258 - val_loss: 0.7297 - val_accuracy: 0.7134\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 6s 59ms/step - loss: 0.6931 - accuracy: 0.7289 - val_loss: 0.7044 - val_accuracy: 0.7311\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 6s 55ms/step - loss: 0.7023 - accuracy: 0.7154 - val_loss: 0.7254 - val_accuracy: 0.7335\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 0.7077 - accuracy: 0.7159 - val_loss: 0.7322 - val_accuracy: 0.7281\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 7s 68ms/step - loss: 0.6947 - accuracy: 0.7249 - val_loss: 0.7755 - val_accuracy: 0.6986\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 5s 48ms/step - loss: 0.7088 - accuracy: 0.7213 - val_loss: 0.7175 - val_accuracy: 0.7382\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 6s 54ms/step - loss: 0.6924 - accuracy: 0.7252 - val_loss: 0.7130 - val_accuracy: 0.7293\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 7s 62ms/step - loss: 0.6946 - accuracy: 0.7241 - val_loss: 0.7534 - val_accuracy: 0.6998\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 0.7048 - accuracy: 0.7253 - val_loss: 0.7480 - val_accuracy: 0.7098\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 8s 80ms/step - loss: 0.7078 - accuracy: 0.7215 - val_loss: 0.7537 - val_accuracy: 0.7069\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 6s 59ms/step - loss: 0.7020 - accuracy: 0.7255 - val_loss: 0.7207 - val_accuracy: 0.7270\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 6s 61ms/step - loss: 0.6845 - accuracy: 0.7327 - val_loss: 0.7134 - val_accuracy: 0.7252\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 6s 56ms/step - loss: 0.6865 - accuracy: 0.7265 - val_loss: 0.7028 - val_accuracy: 0.7246\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 5s 48ms/step - loss: 0.6793 - accuracy: 0.7340 - val_loss: 0.7286 - val_accuracy: 0.7086\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 7s 68ms/step - loss: 0.7095 - accuracy: 0.7172 - val_loss: 0.7141 - val_accuracy: 0.7216\n"
          ]
        }
      ],
      "source": [
        "# Printing the model summary\n",
        "# cnn_subject_model.summary()\n",
        "cnn_subject_model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=cnn_subject_model_optimizer,\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "cnn_subject_model_results = cnn_subject_model.fit(x_train,\n",
        "            y_train,\n",
        "            batch_size=64,\n",
        "            epochs=epochs,\n",
        "            validation_data=(x_valid, y_valid), verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(cnn_subject_model_results.history['accuracy'])\n",
        "plt.plot(cnn_subject_model_results.history['val_accuracy'])\n",
        "plt.title('CNN Model Accuracy for All Subjects')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(cnn_subject_model_results.history['loss'])\n",
        "plt.plot(cnn_subject_model_results.history['val_loss'])\n",
        "plt.title('CNN Model Loss for All Subjects')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "yQBLSudzC5Cz",
        "outputId": "a22d4cc3-f0ab-4e3c-88fb-8e202544744d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCmBn-4FGKR_"
      },
      "source": [
        "#### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "-ANo1mkOGKR_",
        "outputId": "cd9422e6-69e1-48f2-cacf-9f299663bbd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 8ms/step - loss: 0.7869 - accuracy: 0.6450\n",
            "Test accuracy of the CNN model for subject 0: 0.6449999809265137\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.9850 - accuracy: 0.5650\n",
            "Test accuracy of the CNN model for subject 1: 0.5649999976158142\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5456 - accuracy: 0.7950\n",
            "Test accuracy of the CNN model for subject 2: 0.7950000166893005\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6900 - accuracy: 0.7400\n",
            "Test accuracy of the CNN model for subject 3: 0.7400000095367432\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.7767 - accuracy: 0.7287\n",
            "Test accuracy of the CNN model for subject 4: 0.728723406791687\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.7083 - accuracy: 0.6786\n",
            "Test accuracy of the CNN model for subject 5: 0.6785714030265808\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.7951 - accuracy: 0.7200\n",
            "Test accuracy of the CNN model for subject 6: 0.7200000286102295\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.7080 - accuracy: 0.6950\n",
            "Test accuracy of the CNN model for subject 7: 0.6949999928474426\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6255 - accuracy: 0.7766\n",
            "Test accuracy of the CNN model for subject 8: 0.7765957713127136\n"
          ]
        }
      ],
      "source": [
        "subjects = 9\n",
        "subject_scores = []\n",
        "for subject in range(subjects):\n",
        "    # tf.keras.backend.clear_session()\n",
        "    _, _, _, _, x_test, y_test = preprocess_subjects(subject=subject)\n",
        "    cnn_subject_model_score = cnn_subject_model.evaluate(x_test, y_test, verbose=True)\n",
        "    print(f'Test accuracy of the CNN model for subject {subject}:',cnn_subject_model_score[1])\n",
        "\n",
        "    subject_scores.append(cnn_subject_model_score[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "# making the bar chart on the data\n",
        "x = list(range(9))\n",
        "plt.bar(x, subject_scores)\n",
        "  \n",
        "# add value labels\n",
        "for i in range(len(x)):\n",
        "  plt.text(i, subject_scores[i], round(subject_scores[i],2), ha = 'center')\n",
        "  \n",
        "plt.title('CNN Model Test Accuracy for Each Subject')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('subject')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "xMNd3J5iEL1y",
        "outputId": "075d7ef7-fa83-4d77-d65a-ffc8a6aa8509"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsTQ2joUGKSA"
      },
      "source": [
        "## 3. Evaluate the classification accuracy as a function of time (e.g., does it increase as you have data over longer periods of time? how much time is required to get a reasonable classification accuracy?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuBtpN55GKSA"
      },
      "source": [
        "#### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2iytyE4xkrSN"
      },
      "outputs": [],
      "source": [
        "def data_prep_modular(X,y,sub_sample,average,noise, trim_ratio=0.5):\n",
        "    \n",
        "    total_X = None\n",
        "    total_y = None\n",
        "    \n",
        "    # Trimming the data (sample,22,1000) -> (sample,22,500)\n",
        "    X = X[:,:, 0:(int(X.shape[2] * trim_ratio))]\n",
        "    print('Shape of X after trimming:',X.shape)\n",
        "    \n",
        "    # Maxpooling the data (sample,22,1000) -> (sample,22,500/sub_sample)\n",
        "    X_max = np.max(X.reshape(X.shape[0], X.shape[1], -1, sub_sample), axis=3)\n",
        "    \n",
        "    \n",
        "    total_X = X_max\n",
        "    total_y = y\n",
        "    # print('Shape of X after maxpooling:',total_X.shape)\n",
        "    \n",
        "    # Averaging + noise \n",
        "    X_average = np.mean(X.reshape(X.shape[0], X.shape[1], -1, average), axis=3)\n",
        "    X_average = X_average + np.random.normal(0.0, 0.5, X_average.shape)\n",
        "    \n",
        "    total_X = np.vstack((total_X, X_average))\n",
        "    total_y = np.hstack((total_y, y))\n",
        "    # print('Shape of X after averaging+noise and concatenating:',total_X.shape)\n",
        "    \n",
        "    # Subsampling\n",
        "    \n",
        "    for i in range(sub_sample):\n",
        "        \n",
        "        X_subsample = X[:, :, i::sub_sample] + (np.random.normal(0.0, 0.5, X[:, :,i::sub_sample].shape) if noise else 0.0)\n",
        "        total_X = np.vstack((total_X, X_subsample))\n",
        "        total_y = np.hstack((total_y, y))\n",
        "        \n",
        "    \n",
        "    # print('Shape of X after subsampling and concatenating:',total_X.shape)\n",
        "    return total_X,total_y\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wZl8T00ZkrSO"
      },
      "outputs": [],
      "source": [
        "\n",
        "def preprocess_time(trim_ratio):\n",
        "    X_test = np.load(\"X_test.npy\")\n",
        "    y_test = np.load(\"y_test.npy\")\n",
        "    person_train_valid = np.load(\"person_train_valid.npy\")\n",
        "    X_train_valid = np.load(\"X_train_valid.npy\")\n",
        "    y_train_valid = np.load(\"y_train_valid.npy\")\n",
        "    person_test = np.load(\"person_test.npy\")\n",
        "\n",
        "    ## Adjusting the labels so that \n",
        "\n",
        "    # Cue onset left - 0\n",
        "    # Cue onset right - 1\n",
        "    # Cue onset foot - 2\n",
        "    # Cue onset tongue - 3\n",
        "\n",
        "    y_train_valid -= 769\n",
        "    y_test -= 769\n",
        "\n",
        "\n",
        "    # shuffle with 5 fold\n",
        "    indicies_valid = np.random.choice(X_train_valid.shape[0], X_train_valid.shape[0] // 5, replace=False)\n",
        "    indicies_train = np.array(list(set(range(X_train_valid.shape[0])).difference(set(indicies_valid))))\n",
        "\n",
        "    # Creating the training and validation sets using the generated indices\n",
        "    X_train, X_valid = X_train_valid[indicies_train], X_train_valid[indicies_valid] \n",
        "    y_train, y_valid = y_train_valid[indicies_train], y_train_valid[indicies_valid]\n",
        "\n",
        "\n",
        "\n",
        "    # Preprocessing the dataset\n",
        "    x_train,y_train = data_prep_modular(X_train,y_train,2,2,True, trim_ratio=trim_ratio)\n",
        "    x_valid,y_valid = data_prep_modular(X_valid,y_valid,2,2,True, trim_ratio=trim_ratio)\n",
        "    X_test_prep,y_test_prep = data_prep_modular(X_test,y_test,2,2,True, trim_ratio=trim_ratio)\n",
        "\n",
        "    print('Shape of training set:',x_train.shape)\n",
        "    print('Shape of validation set:',x_valid.shape)\n",
        "    print('Shape of training labels:',y_train.shape)\n",
        "    print('Shape of validation labels:',y_valid.shape)\n",
        "    print('Shape of testing set:',X_test_prep.shape)\n",
        "    print('Shape of testing labels:',y_test_prep.shape)\n",
        "\n",
        "    # Converting the labels to categorical variables for multiclass classification\n",
        "    y_train = to_categorical(y_train, 4)\n",
        "    y_valid = to_categorical(y_valid, 4)\n",
        "    y_test = to_categorical(y_test_prep, 4)\n",
        "    print('Shape of training labels after categorical conversion:',y_train.shape)\n",
        "    print('Shape of validation labels after categorical conversion:',y_valid.shape)\n",
        "    print('Shape of test labels after categorical conversion:',y_test.shape)\n",
        "\n",
        "    # Adding width of the segment to be 1\n",
        "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "    x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
        "    x_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n",
        "    print('Shape of training set after adding width info:',x_train.shape)\n",
        "    print('Shape of validation set after adding width info:',x_valid.shape)\n",
        "    print('Shape of test set after adding width info:',x_test.shape)\n",
        "\n",
        "    # Reshaping the training and validation dataset\n",
        "    x_train = np.swapaxes(x_train, 1,3)\n",
        "    x_train = np.swapaxes(x_train, 1,2)\n",
        "    x_valid = np.swapaxes(x_valid, 1,3)\n",
        "    x_valid = np.swapaxes(x_valid, 1,2)\n",
        "    x_test = np.swapaxes(x_test, 1,3)\n",
        "    x_test = np.swapaxes(x_test, 1,2)\n",
        "    print('Shape of training set after dimension reshaping:',x_train.shape)\n",
        "    print('Shape of validation set after dimension reshaping:',x_valid.shape)\n",
        "    print('Shape of test set after dimension reshaping:',x_test.shape)\n",
        "\n",
        "\n",
        "    return (x_train, y_train, x_valid, y_valid, x_test, y_test)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGpl_bA8GKSB"
      },
      "source": [
        "#### Model / Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5otg3iW9GKSB"
      },
      "outputs": [],
      "source": [
        "def cnn_model(trim_ratio):\n",
        "    learning_rate = 1e-3\n",
        "    epochs = 100\n",
        "    cnn_subject_model_optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    x_train, y_train, x_valid, y_valid, x_test, y_test = preprocess_time(trim_ratio=trim_ratio)\n",
        "\n",
        "    # Building the CNN model using sequential class\n",
        "    cnn = Sequential()\n",
        "\n",
        "    # Conv. block 1\n",
        "    cnn.add(Conv2D(filters=20, kernel_size=(5,1), padding='same', activation='elu', input_shape=(x_train.shape[1],1,22)))\n",
        "    cnn.add(MaxPooling2D(pool_size=(3,1), padding='same')) \n",
        "    cnn.add(BatchNormalization())\n",
        "    cnn.add(Dropout(0.5))\n",
        "\n",
        "    # Conv. block 2\n",
        "    cnn.add(Conv2D(filters=20, kernel_size=(15,1), padding='same', activation='elu'))\n",
        "    cnn.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
        "    cnn.add(BatchNormalization())\n",
        "    cnn.add(Dropout(0.5))\n",
        "\n",
        "    # Conv. block 3\n",
        "    cnn.add(Conv2D(filters=10, kernel_size=(10,1), padding='same', activation='elu'))\n",
        "    cnn.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
        "    cnn.add(BatchNormalization())\n",
        "    cnn.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "    # Output layer with Softmax activation\n",
        "    cnn.add(Flatten()) # Flattens the input\n",
        "    cnn.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
        "\n",
        "    cnn.compile(loss='categorical_crossentropy',\n",
        "                    optimizer=cnn_subject_model_optimizer,\n",
        "                    metrics=['accuracy'])\n",
        "    \n",
        "    cnn_training_results = cnn.fit(x_train,\n",
        "            y_train,\n",
        "            batch_size=64,\n",
        "            epochs=epochs,\n",
        "            validation_data=(x_valid, y_valid), verbose=True)\n",
        "    \n",
        "    cnn_test_score = cnn.evaluate(x_test, y_test, verbose=True)\n",
        "    print(f'Test Accuracy: {cnn_test_score[1]}')\n",
        "    return cnn, cnn_training_results, cnn_test_score\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqGCBWToGKSC"
      },
      "source": [
        "#### Training /Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "t1woeXr_GKSC",
        "outputId": "7606f8a8-08eb-4945-ca67-6d407128c25f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X after trimming: (1692, 22, 100)\n",
            "Shape of X after trimming: (423, 22, 100)\n",
            "Shape of X after trimming: (443, 22, 100)\n",
            "Shape of training set: (6768, 22, 50)\n",
            "Shape of validation set: (1692, 22, 50)\n",
            "Shape of training labels: (6768,)\n",
            "Shape of validation labels: (1692,)\n",
            "Shape of testing set: (1772, 22, 50)\n",
            "Shape of testing labels: (1772,)\n",
            "Shape of training labels after categorical conversion: (6768, 4)\n",
            "Shape of validation labels after categorical conversion: (1692, 4)\n",
            "Shape of test labels after categorical conversion: (1772, 4)\n",
            "Shape of training set after adding width info: (6768, 22, 50, 1)\n",
            "Shape of validation set after adding width info: (1692, 22, 50, 1)\n",
            "Shape of test set after adding width info: (1772, 22, 50, 1)\n",
            "Shape of training set after dimension reshaping: (6768, 50, 1, 22)\n",
            "Shape of validation set after dimension reshaping: (1692, 50, 1, 22)\n",
            "Shape of test set after dimension reshaping: (1772, 50, 1, 22)\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 1.9312 - accuracy: 0.2629 - val_loss: 1.4050 - val_accuracy: 0.3381\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 1.5891 - accuracy: 0.2893 - val_loss: 1.3466 - val_accuracy: 0.3387\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 1.4844 - accuracy: 0.3008 - val_loss: 1.3339 - val_accuracy: 0.3783\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.4156 - accuracy: 0.3234 - val_loss: 1.3213 - val_accuracy: 0.3889\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.3812 - accuracy: 0.3246 - val_loss: 1.3160 - val_accuracy: 0.3948\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 2s 14ms/step - loss: 1.3636 - accuracy: 0.3389 - val_loss: 1.3092 - val_accuracy: 0.4043\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.3324 - accuracy: 0.3667 - val_loss: 1.3011 - val_accuracy: 0.4374\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.3202 - accuracy: 0.3749 - val_loss: 1.3032 - val_accuracy: 0.4084\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 2s 21ms/step - loss: 1.3154 - accuracy: 0.3663 - val_loss: 1.2964 - val_accuracy: 0.4273\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 1.3038 - accuracy: 0.3825 - val_loss: 1.2830 - val_accuracy: 0.4391\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 1.2893 - accuracy: 0.3935 - val_loss: 1.2729 - val_accuracy: 0.4480\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.2769 - accuracy: 0.4037 - val_loss: 1.2636 - val_accuracy: 0.4545\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.2743 - accuracy: 0.4051 - val_loss: 1.2602 - val_accuracy: 0.4504\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 2s 14ms/step - loss: 1.2599 - accuracy: 0.4257 - val_loss: 1.2465 - val_accuracy: 0.4610\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 2s 14ms/step - loss: 1.2527 - accuracy: 0.4211 - val_loss: 1.2419 - val_accuracy: 0.4610\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 2s 14ms/step - loss: 1.2489 - accuracy: 0.4280 - val_loss: 1.2289 - val_accuracy: 0.4704\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 1.2294 - accuracy: 0.4441 - val_loss: 1.2364 - val_accuracy: 0.4793\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 1.2192 - accuracy: 0.4509 - val_loss: 1.2138 - val_accuracy: 0.4704\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 1.2087 - accuracy: 0.4634 - val_loss: 1.2184 - val_accuracy: 0.4764\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.2005 - accuracy: 0.4622 - val_loss: 1.2011 - val_accuracy: 0.4799\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.1942 - accuracy: 0.4755 - val_loss: 1.2047 - val_accuracy: 0.4923\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.1938 - accuracy: 0.4660 - val_loss: 1.2027 - val_accuracy: 0.4716\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.1871 - accuracy: 0.4738 - val_loss: 1.1830 - val_accuracy: 0.4994\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.1716 - accuracy: 0.4835 - val_loss: 1.1678 - val_accuracy: 0.5041\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.1650 - accuracy: 0.4953 - val_loss: 1.1578 - val_accuracy: 0.5071\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 2s 21ms/step - loss: 1.1647 - accuracy: 0.4934 - val_loss: 1.1588 - val_accuracy: 0.4982\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 1.1605 - accuracy: 0.4868 - val_loss: 1.1617 - val_accuracy: 0.4911\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 1.1472 - accuracy: 0.5044 - val_loss: 1.1501 - val_accuracy: 0.5083\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.1413 - accuracy: 0.4993 - val_loss: 1.1385 - val_accuracy: 0.4870\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.1379 - accuracy: 0.5059 - val_loss: 1.1371 - val_accuracy: 0.5047\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.1373 - accuracy: 0.5100 - val_loss: 1.1504 - val_accuracy: 0.4970\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 2s 14ms/step - loss: 1.1227 - accuracy: 0.5133 - val_loss: 1.1350 - val_accuracy: 0.5095\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.1139 - accuracy: 0.5102 - val_loss: 1.1292 - val_accuracy: 0.5012\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 1.1149 - accuracy: 0.5176 - val_loss: 1.1357 - val_accuracy: 0.4876\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 1.1114 - accuracy: 0.5207 - val_loss: 1.1180 - val_accuracy: 0.5035\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 2s 21ms/step - loss: 1.1149 - accuracy: 0.5210 - val_loss: 1.1272 - val_accuracy: 0.4976\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.0995 - accuracy: 0.5296 - val_loss: 1.1171 - val_accuracy: 0.5000\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.0898 - accuracy: 0.5306 - val_loss: 1.1143 - val_accuracy: 0.5041\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 2s 14ms/step - loss: 1.0897 - accuracy: 0.5318 - val_loss: 1.1059 - val_accuracy: 0.5035\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.0865 - accuracy: 0.5384 - val_loss: 1.1103 - val_accuracy: 0.5130\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.0788 - accuracy: 0.5396 - val_loss: 1.1081 - val_accuracy: 0.5154\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.0706 - accuracy: 0.5510 - val_loss: 1.1003 - val_accuracy: 0.4959\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 1.0824 - accuracy: 0.5384 - val_loss: 1.1091 - val_accuracy: 0.5160\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 1.0727 - accuracy: 0.5464 - val_loss: 1.1209 - val_accuracy: 0.4835\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.0722 - accuracy: 0.5430 - val_loss: 1.0944 - val_accuracy: 0.5189\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.0572 - accuracy: 0.5533 - val_loss: 1.1016 - val_accuracy: 0.5213\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 2s 14ms/step - loss: 1.0530 - accuracy: 0.5527 - val_loss: 1.1077 - val_accuracy: 0.5089\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.0668 - accuracy: 0.5493 - val_loss: 1.0957 - val_accuracy: 0.5035\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.0620 - accuracy: 0.5532 - val_loss: 1.0931 - val_accuracy: 0.5313\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.0573 - accuracy: 0.5556 - val_loss: 1.0977 - val_accuracy: 0.5165\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 2s 20ms/step - loss: 1.0492 - accuracy: 0.5597 - val_loss: 1.0887 - val_accuracy: 0.5136\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 2s 22ms/step - loss: 1.0402 - accuracy: 0.5550 - val_loss: 1.0960 - val_accuracy: 0.5136\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 2s 19ms/step - loss: 1.0393 - accuracy: 0.5570 - val_loss: 1.1017 - val_accuracy: 0.5100\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.0394 - accuracy: 0.5592 - val_loss: 1.0814 - val_accuracy: 0.4965\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.0461 - accuracy: 0.5591 - val_loss: 1.0823 - val_accuracy: 0.5213\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.0348 - accuracy: 0.5677 - val_loss: 1.0831 - val_accuracy: 0.5142\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 2s 14ms/step - loss: 1.0211 - accuracy: 0.5730 - val_loss: 1.0817 - val_accuracy: 0.5142\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.0161 - accuracy: 0.5730 - val_loss: 1.0851 - val_accuracy: 0.5142\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.0314 - accuracy: 0.5724 - val_loss: 1.1018 - val_accuracy: 0.4917\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 1.0255 - accuracy: 0.5687 - val_loss: 1.0954 - val_accuracy: 0.5035\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 1.0286 - accuracy: 0.5677 - val_loss: 1.0796 - val_accuracy: 0.5160\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.0243 - accuracy: 0.5714 - val_loss: 1.0995 - val_accuracy: 0.4965\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 2s 14ms/step - loss: 1.0243 - accuracy: 0.5686 - val_loss: 1.1005 - val_accuracy: 0.5065\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.0261 - accuracy: 0.5665 - val_loss: 1.0773 - val_accuracy: 0.5160\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 2s 14ms/step - loss: 1.0155 - accuracy: 0.5723 - val_loss: 1.1002 - val_accuracy: 0.5154\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.0145 - accuracy: 0.5749 - val_loss: 1.0886 - val_accuracy: 0.5272\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.0147 - accuracy: 0.5789 - val_loss: 1.0858 - val_accuracy: 0.5059\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 2s 21ms/step - loss: 1.0096 - accuracy: 0.5799 - val_loss: 1.0799 - val_accuracy: 0.5177\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 1.0044 - accuracy: 0.5845 - val_loss: 1.0710 - val_accuracy: 0.5296\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 2s 17ms/step - loss: 1.0089 - accuracy: 0.5767 - val_loss: 1.0868 - val_accuracy: 0.5177\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.0102 - accuracy: 0.5792 - val_loss: 1.0719 - val_accuracy: 0.5225\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 2s 14ms/step - loss: 1.0158 - accuracy: 0.5745 - val_loss: 1.1097 - val_accuracy: 0.5071\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.0017 - accuracy: 0.5923 - val_loss: 1.0907 - val_accuracy: 0.5053\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.9857 - accuracy: 0.5839 - val_loss: 1.0944 - val_accuracy: 0.5136\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.9974 - accuracy: 0.5829 - val_loss: 1.0686 - val_accuracy: 0.5278\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 2s 18ms/step - loss: 1.0019 - accuracy: 0.5884 - val_loss: 1.0725 - val_accuracy: 0.5142\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 0.9997 - accuracy: 0.5891 - val_loss: 1.0759 - val_accuracy: 0.5177\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 2s 20ms/step - loss: 0.9869 - accuracy: 0.5847 - val_loss: 1.0738 - val_accuracy: 0.5290\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.9885 - accuracy: 0.5906 - val_loss: 1.0790 - val_accuracy: 0.5325\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.9882 - accuracy: 0.5872 - val_loss: 1.0871 - val_accuracy: 0.5290\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.9879 - accuracy: 0.5836 - val_loss: 1.1048 - val_accuracy: 0.5041\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 1.0013 - accuracy: 0.5839 - val_loss: 1.0763 - val_accuracy: 0.5100\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.9950 - accuracy: 0.5879 - val_loss: 1.0869 - val_accuracy: 0.5136\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.9748 - accuracy: 0.5978 - val_loss: 1.0749 - val_accuracy: 0.5260\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 2s 22ms/step - loss: 0.9958 - accuracy: 0.5845 - val_loss: 1.1054 - val_accuracy: 0.5148\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 0.9698 - accuracy: 0.6034 - val_loss: 1.0909 - val_accuracy: 0.5053\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 2s 16ms/step - loss: 0.9798 - accuracy: 0.5935 - val_loss: 1.0839 - val_accuracy: 0.5325\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.9830 - accuracy: 0.5867 - val_loss: 1.0808 - val_accuracy: 0.5290\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.9806 - accuracy: 0.5943 - val_loss: 1.0856 - val_accuracy: 0.5313\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 2s 14ms/step - loss: 0.9746 - accuracy: 0.5983 - val_loss: 1.0933 - val_accuracy: 0.5236\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 2s 14ms/step - loss: 0.9799 - accuracy: 0.5909 - val_loss: 1.0801 - val_accuracy: 0.5041\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.9713 - accuracy: 0.6024 - val_loss: 1.0983 - val_accuracy: 0.5290\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 2s 20ms/step - loss: 0.9837 - accuracy: 0.5888 - val_loss: 1.0818 - val_accuracy: 0.5171\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 0.9835 - accuracy: 0.5956 - val_loss: 1.0892 - val_accuracy: 0.5136\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 2s 19ms/step - loss: 0.9757 - accuracy: 0.5968 - val_loss: 1.0678 - val_accuracy: 0.5219\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.9662 - accuracy: 0.5991 - val_loss: 1.0686 - val_accuracy: 0.5071\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.9763 - accuracy: 0.5953 - val_loss: 1.0668 - val_accuracy: 0.5242\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.9831 - accuracy: 0.5944 - val_loss: 1.0879 - val_accuracy: 0.5071\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.9790 - accuracy: 0.5965 - val_loss: 1.0682 - val_accuracy: 0.5230\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 2s 15ms/step - loss: 0.9786 - accuracy: 0.5977 - val_loss: 1.0747 - val_accuracy: 0.5130\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 1.0549 - accuracy: 0.5581\n",
            "Test Accuracy: 0.5581263899803162\n",
            "Shape of X after trimming: (1692, 22, 200)\n",
            "Shape of X after trimming: (423, 22, 200)\n",
            "Shape of X after trimming: (443, 22, 200)\n",
            "Shape of training set: (6768, 22, 100)\n",
            "Shape of validation set: (1692, 22, 100)\n",
            "Shape of training labels: (6768,)\n",
            "Shape of validation labels: (1692,)\n",
            "Shape of testing set: (1772, 22, 100)\n",
            "Shape of testing labels: (1772,)\n",
            "Shape of training labels after categorical conversion: (6768, 4)\n",
            "Shape of validation labels after categorical conversion: (1692, 4)\n",
            "Shape of test labels after categorical conversion: (1772, 4)\n",
            "Shape of training set after adding width info: (6768, 22, 100, 1)\n",
            "Shape of validation set after adding width info: (1692, 22, 100, 1)\n",
            "Shape of test set after adding width info: (1772, 22, 100, 1)\n",
            "Shape of training set after dimension reshaping: (6768, 100, 1, 22)\n",
            "Shape of validation set after dimension reshaping: (1692, 100, 1, 22)\n",
            "Shape of test set after dimension reshaping: (1772, 100, 1, 22)\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 4s 29ms/step - loss: 2.0067 - accuracy: 0.2730 - val_loss: 1.4385 - val_accuracy: 0.3387\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 1.6406 - accuracy: 0.2937 - val_loss: 1.3559 - val_accuracy: 0.3505\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 1.4886 - accuracy: 0.3174 - val_loss: 1.3290 - val_accuracy: 0.3570\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 1.4252 - accuracy: 0.3261 - val_loss: 1.3166 - val_accuracy: 0.3700\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 4s 34ms/step - loss: 1.3705 - accuracy: 0.3471 - val_loss: 1.3131 - val_accuracy: 0.3694\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 1.3410 - accuracy: 0.3641 - val_loss: 1.2977 - val_accuracy: 0.3853\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 1.3150 - accuracy: 0.3833 - val_loss: 1.2905 - val_accuracy: 0.4125\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 1.3042 - accuracy: 0.3944 - val_loss: 1.2560 - val_accuracy: 0.4415\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 1.2804 - accuracy: 0.4069 - val_loss: 1.2317 - val_accuracy: 0.4716\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 3s 29ms/step - loss: 1.2609 - accuracy: 0.4341 - val_loss: 1.2162 - val_accuracy: 0.4840\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 4s 35ms/step - loss: 1.2484 - accuracy: 0.4301 - val_loss: 1.1884 - val_accuracy: 0.4823\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 1.2356 - accuracy: 0.4439 - val_loss: 1.1756 - val_accuracy: 0.4923\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 1.2168 - accuracy: 0.4514 - val_loss: 1.1575 - val_accuracy: 0.5130\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 1.2031 - accuracy: 0.4679 - val_loss: 1.1516 - val_accuracy: 0.5100\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 1.2046 - accuracy: 0.4719 - val_loss: 1.1471 - val_accuracy: 0.5213\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 4s 39ms/step - loss: 1.1831 - accuracy: 0.4845 - val_loss: 1.1180 - val_accuracy: 0.5408\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 1.1777 - accuracy: 0.4756 - val_loss: 1.1087 - val_accuracy: 0.5325\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 1.1702 - accuracy: 0.4907 - val_loss: 1.1122 - val_accuracy: 0.5290\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 1.1622 - accuracy: 0.4972 - val_loss: 1.1039 - val_accuracy: 0.5331\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 1.1382 - accuracy: 0.5124 - val_loss: 1.0736 - val_accuracy: 0.5431\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 4s 37ms/step - loss: 1.1474 - accuracy: 0.4990 - val_loss: 1.0697 - val_accuracy: 0.5520\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 3s 27ms/step - loss: 1.1383 - accuracy: 0.5130 - val_loss: 1.1195 - val_accuracy: 0.5095\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 1.1342 - accuracy: 0.5115 - val_loss: 1.0725 - val_accuracy: 0.5396\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 2s 22ms/step - loss: 1.1154 - accuracy: 0.5214 - val_loss: 1.0507 - val_accuracy: 0.5644\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 1.1095 - accuracy: 0.5236 - val_loss: 1.0930 - val_accuracy: 0.5366\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 1.0966 - accuracy: 0.5294 - val_loss: 1.0450 - val_accuracy: 0.5786\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 3s 28ms/step - loss: 1.0928 - accuracy: 0.5306 - val_loss: 1.0388 - val_accuracy: 0.5573\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 1.0925 - accuracy: 0.5263 - val_loss: 1.0233 - val_accuracy: 0.5715\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 2s 22ms/step - loss: 1.0841 - accuracy: 0.5421 - val_loss: 1.0187 - val_accuracy: 0.5650\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 2s 22ms/step - loss: 1.0568 - accuracy: 0.5499 - val_loss: 1.0512 - val_accuracy: 0.5544\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 1.0612 - accuracy: 0.5486 - val_loss: 1.0275 - val_accuracy: 0.5579\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 3s 29ms/step - loss: 1.0581 - accuracy: 0.5539 - val_loss: 1.0260 - val_accuracy: 0.5822\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 1.0535 - accuracy: 0.5576 - val_loss: 1.0043 - val_accuracy: 0.5691\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 1.0415 - accuracy: 0.5637 - val_loss: 1.0363 - val_accuracy: 0.5638\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 2s 22ms/step - loss: 1.0388 - accuracy: 0.5613 - val_loss: 0.9670 - val_accuracy: 0.6141\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 3s 28ms/step - loss: 1.0470 - accuracy: 0.5569 - val_loss: 0.9702 - val_accuracy: 0.6129\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 1.0180 - accuracy: 0.5733 - val_loss: 1.0046 - val_accuracy: 0.5668\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 2s 22ms/step - loss: 1.0134 - accuracy: 0.5829 - val_loss: 0.9782 - val_accuracy: 0.5922\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 1.0251 - accuracy: 0.5714 - val_loss: 0.9609 - val_accuracy: 0.5916\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 1.0147 - accuracy: 0.5752 - val_loss: 0.9569 - val_accuracy: 0.5963\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 3s 27ms/step - loss: 0.9960 - accuracy: 0.5878 - val_loss: 0.9605 - val_accuracy: 0.6022\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 1.0086 - accuracy: 0.5712 - val_loss: 0.9632 - val_accuracy: 0.5987\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 0.9968 - accuracy: 0.5833 - val_loss: 0.9550 - val_accuracy: 0.5934\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 2s 22ms/step - loss: 0.9965 - accuracy: 0.5804 - val_loss: 0.9660 - val_accuracy: 0.5993\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 0.9830 - accuracy: 0.5894 - val_loss: 0.9487 - val_accuracy: 0.5999\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.9948 - accuracy: 0.5857 - val_loss: 0.9368 - val_accuracy: 0.6064\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 4s 34ms/step - loss: 0.9811 - accuracy: 0.6003 - val_loss: 0.9654 - val_accuracy: 0.5898\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 2s 22ms/step - loss: 0.9886 - accuracy: 0.5892 - val_loss: 0.9539 - val_accuracy: 0.6046\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 0.9692 - accuracy: 0.6033 - val_loss: 0.9351 - val_accuracy: 0.5928\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 2s 22ms/step - loss: 0.9602 - accuracy: 0.6074 - val_loss: 0.9373 - val_accuracy: 0.5999\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 0.9799 - accuracy: 0.5894 - val_loss: 0.9314 - val_accuracy: 0.6017\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 4s 36ms/step - loss: 0.9678 - accuracy: 0.6039 - val_loss: 0.9217 - val_accuracy: 0.6371\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 0.9856 - accuracy: 0.5904 - val_loss: 0.9355 - val_accuracy: 0.5952\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 0.9640 - accuracy: 0.6045 - val_loss: 0.9254 - val_accuracy: 0.6005\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 0.9531 - accuracy: 0.6110 - val_loss: 0.9107 - val_accuracy: 0.6158\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 0.9510 - accuracy: 0.6040 - val_loss: 0.9709 - val_accuracy: 0.5662\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 4s 37ms/step - loss: 0.9536 - accuracy: 0.6117 - val_loss: 0.9195 - val_accuracy: 0.6005\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 0.9590 - accuracy: 0.6056 - val_loss: 0.9132 - val_accuracy: 0.6200\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 0.9534 - accuracy: 0.6092 - val_loss: 0.9319 - val_accuracy: 0.6022\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 0.9407 - accuracy: 0.6124 - val_loss: 0.9359 - val_accuracy: 0.6058\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 0.9316 - accuracy: 0.6188 - val_loss: 0.9284 - val_accuracy: 0.6082\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 4s 38ms/step - loss: 0.9401 - accuracy: 0.6108 - val_loss: 0.9356 - val_accuracy: 0.5969\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.9368 - accuracy: 0.6155 - val_loss: 0.9200 - val_accuracy: 0.6152\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 0.9251 - accuracy: 0.6249 - val_loss: 0.9088 - val_accuracy: 0.6111\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 2s 24ms/step - loss: 0.9255 - accuracy: 0.6209 - val_loss: 0.9360 - val_accuracy: 0.5999\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 0.9303 - accuracy: 0.6207 - val_loss: 0.9212 - val_accuracy: 0.6052\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 4s 38ms/step - loss: 0.9288 - accuracy: 0.6291 - val_loss: 0.9008 - val_accuracy: 0.6235\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 0.9257 - accuracy: 0.6216 - val_loss: 0.8986 - val_accuracy: 0.6401\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 0.9311 - accuracy: 0.6157 - val_loss: 0.9238 - val_accuracy: 0.6034\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 0.9140 - accuracy: 0.6283 - val_loss: 0.9303 - val_accuracy: 0.6070\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 2s 24ms/step - loss: 0.9139 - accuracy: 0.6249 - val_loss: 0.8970 - val_accuracy: 0.6353\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 4s 37ms/step - loss: 0.9205 - accuracy: 0.6247 - val_loss: 0.8963 - val_accuracy: 0.6135\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 0.9182 - accuracy: 0.6277 - val_loss: 0.8981 - val_accuracy: 0.6395\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.9123 - accuracy: 0.6257 - val_loss: 0.8955 - val_accuracy: 0.6247\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 2s 24ms/step - loss: 0.9024 - accuracy: 0.6257 - val_loss: 0.8948 - val_accuracy: 0.6158\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 0.8996 - accuracy: 0.6374 - val_loss: 0.8989 - val_accuracy: 0.6141\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 4s 38ms/step - loss: 0.9229 - accuracy: 0.6161 - val_loss: 0.9008 - val_accuracy: 0.6223\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 0.9102 - accuracy: 0.6308 - val_loss: 0.8888 - val_accuracy: 0.6265\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 0.8963 - accuracy: 0.6389 - val_loss: 0.8939 - val_accuracy: 0.6259\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 0.9069 - accuracy: 0.6294 - val_loss: 0.9052 - val_accuracy: 0.6164\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 0.9112 - accuracy: 0.6280 - val_loss: 0.9070 - val_accuracy: 0.6271\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 4s 37ms/step - loss: 0.8953 - accuracy: 0.6387 - val_loss: 0.8983 - val_accuracy: 0.6229\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 0.9094 - accuracy: 0.6368 - val_loss: 0.8931 - val_accuracy: 0.6158\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 0.9036 - accuracy: 0.6337 - val_loss: 0.8815 - val_accuracy: 0.6383\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 2s 24ms/step - loss: 0.8954 - accuracy: 0.6370 - val_loss: 0.8928 - val_accuracy: 0.6217\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 0.9000 - accuracy: 0.6376 - val_loss: 0.9022 - val_accuracy: 0.6371\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 4s 36ms/step - loss: 0.8850 - accuracy: 0.6410 - val_loss: 0.9091 - val_accuracy: 0.6093\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.9062 - accuracy: 0.6327 - val_loss: 0.8805 - val_accuracy: 0.6371\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 0.8950 - accuracy: 0.6399 - val_loss: 0.8851 - val_accuracy: 0.6371\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 0.8833 - accuracy: 0.6402 - val_loss: 0.9078 - val_accuracy: 0.6348\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.8788 - accuracy: 0.6393 - val_loss: 0.8805 - val_accuracy: 0.6454\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 4s 36ms/step - loss: 0.8960 - accuracy: 0.6318 - val_loss: 0.8874 - val_accuracy: 0.6348\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.8550 - accuracy: 0.6517 - val_loss: 0.8791 - val_accuracy: 0.6519\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 0.9011 - accuracy: 0.6297 - val_loss: 0.9113 - val_accuracy: 0.6070\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 0.8794 - accuracy: 0.6411 - val_loss: 0.8823 - val_accuracy: 0.6407\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 0.8951 - accuracy: 0.6374 - val_loss: 0.9241 - val_accuracy: 0.6129\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 4s 36ms/step - loss: 0.8925 - accuracy: 0.6305 - val_loss: 0.8949 - val_accuracy: 0.6330\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.8831 - accuracy: 0.6439 - val_loss: 0.9210 - val_accuracy: 0.6217\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 0.8683 - accuracy: 0.6467 - val_loss: 0.9035 - val_accuracy: 0.6217\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.8817 - accuracy: 0.6451 - val_loss: 0.9054 - val_accuracy: 0.6164\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.9226 - accuracy: 0.6332\n",
            "Test Accuracy: 0.6331828236579895\n",
            "Shape of X after trimming: (1692, 22, 300)\n",
            "Shape of X after trimming: (423, 22, 300)\n",
            "Shape of X after trimming: (443, 22, 300)\n",
            "Shape of training set: (6768, 22, 150)\n",
            "Shape of validation set: (1692, 22, 150)\n",
            "Shape of training labels: (6768,)\n",
            "Shape of validation labels: (1692,)\n",
            "Shape of testing set: (1772, 22, 150)\n",
            "Shape of testing labels: (1772,)\n",
            "Shape of training labels after categorical conversion: (6768, 4)\n",
            "Shape of validation labels after categorical conversion: (1692, 4)\n",
            "Shape of test labels after categorical conversion: (1772, 4)\n",
            "Shape of training set after adding width info: (6768, 22, 150, 1)\n",
            "Shape of validation set after adding width info: (1692, 22, 150, 1)\n",
            "Shape of test set after adding width info: (1772, 22, 150, 1)\n",
            "Shape of training set after dimension reshaping: (6768, 150, 1, 22)\n",
            "Shape of validation set after dimension reshaping: (1692, 150, 1, 22)\n",
            "Shape of test set after dimension reshaping: (1772, 150, 1, 22)\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 5s 44ms/step - loss: 1.9392 - accuracy: 0.2804 - val_loss: 1.4066 - val_accuracy: 0.3268\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 4s 38ms/step - loss: 1.6116 - accuracy: 0.2937 - val_loss: 1.3507 - val_accuracy: 0.3422\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 3s 33ms/step - loss: 1.4691 - accuracy: 0.3079 - val_loss: 1.3332 - val_accuracy: 0.3605\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 1.3910 - accuracy: 0.3280 - val_loss: 1.3119 - val_accuracy: 0.3901\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 1.3372 - accuracy: 0.3710 - val_loss: 1.2813 - val_accuracy: 0.4155\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 1.3028 - accuracy: 0.3920 - val_loss: 1.2474 - val_accuracy: 0.4504\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 1.2643 - accuracy: 0.4252 - val_loss: 1.2224 - val_accuracy: 0.4504\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 4s 36ms/step - loss: 1.2343 - accuracy: 0.4456 - val_loss: 1.1854 - val_accuracy: 0.4894\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 5s 43ms/step - loss: 1.2145 - accuracy: 0.4557 - val_loss: 1.1667 - val_accuracy: 0.5236\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 4s 34ms/step - loss: 1.1911 - accuracy: 0.4778 - val_loss: 1.1413 - val_accuracy: 0.5124\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 3s 33ms/step - loss: 1.1731 - accuracy: 0.4849 - val_loss: 1.1097 - val_accuracy: 0.5177\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 5s 45ms/step - loss: 1.1566 - accuracy: 0.4965 - val_loss: 1.0864 - val_accuracy: 0.5408\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 4s 35ms/step - loss: 1.1477 - accuracy: 0.5041 - val_loss: 1.1148 - val_accuracy: 0.5420\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 3s 33ms/step - loss: 1.1208 - accuracy: 0.5134 - val_loss: 1.0797 - val_accuracy: 0.5426\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 3s 33ms/step - loss: 1.1029 - accuracy: 0.5281 - val_loss: 1.0588 - val_accuracy: 0.5443\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 5s 48ms/step - loss: 1.0889 - accuracy: 0.5337 - val_loss: 1.0557 - val_accuracy: 0.5449\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 3s 33ms/step - loss: 1.0839 - accuracy: 0.5399 - val_loss: 1.0308 - val_accuracy: 0.5644\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 4s 33ms/step - loss: 1.0652 - accuracy: 0.5474 - val_loss: 1.0256 - val_accuracy: 0.5709\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 5s 43ms/step - loss: 1.0582 - accuracy: 0.5507 - val_loss: 1.0077 - val_accuracy: 0.5916\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 4s 38ms/step - loss: 1.0657 - accuracy: 0.5488 - val_loss: 1.0051 - val_accuracy: 0.5762\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 4s 33ms/step - loss: 1.0393 - accuracy: 0.5613 - val_loss: 0.9990 - val_accuracy: 0.5875\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 3s 33ms/step - loss: 1.0319 - accuracy: 0.5646 - val_loss: 0.9909 - val_accuracy: 0.5946\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 5s 48ms/step - loss: 1.0124 - accuracy: 0.5777 - val_loss: 0.9674 - val_accuracy: 0.5987\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 4s 33ms/step - loss: 1.0094 - accuracy: 0.5705 - val_loss: 0.9592 - val_accuracy: 0.6040\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 4s 33ms/step - loss: 1.0040 - accuracy: 0.5829 - val_loss: 0.9387 - val_accuracy: 0.6158\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 4s 39ms/step - loss: 0.9985 - accuracy: 0.5793 - val_loss: 0.9306 - val_accuracy: 0.6330\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 0.9805 - accuracy: 0.5913 - val_loss: 0.9180 - val_accuracy: 0.6306\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 3s 33ms/step - loss: 0.9779 - accuracy: 0.5932 - val_loss: 0.9256 - val_accuracy: 0.6342\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 3s 33ms/step - loss: 0.9570 - accuracy: 0.6082 - val_loss: 0.9161 - val_accuracy: 0.6336\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 0.9638 - accuracy: 0.5987 - val_loss: 0.9288 - val_accuracy: 0.6105\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 4s 34ms/step - loss: 0.9534 - accuracy: 0.6064 - val_loss: 0.9076 - val_accuracy: 0.6336\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 4s 33ms/step - loss: 0.9476 - accuracy: 0.6074 - val_loss: 0.9028 - val_accuracy: 0.6460\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 4s 37ms/step - loss: 0.9430 - accuracy: 0.6053 - val_loss: 0.8953 - val_accuracy: 0.6365\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 5s 44ms/step - loss: 0.9327 - accuracy: 0.6151 - val_loss: 0.8972 - val_accuracy: 0.6330\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 3s 33ms/step - loss: 0.9243 - accuracy: 0.6217 - val_loss: 0.9026 - val_accuracy: 0.6170\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 3s 33ms/step - loss: 0.9207 - accuracy: 0.6229 - val_loss: 0.8764 - val_accuracy: 0.6548\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 5s 46ms/step - loss: 0.9354 - accuracy: 0.6158 - val_loss: 0.8755 - val_accuracy: 0.6495\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 4s 36ms/step - loss: 0.9097 - accuracy: 0.6299 - val_loss: 0.8901 - val_accuracy: 0.6253\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 4s 33ms/step - loss: 0.9016 - accuracy: 0.6288 - val_loss: 0.8881 - val_accuracy: 0.6353\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 4s 34ms/step - loss: 0.8980 - accuracy: 0.6333 - val_loss: 0.8857 - val_accuracy: 0.6418\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 0.8755 - accuracy: 0.6423 - val_loss: 0.8667 - val_accuracy: 0.6466\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 4s 33ms/step - loss: 0.8932 - accuracy: 0.6361 - val_loss: 0.8821 - val_accuracy: 0.6377\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 4s 33ms/step - loss: 0.8724 - accuracy: 0.6473 - val_loss: 0.8586 - val_accuracy: 0.6643\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 0.8803 - accuracy: 0.6427 - val_loss: 0.8750 - val_accuracy: 0.6513\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 4s 39ms/step - loss: 0.8566 - accuracy: 0.6520 - val_loss: 0.8755 - val_accuracy: 0.6519\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 4s 33ms/step - loss: 0.8783 - accuracy: 0.6399 - val_loss: 0.8811 - val_accuracy: 0.6365\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 4s 33ms/step - loss: 0.8666 - accuracy: 0.6441 - val_loss: 0.8612 - val_accuracy: 0.6454\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 5s 48ms/step - loss: 0.8618 - accuracy: 0.6512 - val_loss: 0.8517 - val_accuracy: 0.6554\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 4s 34ms/step - loss: 0.8614 - accuracy: 0.6447 - val_loss: 0.8578 - val_accuracy: 0.6424\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 4s 33ms/step - loss: 0.8557 - accuracy: 0.6550 - val_loss: 0.8481 - val_accuracy: 0.6702\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 4s 38ms/step - loss: 0.8634 - accuracy: 0.6390 - val_loss: 0.8646 - val_accuracy: 0.6478\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 5s 44ms/step - loss: 0.8580 - accuracy: 0.6551 - val_loss: 0.8575 - val_accuracy: 0.6578\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 4s 33ms/step - loss: 0.8529 - accuracy: 0.6569 - val_loss: 0.8523 - val_accuracy: 0.6590\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 4s 33ms/step - loss: 0.8469 - accuracy: 0.6593 - val_loss: 0.8437 - val_accuracy: 0.6543\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 0.8448 - accuracy: 0.6556 - val_loss: 0.8640 - val_accuracy: 0.6608\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 4s 35ms/step - loss: 0.8339 - accuracy: 0.6683 - val_loss: 0.8527 - val_accuracy: 0.6401\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 4s 33ms/step - loss: 0.8456 - accuracy: 0.6559 - val_loss: 0.8579 - val_accuracy: 0.6501\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 4s 37ms/step - loss: 0.8402 - accuracy: 0.6574 - val_loss: 0.8488 - val_accuracy: 0.6501\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 5s 44ms/step - loss: 0.8282 - accuracy: 0.6619 - val_loss: 0.8529 - val_accuracy: 0.6407\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 4s 33ms/step - loss: 0.8371 - accuracy: 0.6587 - val_loss: 0.8422 - val_accuracy: 0.6560\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 4s 33ms/step - loss: 0.8321 - accuracy: 0.6619 - val_loss: 0.8451 - val_accuracy: 0.6543\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 5s 45ms/step - loss: 0.8386 - accuracy: 0.6584 - val_loss: 0.8422 - val_accuracy: 0.6596\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 4s 38ms/step - loss: 0.8325 - accuracy: 0.6575 - val_loss: 0.8533 - val_accuracy: 0.6472\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 4s 34ms/step - loss: 0.8316 - accuracy: 0.6652 - val_loss: 0.8416 - val_accuracy: 0.6566\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 4s 33ms/step - loss: 0.8286 - accuracy: 0.6704 - val_loss: 0.8476 - val_accuracy: 0.6619\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 5s 49ms/step - loss: 0.8137 - accuracy: 0.6760 - val_loss: 0.8642 - val_accuracy: 0.6495\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 4s 34ms/step - loss: 0.8201 - accuracy: 0.6723 - val_loss: 0.8381 - val_accuracy: 0.6608\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 4s 34ms/step - loss: 0.8199 - accuracy: 0.6690 - val_loss: 0.8529 - val_accuracy: 0.6495\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 5s 43ms/step - loss: 0.8141 - accuracy: 0.6658 - val_loss: 0.8349 - val_accuracy: 0.6513\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 4s 40ms/step - loss: 0.8036 - accuracy: 0.6752 - val_loss: 0.8389 - val_accuracy: 0.6578\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 4s 34ms/step - loss: 0.8150 - accuracy: 0.6658 - val_loss: 0.8560 - val_accuracy: 0.6548\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 4s 34ms/step - loss: 0.8104 - accuracy: 0.6743 - val_loss: 0.8607 - val_accuracy: 0.6513\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 5s 50ms/step - loss: 0.8045 - accuracy: 0.6665 - val_loss: 0.8371 - val_accuracy: 0.6613\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 4s 35ms/step - loss: 0.8156 - accuracy: 0.6677 - val_loss: 0.8324 - val_accuracy: 0.6667\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 4s 34ms/step - loss: 0.8036 - accuracy: 0.6758 - val_loss: 0.8606 - val_accuracy: 0.6395\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 0.8007 - accuracy: 0.6735 - val_loss: 0.8323 - val_accuracy: 0.6708\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 4s 41ms/step - loss: 0.7894 - accuracy: 0.6826 - val_loss: 0.8414 - val_accuracy: 0.6673\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 4s 33ms/step - loss: 0.8004 - accuracy: 0.6732 - val_loss: 0.8406 - val_accuracy: 0.6643\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 4s 34ms/step - loss: 0.8030 - accuracy: 0.6758 - val_loss: 0.8286 - val_accuracy: 0.6767\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 5s 50ms/step - loss: 0.7986 - accuracy: 0.6776 - val_loss: 0.8365 - val_accuracy: 0.6732\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 4s 33ms/step - loss: 0.7887 - accuracy: 0.6844 - val_loss: 0.8237 - val_accuracy: 0.6856\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 4s 33ms/step - loss: 0.7824 - accuracy: 0.6860 - val_loss: 0.8353 - val_accuracy: 0.6749\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 4s 39ms/step - loss: 0.7770 - accuracy: 0.6896 - val_loss: 0.8494 - val_accuracy: 0.6513\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 5s 44ms/step - loss: 0.7919 - accuracy: 0.6848 - val_loss: 0.8223 - val_accuracy: 0.6738\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 4s 34ms/step - loss: 0.7859 - accuracy: 0.6785 - val_loss: 0.8312 - val_accuracy: 0.6667\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 4s 33ms/step - loss: 0.7893 - accuracy: 0.6866 - val_loss: 0.8198 - val_accuracy: 0.6738\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 5s 46ms/step - loss: 0.8040 - accuracy: 0.6769 - val_loss: 0.8371 - val_accuracy: 0.6483\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 4s 37ms/step - loss: 0.7864 - accuracy: 0.6822 - val_loss: 0.8337 - val_accuracy: 0.6519\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 4s 34ms/step - loss: 0.7836 - accuracy: 0.6882 - val_loss: 0.8038 - val_accuracy: 0.6761\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 4s 38ms/step - loss: 0.7929 - accuracy: 0.6785 - val_loss: 0.8540 - val_accuracy: 0.6489\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 5s 45ms/step - loss: 0.7873 - accuracy: 0.6891 - val_loss: 0.8519 - val_accuracy: 0.6543\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 4s 34ms/step - loss: 0.7747 - accuracy: 0.6874 - val_loss: 0.8331 - val_accuracy: 0.6738\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 4s 34ms/step - loss: 0.7729 - accuracy: 0.6934 - val_loss: 0.8369 - val_accuracy: 0.6785\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 5s 49ms/step - loss: 0.7724 - accuracy: 0.6978 - val_loss: 0.8554 - val_accuracy: 0.6578\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 4s 34ms/step - loss: 0.7913 - accuracy: 0.6850 - val_loss: 0.8294 - val_accuracy: 0.6631\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 4s 34ms/step - loss: 0.7834 - accuracy: 0.6831 - val_loss: 0.8525 - val_accuracy: 0.6548\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 4s 41ms/step - loss: 0.7772 - accuracy: 0.6850 - val_loss: 0.8370 - val_accuracy: 0.6507\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 5s 43ms/step - loss: 0.7755 - accuracy: 0.6910 - val_loss: 0.8389 - val_accuracy: 0.6637\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 4s 34ms/step - loss: 0.7856 - accuracy: 0.6820 - val_loss: 0.8363 - val_accuracy: 0.6643\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 4s 34ms/step - loss: 0.7671 - accuracy: 0.6924 - val_loss: 0.8316 - val_accuracy: 0.6596\n",
            "56/56 [==============================] - 0s 6ms/step - loss: 0.7862 - accuracy: 0.6902\n",
            "Test Accuracy: 0.6901805996894836\n",
            "Shape of X after trimming: (1692, 22, 400)\n",
            "Shape of X after trimming: (423, 22, 400)\n",
            "Shape of X after trimming: (443, 22, 400)\n",
            "Shape of training set: (6768, 22, 200)\n",
            "Shape of validation set: (1692, 22, 200)\n",
            "Shape of training labels: (6768,)\n",
            "Shape of validation labels: (1692,)\n",
            "Shape of testing set: (1772, 22, 200)\n",
            "Shape of testing labels: (1772,)\n",
            "Shape of training labels after categorical conversion: (6768, 4)\n",
            "Shape of validation labels after categorical conversion: (1692, 4)\n",
            "Shape of test labels after categorical conversion: (1772, 4)\n",
            "Shape of training set after adding width info: (6768, 22, 200, 1)\n",
            "Shape of validation set after adding width info: (1692, 22, 200, 1)\n",
            "Shape of test set after adding width info: (1772, 22, 200, 1)\n",
            "Shape of training set after dimension reshaping: (6768, 200, 1, 22)\n",
            "Shape of validation set after dimension reshaping: (1692, 200, 1, 22)\n",
            "Shape of test set after dimension reshaping: (1772, 200, 1, 22)\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 5s 43ms/step - loss: 2.0103 - accuracy: 0.2775 - val_loss: 1.4233 - val_accuracy: 0.3227\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 5s 48ms/step - loss: 1.6161 - accuracy: 0.3107 - val_loss: 1.3382 - val_accuracy: 0.3251\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 5s 52ms/step - loss: 1.4408 - accuracy: 0.3308 - val_loss: 1.3066 - val_accuracy: 0.3505\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 1.3425 - accuracy: 0.3737 - val_loss: 1.2536 - val_accuracy: 0.3836\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 6s 53ms/step - loss: 1.2778 - accuracy: 0.4156 - val_loss: 1.2404 - val_accuracy: 0.3972\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 1.2268 - accuracy: 0.4412 - val_loss: 1.2015 - val_accuracy: 0.4616\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 4s 41ms/step - loss: 1.2163 - accuracy: 0.4496 - val_loss: 1.1677 - val_accuracy: 0.5095\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 6s 56ms/step - loss: 1.1830 - accuracy: 0.4771 - val_loss: 1.1286 - val_accuracy: 0.5402\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 5s 44ms/step - loss: 1.1653 - accuracy: 0.4830 - val_loss: 1.1046 - val_accuracy: 0.5556\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 4s 41ms/step - loss: 1.1400 - accuracy: 0.5050 - val_loss: 1.0832 - val_accuracy: 0.5567\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 6s 59ms/step - loss: 1.1176 - accuracy: 0.5136 - val_loss: 1.0728 - val_accuracy: 0.5550\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 4s 41ms/step - loss: 1.1150 - accuracy: 0.5154 - val_loss: 1.0520 - val_accuracy: 0.5816\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 4s 41ms/step - loss: 1.1037 - accuracy: 0.5207 - val_loss: 1.0416 - val_accuracy: 0.5887\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 6s 59ms/step - loss: 1.0997 - accuracy: 0.5247 - val_loss: 1.0261 - val_accuracy: 0.5928\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 4s 41ms/step - loss: 1.0747 - accuracy: 0.5397 - val_loss: 1.0144 - val_accuracy: 0.6017\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 1.0755 - accuracy: 0.5420 - val_loss: 0.9962 - val_accuracy: 0.6052\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 6s 59ms/step - loss: 1.0563 - accuracy: 0.5569 - val_loss: 0.9901 - val_accuracy: 0.6164\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 4s 41ms/step - loss: 1.0464 - accuracy: 0.5576 - val_loss: 0.9630 - val_accuracy: 0.6324\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 1.0363 - accuracy: 0.5638 - val_loss: 0.9687 - val_accuracy: 0.6206\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 6s 59ms/step - loss: 1.0230 - accuracy: 0.5755 - val_loss: 0.9627 - val_accuracy: 0.6099\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 4s 41ms/step - loss: 1.0340 - accuracy: 0.5624 - val_loss: 0.9301 - val_accuracy: 0.6466\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 5s 45ms/step - loss: 0.9958 - accuracy: 0.5872 - val_loss: 0.9270 - val_accuracy: 0.6336\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 6s 56ms/step - loss: 0.9926 - accuracy: 0.5838 - val_loss: 0.9330 - val_accuracy: 0.6336\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 4s 41ms/step - loss: 0.9888 - accuracy: 0.5857 - val_loss: 0.9122 - val_accuracy: 0.6436\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 5s 48ms/step - loss: 0.9799 - accuracy: 0.5878 - val_loss: 0.9001 - val_accuracy: 0.6513\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 6s 53ms/step - loss: 0.9595 - accuracy: 0.5999 - val_loss: 0.9089 - val_accuracy: 0.6241\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 4s 41ms/step - loss: 0.9585 - accuracy: 0.6051 - val_loss: 0.8703 - val_accuracy: 0.6566\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 6s 53ms/step - loss: 0.9414 - accuracy: 0.6028 - val_loss: 0.8581 - val_accuracy: 0.6767\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 0.9317 - accuracy: 0.6129 - val_loss: 0.8713 - val_accuracy: 0.6507\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 4s 41ms/step - loss: 0.9268 - accuracy: 0.6207 - val_loss: 0.8542 - val_accuracy: 0.6702\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 6s 58ms/step - loss: 0.9171 - accuracy: 0.6225 - val_loss: 0.8453 - val_accuracy: 0.6862\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 0.9095 - accuracy: 0.6250 - val_loss: 0.8222 - val_accuracy: 0.6844\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 4s 41ms/step - loss: 0.9069 - accuracy: 0.6243 - val_loss: 0.8462 - val_accuracy: 0.6673\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 6s 59ms/step - loss: 0.8950 - accuracy: 0.6340 - val_loss: 0.8090 - val_accuracy: 0.7098\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 4s 41ms/step - loss: 0.8899 - accuracy: 0.6367 - val_loss: 0.8318 - val_accuracy: 0.6856\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 4s 41ms/step - loss: 0.8854 - accuracy: 0.6395 - val_loss: 0.8035 - val_accuracy: 0.7098\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 6s 59ms/step - loss: 0.8948 - accuracy: 0.6337 - val_loss: 0.8339 - val_accuracy: 0.6584\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 4s 41ms/step - loss: 0.8708 - accuracy: 0.6492 - val_loss: 0.7987 - val_accuracy: 0.6992\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 4s 41ms/step - loss: 0.8706 - accuracy: 0.6475 - val_loss: 0.7937 - val_accuracy: 0.7086\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 6s 60ms/step - loss: 0.8703 - accuracy: 0.6461 - val_loss: 0.7978 - val_accuracy: 0.7057\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 0.8617 - accuracy: 0.6522 - val_loss: 0.7977 - val_accuracy: 0.6974\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 4s 41ms/step - loss: 0.8515 - accuracy: 0.6590 - val_loss: 0.7973 - val_accuracy: 0.7021\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 6s 60ms/step - loss: 0.8543 - accuracy: 0.6488 - val_loss: 0.7929 - val_accuracy: 0.6933\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 0.8538 - accuracy: 0.6532 - val_loss: 0.8132 - val_accuracy: 0.6874\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 4s 41ms/step - loss: 0.8521 - accuracy: 0.6519 - val_loss: 0.8053 - val_accuracy: 0.6820\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 6s 60ms/step - loss: 0.8517 - accuracy: 0.6501 - val_loss: 0.7742 - val_accuracy: 0.7063\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 0.8411 - accuracy: 0.6642 - val_loss: 0.7652 - val_accuracy: 0.7175\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 5s 45ms/step - loss: 0.8302 - accuracy: 0.6625 - val_loss: 0.7858 - val_accuracy: 0.6885\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 6s 55ms/step - loss: 0.8350 - accuracy: 0.6640 - val_loss: 0.7781 - val_accuracy: 0.6921\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 0.8364 - accuracy: 0.6572 - val_loss: 0.7586 - val_accuracy: 0.7151\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 0.8061 - accuracy: 0.6764 - val_loss: 0.7826 - val_accuracy: 0.7080\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 6s 53ms/step - loss: 0.8109 - accuracy: 0.6786 - val_loss: 0.7665 - val_accuracy: 0.7057\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 4s 41ms/step - loss: 0.8161 - accuracy: 0.6683 - val_loss: 0.7707 - val_accuracy: 0.7051\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 5s 52ms/step - loss: 0.8112 - accuracy: 0.6717 - val_loss: 0.7681 - val_accuracy: 0.6956\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 5s 49ms/step - loss: 0.8066 - accuracy: 0.6761 - val_loss: 0.7620 - val_accuracy: 0.6998\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 0.8080 - accuracy: 0.6726 - val_loss: 0.7830 - val_accuracy: 0.6950\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 6s 56ms/step - loss: 0.8172 - accuracy: 0.6730 - val_loss: 0.7597 - val_accuracy: 0.7181\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 5s 45ms/step - loss: 0.8112 - accuracy: 0.6755 - val_loss: 0.7715 - val_accuracy: 0.6962\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 0.7966 - accuracy: 0.6736 - val_loss: 0.7583 - val_accuracy: 0.6980\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 6s 60ms/step - loss: 0.7963 - accuracy: 0.6789 - val_loss: 0.7497 - val_accuracy: 0.7169\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 4s 41ms/step - loss: 0.7955 - accuracy: 0.6752 - val_loss: 0.7498 - val_accuracy: 0.7063\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 0.8030 - accuracy: 0.6718 - val_loss: 0.7508 - val_accuracy: 0.7246\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 6s 60ms/step - loss: 0.7937 - accuracy: 0.6792 - val_loss: 0.7435 - val_accuracy: 0.7122\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 0.7794 - accuracy: 0.6834 - val_loss: 0.7686 - val_accuracy: 0.7104\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 0.7973 - accuracy: 0.6773 - val_loss: 0.7578 - val_accuracy: 0.7080\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 6s 60ms/step - loss: 0.7906 - accuracy: 0.6811 - val_loss: 0.7529 - val_accuracy: 0.7151\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 0.7987 - accuracy: 0.6752 - val_loss: 0.7684 - val_accuracy: 0.7015\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 4s 41ms/step - loss: 0.7855 - accuracy: 0.6822 - val_loss: 0.7382 - val_accuracy: 0.7181\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 6s 60ms/step - loss: 0.7783 - accuracy: 0.6853 - val_loss: 0.7447 - val_accuracy: 0.7009\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 0.7821 - accuracy: 0.6797 - val_loss: 0.7282 - val_accuracy: 0.7228\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 0.7716 - accuracy: 0.6915 - val_loss: 0.7378 - val_accuracy: 0.7175\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 6s 60ms/step - loss: 0.7739 - accuracy: 0.6869 - val_loss: 0.7453 - val_accuracy: 0.7092\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 0.7851 - accuracy: 0.6859 - val_loss: 0.7312 - val_accuracy: 0.7246\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 5s 45ms/step - loss: 0.7755 - accuracy: 0.6817 - val_loss: 0.7343 - val_accuracy: 0.7187\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 6s 56ms/step - loss: 0.7766 - accuracy: 0.6876 - val_loss: 0.7570 - val_accuracy: 0.7009\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 0.7711 - accuracy: 0.6897 - val_loss: 0.7389 - val_accuracy: 0.7009\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 5s 47ms/step - loss: 0.7713 - accuracy: 0.6829 - val_loss: 0.7489 - val_accuracy: 0.7074\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 6s 54ms/step - loss: 0.7682 - accuracy: 0.6946 - val_loss: 0.7349 - val_accuracy: 0.7169\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 0.7767 - accuracy: 0.6890 - val_loss: 0.7828 - val_accuracy: 0.6915\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 5s 51ms/step - loss: 0.7555 - accuracy: 0.6970 - val_loss: 0.7363 - val_accuracy: 0.7157\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 5s 50ms/step - loss: 0.7710 - accuracy: 0.6894 - val_loss: 0.7395 - val_accuracy: 0.7128\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 4s 41ms/step - loss: 0.7653 - accuracy: 0.6891 - val_loss: 0.7494 - val_accuracy: 0.7104\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 6s 53ms/step - loss: 0.7702 - accuracy: 0.6871 - val_loss: 0.7390 - val_accuracy: 0.7074\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 5s 48ms/step - loss: 0.7575 - accuracy: 0.6953 - val_loss: 0.7520 - val_accuracy: 0.7139\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 0.7726 - accuracy: 0.6853 - val_loss: 0.7299 - val_accuracy: 0.7199\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 6s 57ms/step - loss: 0.7529 - accuracy: 0.6996 - val_loss: 0.7245 - val_accuracy: 0.7098\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 5s 43ms/step - loss: 0.7518 - accuracy: 0.7001 - val_loss: 0.7390 - val_accuracy: 0.7098\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 0.7510 - accuracy: 0.6980 - val_loss: 0.7283 - val_accuracy: 0.7246\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 7s 62ms/step - loss: 0.7571 - accuracy: 0.7001 - val_loss: 0.7378 - val_accuracy: 0.6998\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 5s 43ms/step - loss: 0.7499 - accuracy: 0.7001 - val_loss: 0.7252 - val_accuracy: 0.7187\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 0.7408 - accuracy: 0.7083 - val_loss: 0.7115 - val_accuracy: 0.7305\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 6s 60ms/step - loss: 0.7533 - accuracy: 0.7017 - val_loss: 0.7403 - val_accuracy: 0.7080\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 0.7573 - accuracy: 0.6925 - val_loss: 0.7212 - val_accuracy: 0.7299\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 0.7534 - accuracy: 0.6987 - val_loss: 0.7320 - val_accuracy: 0.7086\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 6s 60ms/step - loss: 0.7479 - accuracy: 0.7015 - val_loss: 0.7303 - val_accuracy: 0.7246\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 0.7458 - accuracy: 0.7001 - val_loss: 0.7239 - val_accuracy: 0.7204\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 5s 45ms/step - loss: 0.7384 - accuracy: 0.7027 - val_loss: 0.7302 - val_accuracy: 0.7258\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 6s 56ms/step - loss: 0.7345 - accuracy: 0.7088 - val_loss: 0.7317 - val_accuracy: 0.7193\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 0.7350 - accuracy: 0.7072 - val_loss: 0.7245 - val_accuracy: 0.7311\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 5s 46ms/step - loss: 0.7363 - accuracy: 0.7052 - val_loss: 0.7222 - val_accuracy: 0.7293\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7632 - accuracy: 0.7082\n",
            "Test Accuracy: 0.7082392573356628\n",
            "Shape of X after trimming: (1692, 22, 500)\n",
            "Shape of X after trimming: (423, 22, 500)\n",
            "Shape of X after trimming: (443, 22, 500)\n",
            "Shape of training set: (6768, 22, 250)\n",
            "Shape of validation set: (1692, 22, 250)\n",
            "Shape of training labels: (6768,)\n",
            "Shape of validation labels: (1692,)\n",
            "Shape of testing set: (1772, 22, 250)\n",
            "Shape of testing labels: (1772,)\n",
            "Shape of training labels after categorical conversion: (6768, 4)\n",
            "Shape of validation labels after categorical conversion: (1692, 4)\n",
            "Shape of test labels after categorical conversion: (1772, 4)\n",
            "Shape of training set after adding width info: (6768, 22, 250, 1)\n",
            "Shape of validation set after adding width info: (1692, 22, 250, 1)\n",
            "Shape of test set after adding width info: (1772, 22, 250, 1)\n",
            "Shape of training set after dimension reshaping: (6768, 250, 1, 22)\n",
            "Shape of validation set after dimension reshaping: (1692, 250, 1, 22)\n",
            "Shape of test set after dimension reshaping: (1772, 250, 1, 22)\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 7s 56ms/step - loss: 1.9293 - accuracy: 0.2903 - val_loss: 1.4782 - val_accuracy: 0.3682\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 8s 78ms/step - loss: 1.5326 - accuracy: 0.3358 - val_loss: 1.2617 - val_accuracy: 0.4084\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 7s 62ms/step - loss: 1.3633 - accuracy: 0.3793 - val_loss: 1.2148 - val_accuracy: 0.4249\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 1.2701 - accuracy: 0.4297 - val_loss: 1.1877 - val_accuracy: 0.4758\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 5s 51ms/step - loss: 1.2258 - accuracy: 0.4481 - val_loss: 1.1782 - val_accuracy: 0.4799\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 7s 71ms/step - loss: 1.1983 - accuracy: 0.4607 - val_loss: 1.1669 - val_accuracy: 0.4882\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 5s 51ms/step - loss: 1.1626 - accuracy: 0.4812 - val_loss: 1.1603 - val_accuracy: 0.4965\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 7s 70ms/step - loss: 1.1453 - accuracy: 0.4982 - val_loss: 1.1432 - val_accuracy: 0.5266\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 5s 51ms/step - loss: 1.1235 - accuracy: 0.5140 - val_loss: 1.1441 - val_accuracy: 0.5059\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 6s 57ms/step - loss: 1.1067 - accuracy: 0.5161 - val_loss: 1.0971 - val_accuracy: 0.5437\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 7s 61ms/step - loss: 1.0887 - accuracy: 0.5363 - val_loss: 1.0871 - val_accuracy: 0.5644\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 5s 51ms/step - loss: 1.0612 - accuracy: 0.5458 - val_loss: 1.0647 - val_accuracy: 0.5556\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 7s 68ms/step - loss: 1.0397 - accuracy: 0.5624 - val_loss: 1.0495 - val_accuracy: 0.5751\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 6s 52ms/step - loss: 1.0407 - accuracy: 0.5598 - val_loss: 1.0430 - val_accuracy: 0.5709\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 7s 69ms/step - loss: 1.0188 - accuracy: 0.5779 - val_loss: 1.0206 - val_accuracy: 0.5845\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 5s 52ms/step - loss: 0.9974 - accuracy: 0.5906 - val_loss: 0.9939 - val_accuracy: 0.5987\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 6s 60ms/step - loss: 0.9798 - accuracy: 0.5901 - val_loss: 1.0174 - val_accuracy: 0.5875\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 6s 60ms/step - loss: 0.9783 - accuracy: 0.5922 - val_loss: 0.9742 - val_accuracy: 0.5904\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 5s 52ms/step - loss: 0.9609 - accuracy: 0.6093 - val_loss: 0.9808 - val_accuracy: 0.5887\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 7s 68ms/step - loss: 0.9449 - accuracy: 0.6083 - val_loss: 0.9417 - val_accuracy: 0.6011\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 5s 51ms/step - loss: 0.9258 - accuracy: 0.6152 - val_loss: 0.9144 - val_accuracy: 0.6300\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 7s 67ms/step - loss: 0.9378 - accuracy: 0.6135 - val_loss: 0.9070 - val_accuracy: 0.6525\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 5s 51ms/step - loss: 0.9183 - accuracy: 0.6280 - val_loss: 0.9201 - val_accuracy: 0.6217\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 6s 55ms/step - loss: 0.8934 - accuracy: 0.6405 - val_loss: 0.8925 - val_accuracy: 0.6495\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 7s 63ms/step - loss: 0.8965 - accuracy: 0.6361 - val_loss: 0.8795 - val_accuracy: 0.6495\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 5s 51ms/step - loss: 0.8817 - accuracy: 0.6467 - val_loss: 0.8832 - val_accuracy: 0.6413\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 7s 69ms/step - loss: 0.8827 - accuracy: 0.6371 - val_loss: 0.8793 - val_accuracy: 0.6348\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 5s 51ms/step - loss: 0.8845 - accuracy: 0.6396 - val_loss: 0.8729 - val_accuracy: 0.6454\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.8545 - accuracy: 0.6579 - val_loss: 0.8559 - val_accuracy: 0.6684\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 6s 55ms/step - loss: 0.8640 - accuracy: 0.6473 - val_loss: 0.8874 - val_accuracy: 0.6548\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 6s 54ms/step - loss: 0.8407 - accuracy: 0.6577 - val_loss: 0.8323 - val_accuracy: 0.6655\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 7s 66ms/step - loss: 0.8334 - accuracy: 0.6618 - val_loss: 0.8295 - val_accuracy: 0.6767\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 6s 54ms/step - loss: 0.8415 - accuracy: 0.6551 - val_loss: 0.8176 - val_accuracy: 0.6785\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 7s 69ms/step - loss: 0.8094 - accuracy: 0.6736 - val_loss: 0.8361 - val_accuracy: 0.6649\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 6s 53ms/step - loss: 0.8328 - accuracy: 0.6646 - val_loss: 0.8275 - val_accuracy: 0.6809\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 7s 67ms/step - loss: 0.8248 - accuracy: 0.6715 - val_loss: 0.7969 - val_accuracy: 0.6921\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 6s 53ms/step - loss: 0.8326 - accuracy: 0.6695 - val_loss: 0.8134 - val_accuracy: 0.6785\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 6s 55ms/step - loss: 0.8219 - accuracy: 0.6633 - val_loss: 0.8407 - val_accuracy: 0.6572\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 7s 65ms/step - loss: 0.8163 - accuracy: 0.6732 - val_loss: 0.8350 - val_accuracy: 0.6702\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 6s 52ms/step - loss: 0.8035 - accuracy: 0.6761 - val_loss: 0.8367 - val_accuracy: 0.6531\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 7s 68ms/step - loss: 0.7947 - accuracy: 0.6789 - val_loss: 0.8285 - val_accuracy: 0.6495\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 6s 54ms/step - loss: 0.8044 - accuracy: 0.6863 - val_loss: 0.8184 - val_accuracy: 0.6779\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 7s 66ms/step - loss: 0.7935 - accuracy: 0.6866 - val_loss: 0.8055 - val_accuracy: 0.6661\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 6s 54ms/step - loss: 0.7925 - accuracy: 0.6847 - val_loss: 0.7968 - val_accuracy: 0.6814\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 6s 55ms/step - loss: 0.7929 - accuracy: 0.6820 - val_loss: 0.7709 - val_accuracy: 0.6992\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 7s 65ms/step - loss: 0.7817 - accuracy: 0.6922 - val_loss: 0.7789 - val_accuracy: 0.6891\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 5s 52ms/step - loss: 0.7834 - accuracy: 0.6878 - val_loss: 0.7885 - val_accuracy: 0.6862\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 7s 69ms/step - loss: 0.7923 - accuracy: 0.6826 - val_loss: 0.7821 - val_accuracy: 0.7033\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 6s 55ms/step - loss: 0.7726 - accuracy: 0.6918 - val_loss: 0.8138 - val_accuracy: 0.6584\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 7s 68ms/step - loss: 0.7715 - accuracy: 0.6868 - val_loss: 0.7898 - val_accuracy: 0.6720\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 6s 53ms/step - loss: 0.7676 - accuracy: 0.6937 - val_loss: 0.7719 - val_accuracy: 0.6956\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 6s 57ms/step - loss: 0.7546 - accuracy: 0.7023 - val_loss: 0.7677 - val_accuracy: 0.6791\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 7s 63ms/step - loss: 0.7555 - accuracy: 0.7036 - val_loss: 0.8212 - val_accuracy: 0.6525\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 5s 52ms/step - loss: 0.7758 - accuracy: 0.6965 - val_loss: 0.8052 - val_accuracy: 0.6726\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 8s 71ms/step - loss: 0.7518 - accuracy: 0.7008 - val_loss: 0.7752 - val_accuracy: 0.6927\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 5s 52ms/step - loss: 0.7530 - accuracy: 0.7014 - val_loss: 0.7763 - val_accuracy: 0.6874\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 7s 68ms/step - loss: 0.7485 - accuracy: 0.7038 - val_loss: 0.7870 - val_accuracy: 0.6844\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 6s 52ms/step - loss: 0.7435 - accuracy: 0.7103 - val_loss: 0.7816 - val_accuracy: 0.6844\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 6s 57ms/step - loss: 0.7509 - accuracy: 0.7067 - val_loss: 0.7574 - val_accuracy: 0.7128\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 7s 63ms/step - loss: 0.7304 - accuracy: 0.7101 - val_loss: 0.7618 - val_accuracy: 0.7039\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 5s 51ms/step - loss: 0.7351 - accuracy: 0.7089 - val_loss: 0.7713 - val_accuracy: 0.6868\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 7s 69ms/step - loss: 0.7614 - accuracy: 0.6965 - val_loss: 0.7812 - val_accuracy: 0.6862\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 6s 53ms/step - loss: 0.7404 - accuracy: 0.7066 - val_loss: 0.7718 - val_accuracy: 0.6950\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 7s 68ms/step - loss: 0.7442 - accuracy: 0.7085 - val_loss: 0.7854 - val_accuracy: 0.6850\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 6s 54ms/step - loss: 0.7379 - accuracy: 0.7035 - val_loss: 0.7455 - val_accuracy: 0.7051\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 6s 58ms/step - loss: 0.7398 - accuracy: 0.7072 - val_loss: 0.7558 - val_accuracy: 0.7051\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 7s 63ms/step - loss: 0.7288 - accuracy: 0.7107 - val_loss: 0.7703 - val_accuracy: 0.7045\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 6s 52ms/step - loss: 0.7222 - accuracy: 0.7132 - val_loss: 0.7832 - val_accuracy: 0.6838\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 7s 69ms/step - loss: 0.7490 - accuracy: 0.7035 - val_loss: 0.7666 - val_accuracy: 0.6915\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 6s 55ms/step - loss: 0.7303 - accuracy: 0.7113 - val_loss: 0.7588 - val_accuracy: 0.7033\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 7s 69ms/step - loss: 0.7240 - accuracy: 0.7126 - val_loss: 0.7603 - val_accuracy: 0.6879\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 6s 55ms/step - loss: 0.7273 - accuracy: 0.7088 - val_loss: 0.7588 - val_accuracy: 0.7027\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 6s 61ms/step - loss: 0.7204 - accuracy: 0.7138 - val_loss: 0.7845 - val_accuracy: 0.6814\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 6s 61ms/step - loss: 0.7315 - accuracy: 0.7064 - val_loss: 0.7645 - val_accuracy: 0.7009\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 6s 53ms/step - loss: 0.7240 - accuracy: 0.7110 - val_loss: 0.7705 - val_accuracy: 0.6856\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 7s 69ms/step - loss: 0.7233 - accuracy: 0.7107 - val_loss: 0.7557 - val_accuracy: 0.7045\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 6s 52ms/step - loss: 0.7050 - accuracy: 0.7181 - val_loss: 0.7733 - val_accuracy: 0.6974\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 7s 69ms/step - loss: 0.7236 - accuracy: 0.7134 - val_loss: 0.7527 - val_accuracy: 0.7063\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 6s 52ms/step - loss: 0.7107 - accuracy: 0.7162 - val_loss: 0.7919 - val_accuracy: 0.6661\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 7s 63ms/step - loss: 0.7107 - accuracy: 0.7264 - val_loss: 0.7453 - val_accuracy: 0.7134\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 6s 59ms/step - loss: 0.6968 - accuracy: 0.7238 - val_loss: 0.7591 - val_accuracy: 0.6944\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 6s 56ms/step - loss: 0.7073 - accuracy: 0.7188 - val_loss: 0.7378 - val_accuracy: 0.7122\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 7s 66ms/step - loss: 0.6973 - accuracy: 0.7284 - val_loss: 0.7378 - val_accuracy: 0.7080\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 6s 52ms/step - loss: 0.7164 - accuracy: 0.7200 - val_loss: 0.7515 - val_accuracy: 0.7074\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 7s 69ms/step - loss: 0.7005 - accuracy: 0.7244 - val_loss: 0.7489 - val_accuracy: 0.7098\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 6s 53ms/step - loss: 0.7035 - accuracy: 0.7244 - val_loss: 0.7647 - val_accuracy: 0.6903\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 7s 70ms/step - loss: 0.7209 - accuracy: 0.7116 - val_loss: 0.7560 - val_accuracy: 0.6939\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 6s 52ms/step - loss: 0.7071 - accuracy: 0.7194 - val_loss: 0.7993 - val_accuracy: 0.6702\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 6s 61ms/step - loss: 0.6919 - accuracy: 0.7268 - val_loss: 0.7549 - val_accuracy: 0.6939\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 6s 61ms/step - loss: 0.7081 - accuracy: 0.7221 - val_loss: 0.7537 - val_accuracy: 0.7051\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 6s 53ms/step - loss: 0.6855 - accuracy: 0.7277 - val_loss: 0.7784 - val_accuracy: 0.6755\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 8s 71ms/step - loss: 0.6861 - accuracy: 0.7250 - val_loss: 0.7667 - val_accuracy: 0.6998\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 6s 53ms/step - loss: 0.6901 - accuracy: 0.7278 - val_loss: 0.7554 - val_accuracy: 0.6939\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 7s 70ms/step - loss: 0.6910 - accuracy: 0.7264 - val_loss: 0.7573 - val_accuracy: 0.6903\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 6s 53ms/step - loss: 0.6918 - accuracy: 0.7264 - val_loss: 0.7342 - val_accuracy: 0.7139\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 7s 62ms/step - loss: 0.6979 - accuracy: 0.7240 - val_loss: 0.7388 - val_accuracy: 0.7086\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 6s 60ms/step - loss: 0.7031 - accuracy: 0.7219 - val_loss: 0.7493 - val_accuracy: 0.7021\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 6s 53ms/step - loss: 0.6887 - accuracy: 0.7305 - val_loss: 0.7597 - val_accuracy: 0.7009\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 7s 69ms/step - loss: 0.6920 - accuracy: 0.7290 - val_loss: 0.7484 - val_accuracy: 0.7027\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 6s 55ms/step - loss: 0.6748 - accuracy: 0.7303 - val_loss: 0.7475 - val_accuracy: 0.6962\n",
            "56/56 [==============================] - 1s 10ms/step - loss: 0.7545 - accuracy: 0.6902\n",
            "Test Accuracy: 0.6901805996894836\n",
            "Shape of X after trimming: (1692, 22, 600)\n",
            "Shape of X after trimming: (423, 22, 600)\n",
            "Shape of X after trimming: (443, 22, 600)\n",
            "Shape of training set: (6768, 22, 300)\n",
            "Shape of validation set: (1692, 22, 300)\n",
            "Shape of training labels: (6768,)\n",
            "Shape of validation labels: (1692,)\n",
            "Shape of testing set: (1772, 22, 300)\n",
            "Shape of testing labels: (1772,)\n",
            "Shape of training labels after categorical conversion: (6768, 4)\n",
            "Shape of validation labels after categorical conversion: (1692, 4)\n",
            "Shape of test labels after categorical conversion: (1772, 4)\n",
            "Shape of training set after adding width info: (6768, 22, 300, 1)\n",
            "Shape of validation set after adding width info: (1692, 22, 300, 1)\n",
            "Shape of test set after adding width info: (1772, 22, 300, 1)\n",
            "Shape of training set after dimension reshaping: (6768, 300, 1, 22)\n",
            "Shape of validation set after dimension reshaping: (1692, 300, 1, 22)\n",
            "Shape of test set after dimension reshaping: (1772, 300, 1, 22)\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 8s 66ms/step - loss: 1.9964 - accuracy: 0.2871 - val_loss: 1.4215 - val_accuracy: 0.3322\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 1.5924 - accuracy: 0.3254 - val_loss: 1.2772 - val_accuracy: 0.3794\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 7s 67ms/step - loss: 1.4119 - accuracy: 0.3608 - val_loss: 1.2538 - val_accuracy: 0.4048\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 8s 75ms/step - loss: 1.3076 - accuracy: 0.4043 - val_loss: 1.2194 - val_accuracy: 0.4261\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 8s 74ms/step - loss: 1.2358 - accuracy: 0.4359 - val_loss: 1.2072 - val_accuracy: 0.4155\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 7s 69ms/step - loss: 1.2000 - accuracy: 0.4642 - val_loss: 1.1930 - val_accuracy: 0.4232\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 9s 81ms/step - loss: 1.1624 - accuracy: 0.4837 - val_loss: 1.1800 - val_accuracy: 0.4586\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 7s 63ms/step - loss: 1.1238 - accuracy: 0.5064 - val_loss: 1.1726 - val_accuracy: 0.4805\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 1.1073 - accuracy: 0.5183 - val_loss: 1.1375 - val_accuracy: 0.5000\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 1.0866 - accuracy: 0.5312 - val_loss: 1.1233 - val_accuracy: 0.5136\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 1.0642 - accuracy: 0.5443 - val_loss: 1.1209 - val_accuracy: 0.5349\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 7s 63ms/step - loss: 1.0442 - accuracy: 0.5595 - val_loss: 1.0714 - val_accuracy: 0.5361\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 8s 78ms/step - loss: 1.0303 - accuracy: 0.5757 - val_loss: 1.0547 - val_accuracy: 0.5378\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 7s 63ms/step - loss: 1.0025 - accuracy: 0.5811 - val_loss: 1.0356 - val_accuracy: 0.5727\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.9929 - accuracy: 0.5894 - val_loss: 1.0433 - val_accuracy: 0.5780\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.9759 - accuracy: 0.5983 - val_loss: 1.0088 - val_accuracy: 0.5993\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.9516 - accuracy: 0.6102 - val_loss: 1.0139 - val_accuracy: 0.5792\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 7s 63ms/step - loss: 0.9523 - accuracy: 0.6086 - val_loss: 1.0055 - val_accuracy: 0.5845\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.9314 - accuracy: 0.6192 - val_loss: 1.0003 - val_accuracy: 0.5940\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 7s 63ms/step - loss: 0.9240 - accuracy: 0.6167 - val_loss: 0.9628 - val_accuracy: 0.6105\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.9055 - accuracy: 0.6312 - val_loss: 0.9846 - val_accuracy: 0.6182\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.8934 - accuracy: 0.6345 - val_loss: 0.9687 - val_accuracy: 0.5857\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.8815 - accuracy: 0.6475 - val_loss: 0.9639 - val_accuracy: 0.6123\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 7s 63ms/step - loss: 0.8833 - accuracy: 0.6345 - val_loss: 0.9177 - val_accuracy: 0.6377\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.8767 - accuracy: 0.6513 - val_loss: 0.9143 - val_accuracy: 0.6407\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 7s 66ms/step - loss: 0.8570 - accuracy: 0.6507 - val_loss: 0.9140 - val_accuracy: 0.6436\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 8s 77ms/step - loss: 0.8478 - accuracy: 0.6447 - val_loss: 0.8988 - val_accuracy: 0.6413\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 7s 69ms/step - loss: 0.8426 - accuracy: 0.6584 - val_loss: 0.8968 - val_accuracy: 0.6566\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 8s 73ms/step - loss: 0.8440 - accuracy: 0.6594 - val_loss: 0.8846 - val_accuracy: 0.6625\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 8s 72ms/step - loss: 0.8339 - accuracy: 0.6609 - val_loss: 0.8931 - val_accuracy: 0.6608\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 8s 71ms/step - loss: 0.8087 - accuracy: 0.6791 - val_loss: 0.8810 - val_accuracy: 0.6572\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.8080 - accuracy: 0.6748 - val_loss: 0.8790 - val_accuracy: 0.6489\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.8194 - accuracy: 0.6792 - val_loss: 0.8736 - val_accuracy: 0.6495\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.7929 - accuracy: 0.6823 - val_loss: 0.8700 - val_accuracy: 0.6643\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.7886 - accuracy: 0.6894 - val_loss: 0.8492 - val_accuracy: 0.6625\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.7904 - accuracy: 0.6832 - val_loss: 0.8807 - val_accuracy: 0.6649\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.7887 - accuracy: 0.6837 - val_loss: 0.8475 - val_accuracy: 0.6779\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.7884 - accuracy: 0.6826 - val_loss: 0.8487 - val_accuracy: 0.6749\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.7822 - accuracy: 0.6872 - val_loss: 0.8361 - val_accuracy: 0.6785\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.7661 - accuracy: 0.6956 - val_loss: 0.8449 - val_accuracy: 0.6767\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.7690 - accuracy: 0.6952 - val_loss: 0.8301 - val_accuracy: 0.6684\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.7686 - accuracy: 0.6915 - val_loss: 0.8383 - val_accuracy: 0.6690\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.7734 - accuracy: 0.6940 - val_loss: 0.8161 - val_accuracy: 0.6779\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 8s 80ms/step - loss: 0.7612 - accuracy: 0.6977 - val_loss: 0.8393 - val_accuracy: 0.6596\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 7s 63ms/step - loss: 0.7517 - accuracy: 0.7008 - val_loss: 0.8181 - val_accuracy: 0.6590\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.7713 - accuracy: 0.6913 - val_loss: 0.8230 - val_accuracy: 0.6809\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.7456 - accuracy: 0.7055 - val_loss: 0.8333 - val_accuracy: 0.6584\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.7356 - accuracy: 0.7072 - val_loss: 0.8031 - val_accuracy: 0.6814\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 7s 65ms/step - loss: 0.7513 - accuracy: 0.6993 - val_loss: 0.8082 - val_accuracy: 0.6891\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.7376 - accuracy: 0.7072 - val_loss: 0.8616 - val_accuracy: 0.6507\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 8s 73ms/step - loss: 0.7410 - accuracy: 0.6986 - val_loss: 0.8530 - val_accuracy: 0.6655\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 8s 71ms/step - loss: 0.7387 - accuracy: 0.7029 - val_loss: 0.8330 - val_accuracy: 0.6714\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 8s 80ms/step - loss: 0.7466 - accuracy: 0.7007 - val_loss: 0.8045 - val_accuracy: 0.6850\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.7318 - accuracy: 0.7085 - val_loss: 0.8177 - val_accuracy: 0.6838\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.7317 - accuracy: 0.7064 - val_loss: 0.8318 - val_accuracy: 0.6661\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.7240 - accuracy: 0.7113 - val_loss: 0.8033 - val_accuracy: 0.6897\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 9s 81ms/step - loss: 0.7107 - accuracy: 0.7191 - val_loss: 0.8001 - val_accuracy: 0.6832\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.7268 - accuracy: 0.7097 - val_loss: 0.7978 - val_accuracy: 0.6915\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.7158 - accuracy: 0.7131 - val_loss: 0.7962 - val_accuracy: 0.6944\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.7301 - accuracy: 0.7070 - val_loss: 0.8157 - val_accuracy: 0.6732\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.7232 - accuracy: 0.7123 - val_loss: 0.8242 - val_accuracy: 0.6803\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.7216 - accuracy: 0.7168 - val_loss: 0.7918 - val_accuracy: 0.6814\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.7250 - accuracy: 0.7138 - val_loss: 0.8167 - val_accuracy: 0.6779\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 7s 65ms/step - loss: 0.7182 - accuracy: 0.7137 - val_loss: 0.8106 - val_accuracy: 0.6803\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.7021 - accuracy: 0.7199 - val_loss: 0.8020 - val_accuracy: 0.6791\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.7161 - accuracy: 0.7108 - val_loss: 0.8204 - val_accuracy: 0.6767\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 9s 81ms/step - loss: 0.7018 - accuracy: 0.7168 - val_loss: 0.8017 - val_accuracy: 0.6891\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 7s 68ms/step - loss: 0.7014 - accuracy: 0.7176 - val_loss: 0.8218 - val_accuracy: 0.6732\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 8s 75ms/step - loss: 0.7055 - accuracy: 0.7255 - val_loss: 0.7912 - val_accuracy: 0.6950\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 8s 76ms/step - loss: 0.6849 - accuracy: 0.7311 - val_loss: 0.7863 - val_accuracy: 0.7021\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 7s 68ms/step - loss: 0.6994 - accuracy: 0.7292 - val_loss: 0.7714 - val_accuracy: 0.7134\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 9s 85ms/step - loss: 0.6884 - accuracy: 0.7250 - val_loss: 0.7790 - val_accuracy: 0.7009\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.7066 - accuracy: 0.7147 - val_loss: 0.7734 - val_accuracy: 0.6962\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.6896 - accuracy: 0.7312 - val_loss: 0.8179 - val_accuracy: 0.6838\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.6972 - accuracy: 0.7308 - val_loss: 0.7840 - val_accuracy: 0.6874\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.6931 - accuracy: 0.7289 - val_loss: 0.7932 - val_accuracy: 0.6844\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.6802 - accuracy: 0.7354 - val_loss: 0.8065 - val_accuracy: 0.6915\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.7039 - accuracy: 0.7190 - val_loss: 0.8154 - val_accuracy: 0.6678\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.6876 - accuracy: 0.7258 - val_loss: 0.7910 - val_accuracy: 0.6950\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 8s 80ms/step - loss: 0.6769 - accuracy: 0.7355 - val_loss: 0.7732 - val_accuracy: 0.6891\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.6776 - accuracy: 0.7363 - val_loss: 0.7755 - val_accuracy: 0.6850\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 8s 80ms/step - loss: 0.6776 - accuracy: 0.7352 - val_loss: 0.7734 - val_accuracy: 0.6998\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.6839 - accuracy: 0.7281 - val_loss: 0.7975 - val_accuracy: 0.6933\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 8s 80ms/step - loss: 0.6797 - accuracy: 0.7351 - val_loss: 0.7905 - val_accuracy: 0.6850\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.6700 - accuracy: 0.7402 - val_loss: 0.7799 - val_accuracy: 0.7057\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 8s 80ms/step - loss: 0.6694 - accuracy: 0.7385 - val_loss: 0.7734 - val_accuracy: 0.6915\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 8s 73ms/step - loss: 0.6614 - accuracy: 0.7400 - val_loss: 0.7637 - val_accuracy: 0.7080\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 8s 72ms/step - loss: 0.6753 - accuracy: 0.7335 - val_loss: 0.8121 - val_accuracy: 0.6915\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 8s 80ms/step - loss: 0.6831 - accuracy: 0.7265 - val_loss: 0.7741 - val_accuracy: 0.7045\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 7s 65ms/step - loss: 0.6853 - accuracy: 0.7321 - val_loss: 0.7683 - val_accuracy: 0.7021\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 8s 80ms/step - loss: 0.6677 - accuracy: 0.7306 - val_loss: 0.8181 - val_accuracy: 0.6927\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 7s 65ms/step - loss: 0.6757 - accuracy: 0.7298 - val_loss: 0.7654 - val_accuracy: 0.6998\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 8s 80ms/step - loss: 0.6710 - accuracy: 0.7302 - val_loss: 0.7591 - val_accuracy: 0.6998\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.6700 - accuracy: 0.7391 - val_loss: 0.7747 - val_accuracy: 0.6927\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 8s 80ms/step - loss: 0.6670 - accuracy: 0.7397 - val_loss: 0.7952 - val_accuracy: 0.6897\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 7s 65ms/step - loss: 0.6684 - accuracy: 0.7420 - val_loss: 0.7645 - val_accuracy: 0.6986\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 8s 80ms/step - loss: 0.6626 - accuracy: 0.7335 - val_loss: 0.8007 - val_accuracy: 0.6755\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 7s 65ms/step - loss: 0.6592 - accuracy: 0.7398 - val_loss: 0.8015 - val_accuracy: 0.6779\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 8s 80ms/step - loss: 0.6600 - accuracy: 0.7354 - val_loss: 0.7843 - val_accuracy: 0.6826\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.6539 - accuracy: 0.7407 - val_loss: 0.7678 - val_accuracy: 0.7004\n",
            "56/56 [==============================] - 1s 12ms/step - loss: 0.7016 - accuracy: 0.7178\n",
            "Test Accuracy: 0.7178329825401306\n",
            "Shape of X after trimming: (1692, 22, 700)\n",
            "Shape of X after trimming: (423, 22, 700)\n",
            "Shape of X after trimming: (443, 22, 700)\n",
            "Shape of training set: (6768, 22, 350)\n",
            "Shape of validation set: (1692, 22, 350)\n",
            "Shape of training labels: (6768,)\n",
            "Shape of validation labels: (1692,)\n",
            "Shape of testing set: (1772, 22, 350)\n",
            "Shape of testing labels: (1772,)\n",
            "Shape of training labels after categorical conversion: (6768, 4)\n",
            "Shape of validation labels after categorical conversion: (1692, 4)\n",
            "Shape of test labels after categorical conversion: (1772, 4)\n",
            "Shape of training set after adding width info: (6768, 22, 350, 1)\n",
            "Shape of validation set after adding width info: (1692, 22, 350, 1)\n",
            "Shape of test set after adding width info: (1772, 22, 350, 1)\n",
            "Shape of training set after dimension reshaping: (6768, 350, 1, 22)\n",
            "Shape of validation set after dimension reshaping: (1692, 350, 1, 22)\n",
            "Shape of test set after dimension reshaping: (1772, 350, 1, 22)\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 11s 94ms/step - loss: 2.0198 - accuracy: 0.2818 - val_loss: 1.4321 - val_accuracy: 0.3186\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 8s 73ms/step - loss: 1.6153 - accuracy: 0.3112 - val_loss: 1.3186 - val_accuracy: 0.3546\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 9s 88ms/step - loss: 1.4250 - accuracy: 0.3508 - val_loss: 1.2905 - val_accuracy: 0.3783\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 11s 100ms/step - loss: 1.3162 - accuracy: 0.4006 - val_loss: 1.2625 - val_accuracy: 0.3978\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 8s 76ms/step - loss: 1.2420 - accuracy: 0.4399 - val_loss: 1.2397 - val_accuracy: 0.4173\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 9s 87ms/step - loss: 1.1842 - accuracy: 0.4780 - val_loss: 1.2007 - val_accuracy: 0.4344\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 8s 72ms/step - loss: 1.1510 - accuracy: 0.4988 - val_loss: 1.1760 - val_accuracy: 0.4675\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 9s 88ms/step - loss: 1.1273 - accuracy: 0.5059 - val_loss: 1.1571 - val_accuracy: 0.4858\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 8s 77ms/step - loss: 1.1024 - accuracy: 0.5290 - val_loss: 1.1429 - val_accuracy: 0.5035\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 9s 83ms/step - loss: 1.0905 - accuracy: 0.5297 - val_loss: 1.1370 - val_accuracy: 0.5236\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 9s 87ms/step - loss: 1.0679 - accuracy: 0.5358 - val_loss: 1.1478 - val_accuracy: 0.5100\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 8s 72ms/step - loss: 1.0534 - accuracy: 0.5471 - val_loss: 1.1096 - val_accuracy: 0.5225\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 9s 88ms/step - loss: 1.0416 - accuracy: 0.5600 - val_loss: 1.0894 - val_accuracy: 0.5307\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 8s 74ms/step - loss: 1.0371 - accuracy: 0.5718 - val_loss: 1.1076 - val_accuracy: 0.5171\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 9s 86ms/step - loss: 1.0351 - accuracy: 0.5615 - val_loss: 1.0979 - val_accuracy: 0.5195\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 9s 85ms/step - loss: 1.0079 - accuracy: 0.5755 - val_loss: 1.0899 - val_accuracy: 0.5325\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 8s 75ms/step - loss: 1.0000 - accuracy: 0.5851 - val_loss: 1.0600 - val_accuracy: 0.5526\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 9s 89ms/step - loss: 0.9889 - accuracy: 0.5845 - val_loss: 1.0929 - val_accuracy: 0.5236\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 8s 73ms/step - loss: 0.9746 - accuracy: 0.5938 - val_loss: 1.0087 - val_accuracy: 0.5786\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 9s 88ms/step - loss: 0.9645 - accuracy: 0.5937 - val_loss: 1.0089 - val_accuracy: 0.5739\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 9s 88ms/step - loss: 0.9555 - accuracy: 0.5980 - val_loss: 0.9880 - val_accuracy: 0.5875\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 8s 73ms/step - loss: 0.9481 - accuracy: 0.6036 - val_loss: 0.9567 - val_accuracy: 0.6212\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 9s 88ms/step - loss: 0.9212 - accuracy: 0.6215 - val_loss: 0.9748 - val_accuracy: 0.5975\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 8s 72ms/step - loss: 0.9025 - accuracy: 0.6322 - val_loss: 0.9474 - val_accuracy: 0.6052\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 9s 88ms/step - loss: 0.9037 - accuracy: 0.6361 - val_loss: 0.9222 - val_accuracy: 0.6241\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 10s 90ms/step - loss: 0.8960 - accuracy: 0.6377 - val_loss: 0.9520 - val_accuracy: 0.6200\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 8s 73ms/step - loss: 0.8757 - accuracy: 0.6370 - val_loss: 0.8893 - val_accuracy: 0.6531\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 9s 87ms/step - loss: 0.8724 - accuracy: 0.6466 - val_loss: 0.8956 - val_accuracy: 0.6294\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 8s 80ms/step - loss: 0.8572 - accuracy: 0.6575 - val_loss: 0.8914 - val_accuracy: 0.6472\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 9s 81ms/step - loss: 0.8662 - accuracy: 0.6463 - val_loss: 0.8963 - val_accuracy: 0.6454\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 9s 88ms/step - loss: 0.8506 - accuracy: 0.6497 - val_loss: 0.8798 - val_accuracy: 0.6596\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 8s 73ms/step - loss: 0.8395 - accuracy: 0.6615 - val_loss: 0.9184 - val_accuracy: 0.6247\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 9s 87ms/step - loss: 0.8311 - accuracy: 0.6646 - val_loss: 0.8582 - val_accuracy: 0.6667\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 8s 76ms/step - loss: 0.8305 - accuracy: 0.6637 - val_loss: 0.8966 - val_accuracy: 0.6430\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 9s 84ms/step - loss: 0.8121 - accuracy: 0.6752 - val_loss: 0.9018 - val_accuracy: 0.6247\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 9s 88ms/step - loss: 0.8125 - accuracy: 0.6715 - val_loss: 0.8930 - val_accuracy: 0.6283\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 8s 73ms/step - loss: 0.8128 - accuracy: 0.6689 - val_loss: 0.8990 - val_accuracy: 0.6353\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 9s 88ms/step - loss: 0.8043 - accuracy: 0.6745 - val_loss: 0.8329 - val_accuracy: 0.6832\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 8s 75ms/step - loss: 0.7978 - accuracy: 0.6792 - val_loss: 0.8507 - val_accuracy: 0.6738\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 9s 87ms/step - loss: 0.8037 - accuracy: 0.6798 - val_loss: 0.8537 - val_accuracy: 0.6631\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 10s 92ms/step - loss: 0.8043 - accuracy: 0.6754 - val_loss: 0.8713 - val_accuracy: 0.6365\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 8s 72ms/step - loss: 0.8001 - accuracy: 0.6757 - val_loss: 0.8748 - val_accuracy: 0.6608\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 9s 88ms/step - loss: 0.7724 - accuracy: 0.6934 - val_loss: 0.8299 - val_accuracy: 0.6814\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 9s 81ms/step - loss: 0.7925 - accuracy: 0.6844 - val_loss: 0.8472 - val_accuracy: 0.6548\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 9s 80ms/step - loss: 0.7707 - accuracy: 0.6871 - val_loss: 0.8444 - val_accuracy: 0.6501\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 9s 88ms/step - loss: 0.7723 - accuracy: 0.6949 - val_loss: 0.8537 - val_accuracy: 0.6578\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 8s 73ms/step - loss: 0.7770 - accuracy: 0.6882 - val_loss: 0.8104 - val_accuracy: 0.6832\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 9s 88ms/step - loss: 0.7743 - accuracy: 0.6909 - val_loss: 0.8306 - val_accuracy: 0.6625\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 8s 78ms/step - loss: 0.7712 - accuracy: 0.6964 - val_loss: 0.8340 - val_accuracy: 0.6637\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 9s 84ms/step - loss: 0.7530 - accuracy: 0.7021 - val_loss: 0.8292 - val_accuracy: 0.6519\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 9s 88ms/step - loss: 0.7578 - accuracy: 0.6968 - val_loss: 0.8132 - val_accuracy: 0.6844\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 8s 73ms/step - loss: 0.7510 - accuracy: 0.7007 - val_loss: 0.8290 - val_accuracy: 0.6708\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 9s 89ms/step - loss: 0.7595 - accuracy: 0.6974 - val_loss: 0.7998 - val_accuracy: 0.6903\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 8s 78ms/step - loss: 0.7634 - accuracy: 0.6971 - val_loss: 0.8209 - val_accuracy: 0.6779\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 9s 87ms/step - loss: 0.7546 - accuracy: 0.7014 - val_loss: 0.8693 - val_accuracy: 0.6501\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 9s 89ms/step - loss: 0.7584 - accuracy: 0.7021 - val_loss: 0.8338 - val_accuracy: 0.6696\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 8s 74ms/step - loss: 0.7549 - accuracy: 0.7001 - val_loss: 0.8283 - val_accuracy: 0.6696\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 9s 89ms/step - loss: 0.7437 - accuracy: 0.7055 - val_loss: 0.8262 - val_accuracy: 0.6738\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.7266 - accuracy: 0.7123 - val_loss: 0.7781 - val_accuracy: 0.6950\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 9s 83ms/step - loss: 0.7313 - accuracy: 0.7100 - val_loss: 0.8131 - val_accuracy: 0.6761\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 9s 89ms/step - loss: 0.7313 - accuracy: 0.7126 - val_loss: 0.8272 - val_accuracy: 0.6708\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 8s 73ms/step - loss: 0.7263 - accuracy: 0.7048 - val_loss: 0.7948 - val_accuracy: 0.6909\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 9s 89ms/step - loss: 0.7347 - accuracy: 0.7092 - val_loss: 0.8307 - val_accuracy: 0.6708\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 8s 78ms/step - loss: 0.7344 - accuracy: 0.7035 - val_loss: 0.8077 - val_accuracy: 0.6773\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 9s 83ms/step - loss: 0.7389 - accuracy: 0.7043 - val_loss: 0.8236 - val_accuracy: 0.6655\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 9s 88ms/step - loss: 0.7325 - accuracy: 0.7069 - val_loss: 0.7952 - val_accuracy: 0.6791\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 8s 74ms/step - loss: 0.7173 - accuracy: 0.7176 - val_loss: 0.7922 - val_accuracy: 0.6720\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 9s 88ms/step - loss: 0.7159 - accuracy: 0.7166 - val_loss: 0.8166 - val_accuracy: 0.6809\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 8s 76ms/step - loss: 0.7215 - accuracy: 0.7191 - val_loss: 0.8081 - val_accuracy: 0.6785\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 9s 84ms/step - loss: 0.7070 - accuracy: 0.7199 - val_loss: 0.8089 - val_accuracy: 0.6673\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 9s 89ms/step - loss: 0.7129 - accuracy: 0.7141 - val_loss: 0.8032 - val_accuracy: 0.6809\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 8s 73ms/step - loss: 0.7108 - accuracy: 0.7218 - val_loss: 0.8143 - val_accuracy: 0.6820\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 9s 88ms/step - loss: 0.7122 - accuracy: 0.7204 - val_loss: 0.8353 - val_accuracy: 0.6738\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 12s 110ms/step - loss: 0.7166 - accuracy: 0.7128 - val_loss: 0.8037 - val_accuracy: 0.6915\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 8s 76ms/step - loss: 0.7051 - accuracy: 0.7166 - val_loss: 0.8250 - val_accuracy: 0.6791\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 9s 90ms/step - loss: 0.6983 - accuracy: 0.7240 - val_loss: 0.8181 - val_accuracy: 0.6720\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 8s 74ms/step - loss: 0.6951 - accuracy: 0.7252 - val_loss: 0.8043 - val_accuracy: 0.6909\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 9s 89ms/step - loss: 0.7043 - accuracy: 0.7165 - val_loss: 0.8146 - val_accuracy: 0.6732\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 10s 91ms/step - loss: 0.7108 - accuracy: 0.7178 - val_loss: 0.8021 - val_accuracy: 0.6903\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 8s 73ms/step - loss: 0.7044 - accuracy: 0.7203 - val_loss: 0.8174 - val_accuracy: 0.6749\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 9s 89ms/step - loss: 0.6981 - accuracy: 0.7216 - val_loss: 0.7961 - val_accuracy: 0.6891\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 8s 75ms/step - loss: 0.6964 - accuracy: 0.7265 - val_loss: 0.8038 - val_accuracy: 0.6749\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 9s 86ms/step - loss: 0.7011 - accuracy: 0.7173 - val_loss: 0.8022 - val_accuracy: 0.6809\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 10s 93ms/step - loss: 0.7007 - accuracy: 0.7243 - val_loss: 0.8211 - val_accuracy: 0.6649\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 8s 74ms/step - loss: 0.6956 - accuracy: 0.7241 - val_loss: 0.8092 - val_accuracy: 0.6891\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 9s 89ms/step - loss: 0.7050 - accuracy: 0.7159 - val_loss: 0.8002 - val_accuracy: 0.6779\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 9s 82ms/step - loss: 0.6941 - accuracy: 0.7221 - val_loss: 0.8006 - val_accuracy: 0.6814\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 9s 81ms/step - loss: 0.7013 - accuracy: 0.7199 - val_loss: 0.8427 - val_accuracy: 0.6643\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 9s 89ms/step - loss: 0.6896 - accuracy: 0.7274 - val_loss: 0.8244 - val_accuracy: 0.6856\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 8s 73ms/step - loss: 0.6929 - accuracy: 0.7230 - val_loss: 0.8125 - val_accuracy: 0.6879\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 9s 89ms/step - loss: 0.7019 - accuracy: 0.7184 - val_loss: 0.7938 - val_accuracy: 0.6868\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 9s 84ms/step - loss: 0.6944 - accuracy: 0.7280 - val_loss: 0.8044 - val_accuracy: 0.6803\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 8s 80ms/step - loss: 0.6703 - accuracy: 0.7346 - val_loss: 0.7816 - val_accuracy: 0.6998\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 9s 89ms/step - loss: 0.7089 - accuracy: 0.7168 - val_loss: 0.7775 - val_accuracy: 0.6850\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 8s 74ms/step - loss: 0.6830 - accuracy: 0.7303 - val_loss: 0.7992 - val_accuracy: 0.6874\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 9s 89ms/step - loss: 0.6867 - accuracy: 0.7281 - val_loss: 0.8032 - val_accuracy: 0.6950\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 9s 86ms/step - loss: 0.6900 - accuracy: 0.7271 - val_loss: 0.7831 - val_accuracy: 0.6944\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 8s 77ms/step - loss: 0.6904 - accuracy: 0.7218 - val_loss: 0.7939 - val_accuracy: 0.6897\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 9s 89ms/step - loss: 0.6621 - accuracy: 0.7442 - val_loss: 0.7816 - val_accuracy: 0.6903\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 8s 75ms/step - loss: 0.6722 - accuracy: 0.7366 - val_loss: 0.7842 - val_accuracy: 0.7015\n",
            "56/56 [==============================] - 1s 13ms/step - loss: 0.7669 - accuracy: 0.6761\n",
            "Test Accuracy: 0.6760722398757935\n",
            "Shape of X after trimming: (1692, 22, 800)\n",
            "Shape of X after trimming: (423, 22, 800)\n",
            "Shape of X after trimming: (443, 22, 800)\n",
            "Shape of training set: (6768, 22, 400)\n",
            "Shape of validation set: (1692, 22, 400)\n",
            "Shape of training labels: (6768,)\n",
            "Shape of validation labels: (1692,)\n",
            "Shape of testing set: (1772, 22, 400)\n",
            "Shape of testing labels: (1772,)\n",
            "Shape of training labels after categorical conversion: (6768, 4)\n",
            "Shape of validation labels after categorical conversion: (1692, 4)\n",
            "Shape of test labels after categorical conversion: (1772, 4)\n",
            "Shape of training set after adding width info: (6768, 22, 400, 1)\n",
            "Shape of validation set after adding width info: (1692, 22, 400, 1)\n",
            "Shape of test set after adding width info: (1772, 22, 400, 1)\n",
            "Shape of training set after dimension reshaping: (6768, 400, 1, 22)\n",
            "Shape of validation set after dimension reshaping: (1692, 400, 1, 22)\n",
            "Shape of test set after dimension reshaping: (1772, 400, 1, 22)\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 11s 98ms/step - loss: 1.9778 - accuracy: 0.2788 - val_loss: 1.4612 - val_accuracy: 0.3292\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 9s 83ms/step - loss: 1.5833 - accuracy: 0.3100 - val_loss: 1.3698 - val_accuracy: 0.3392\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 1.4159 - accuracy: 0.3454 - val_loss: 1.3555 - val_accuracy: 0.3381\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 10s 98ms/step - loss: 1.3157 - accuracy: 0.3861 - val_loss: 1.3214 - val_accuracy: 0.3723\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 9s 81ms/step - loss: 1.2603 - accuracy: 0.4158 - val_loss: 1.3014 - val_accuracy: 0.3700\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 1.2036 - accuracy: 0.4486 - val_loss: 1.2768 - val_accuracy: 0.3966\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 1.1846 - accuracy: 0.4691 - val_loss: 1.2289 - val_accuracy: 0.4320\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 9s 82ms/step - loss: 1.1531 - accuracy: 0.4888 - val_loss: 1.2023 - val_accuracy: 0.4693\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 1.1404 - accuracy: 0.4954 - val_loss: 1.1917 - val_accuracy: 0.4947\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 1.1288 - accuracy: 0.5034 - val_loss: 1.1971 - val_accuracy: 0.4770\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 9s 81ms/step - loss: 1.0989 - accuracy: 0.5220 - val_loss: 1.1400 - val_accuracy: 0.5183\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 1.0767 - accuracy: 0.5355 - val_loss: 1.1331 - val_accuracy: 0.5236\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 1.0692 - accuracy: 0.5452 - val_loss: 1.1070 - val_accuracy: 0.5431\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 9s 81ms/step - loss: 1.0434 - accuracy: 0.5532 - val_loss: 1.1030 - val_accuracy: 0.5313\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 10s 98ms/step - loss: 1.0319 - accuracy: 0.5662 - val_loss: 1.0977 - val_accuracy: 0.5479\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 1.0127 - accuracy: 0.5767 - val_loss: 1.1031 - val_accuracy: 0.5296\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 9s 81ms/step - loss: 0.9897 - accuracy: 0.5863 - val_loss: 1.0748 - val_accuracy: 0.5786\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.9746 - accuracy: 0.5925 - val_loss: 1.0467 - val_accuracy: 0.5798\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.9556 - accuracy: 0.6102 - val_loss: 1.0245 - val_accuracy: 0.5904\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 9s 82ms/step - loss: 0.9242 - accuracy: 0.6169 - val_loss: 1.0370 - val_accuracy: 0.5786\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 10s 99ms/step - loss: 0.9026 - accuracy: 0.6371 - val_loss: 0.9596 - val_accuracy: 0.6359\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.8916 - accuracy: 0.6342 - val_loss: 0.9717 - val_accuracy: 0.6306\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 9s 81ms/step - loss: 0.8827 - accuracy: 0.6376 - val_loss: 0.9600 - val_accuracy: 0.6359\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.8561 - accuracy: 0.6525 - val_loss: 0.9996 - val_accuracy: 0.6117\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 11s 101ms/step - loss: 0.8658 - accuracy: 0.6432 - val_loss: 1.0008 - val_accuracy: 0.6111\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 9s 81ms/step - loss: 0.8427 - accuracy: 0.6634 - val_loss: 0.9485 - val_accuracy: 0.6448\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 10s 96ms/step - loss: 0.8549 - accuracy: 0.6531 - val_loss: 0.9269 - val_accuracy: 0.6655\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 10s 95ms/step - loss: 0.8395 - accuracy: 0.6659 - val_loss: 0.9098 - val_accuracy: 0.6584\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 9s 80ms/step - loss: 0.8324 - accuracy: 0.6637 - val_loss: 0.9084 - val_accuracy: 0.6667\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 10s 96ms/step - loss: 0.8231 - accuracy: 0.6676 - val_loss: 0.9080 - val_accuracy: 0.6519\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 11s 100ms/step - loss: 0.8113 - accuracy: 0.6699 - val_loss: 0.9071 - val_accuracy: 0.6596\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 9s 81ms/step - loss: 0.8054 - accuracy: 0.6767 - val_loss: 0.9008 - val_accuracy: 0.6655\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 12s 113ms/step - loss: 0.8072 - accuracy: 0.6794 - val_loss: 0.8809 - val_accuracy: 0.6797\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.8031 - accuracy: 0.6764 - val_loss: 0.8983 - val_accuracy: 0.6655\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 9s 88ms/step - loss: 0.7830 - accuracy: 0.6832 - val_loss: 0.9917 - val_accuracy: 0.6087\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 10s 90ms/step - loss: 0.7892 - accuracy: 0.6869 - val_loss: 0.8700 - val_accuracy: 0.6749\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 10s 96ms/step - loss: 0.7694 - accuracy: 0.6928 - val_loss: 0.9199 - val_accuracy: 0.6596\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 10s 90ms/step - loss: 0.7686 - accuracy: 0.6946 - val_loss: 0.8512 - val_accuracy: 0.6850\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 9s 89ms/step - loss: 0.7642 - accuracy: 0.6961 - val_loss: 0.8529 - val_accuracy: 0.6862\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 10s 99ms/step - loss: 0.7739 - accuracy: 0.6984 - val_loss: 0.9059 - val_accuracy: 0.6478\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 9s 88ms/step - loss: 0.7538 - accuracy: 0.7017 - val_loss: 0.8844 - val_accuracy: 0.6566\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 10s 89ms/step - loss: 0.7581 - accuracy: 0.6989 - val_loss: 0.8857 - val_accuracy: 0.6596\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.7430 - accuracy: 0.7024 - val_loss: 0.8970 - val_accuracy: 0.6649\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 10s 92ms/step - loss: 0.7363 - accuracy: 0.7061 - val_loss: 0.8672 - val_accuracy: 0.6809\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 9s 86ms/step - loss: 0.7330 - accuracy: 0.7147 - val_loss: 0.8766 - val_accuracy: 0.6720\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.7458 - accuracy: 0.6977 - val_loss: 0.8897 - val_accuracy: 0.6655\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 10s 95ms/step - loss: 0.7396 - accuracy: 0.7018 - val_loss: 0.8683 - val_accuracy: 0.6868\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 9s 83ms/step - loss: 0.7475 - accuracy: 0.7069 - val_loss: 0.8779 - val_accuracy: 0.6767\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 10s 96ms/step - loss: 0.7442 - accuracy: 0.6967 - val_loss: 0.8705 - val_accuracy: 0.6767\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 10s 98ms/step - loss: 0.7269 - accuracy: 0.7179 - val_loss: 0.8678 - val_accuracy: 0.6844\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 9s 82ms/step - loss: 0.7416 - accuracy: 0.7066 - val_loss: 0.8853 - val_accuracy: 0.6708\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.7220 - accuracy: 0.7117 - val_loss: 0.8798 - val_accuracy: 0.6678\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.7301 - accuracy: 0.7119 - val_loss: 0.8564 - val_accuracy: 0.6738\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 9s 81ms/step - loss: 0.7102 - accuracy: 0.7236 - val_loss: 0.8716 - val_accuracy: 0.6856\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.7025 - accuracy: 0.7206 - val_loss: 0.8470 - val_accuracy: 0.6891\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 11s 100ms/step - loss: 0.6985 - accuracy: 0.7173 - val_loss: 0.8716 - val_accuracy: 0.6726\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 9s 81ms/step - loss: 0.7089 - accuracy: 0.7216 - val_loss: 0.9135 - val_accuracy: 0.6525\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 10s 96ms/step - loss: 0.7050 - accuracy: 0.7200 - val_loss: 0.8376 - val_accuracy: 0.6856\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.7045 - accuracy: 0.7236 - val_loss: 0.8667 - val_accuracy: 0.6702\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 9s 81ms/step - loss: 0.7201 - accuracy: 0.7111 - val_loss: 0.8717 - val_accuracy: 0.6678\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 10s 96ms/step - loss: 0.7046 - accuracy: 0.7157 - val_loss: 0.8754 - val_accuracy: 0.6655\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.7106 - accuracy: 0.7224 - val_loss: 0.8467 - val_accuracy: 0.6767\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 9s 82ms/step - loss: 0.7129 - accuracy: 0.7168 - val_loss: 0.9032 - val_accuracy: 0.6578\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.7032 - accuracy: 0.7234 - val_loss: 0.8506 - val_accuracy: 0.6809\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 10s 96ms/step - loss: 0.7069 - accuracy: 0.7175 - val_loss: 0.8649 - val_accuracy: 0.6844\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 9s 81ms/step - loss: 0.6823 - accuracy: 0.7309 - val_loss: 0.8992 - val_accuracy: 0.6590\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.6874 - accuracy: 0.7358 - val_loss: 0.8496 - val_accuracy: 0.6809\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.7021 - accuracy: 0.7238 - val_loss: 0.8444 - val_accuracy: 0.6868\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 9s 82ms/step - loss: 0.6835 - accuracy: 0.7312 - val_loss: 0.8304 - val_accuracy: 0.6838\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.6828 - accuracy: 0.7339 - val_loss: 0.8331 - val_accuracy: 0.6868\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.6820 - accuracy: 0.7312 - val_loss: 0.8276 - val_accuracy: 0.6992\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 9s 82ms/step - loss: 0.6731 - accuracy: 0.7363 - val_loss: 0.8360 - val_accuracy: 0.6820\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.6669 - accuracy: 0.7371 - val_loss: 0.8033 - val_accuracy: 0.7051\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 10s 96ms/step - loss: 0.6902 - accuracy: 0.7337 - val_loss: 0.8617 - val_accuracy: 0.6785\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 9s 81ms/step - loss: 0.6735 - accuracy: 0.7324 - val_loss: 0.8655 - val_accuracy: 0.6803\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.6768 - accuracy: 0.7346 - val_loss: 0.8737 - val_accuracy: 0.6684\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 10s 96ms/step - loss: 0.6765 - accuracy: 0.7355 - val_loss: 0.8559 - val_accuracy: 0.6684\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 9s 81ms/step - loss: 0.6701 - accuracy: 0.7371 - val_loss: 0.8894 - val_accuracy: 0.6608\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 10s 96ms/step - loss: 0.6758 - accuracy: 0.7346 - val_loss: 0.8679 - val_accuracy: 0.6619\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.6818 - accuracy: 0.7311 - val_loss: 0.8297 - val_accuracy: 0.7009\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 9s 83ms/step - loss: 0.6731 - accuracy: 0.7317 - val_loss: 0.8198 - val_accuracy: 0.6980\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.6711 - accuracy: 0.7315 - val_loss: 0.8386 - val_accuracy: 0.6832\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 10s 96ms/step - loss: 0.6753 - accuracy: 0.7298 - val_loss: 0.8438 - val_accuracy: 0.6791\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 9s 82ms/step - loss: 0.6743 - accuracy: 0.7323 - val_loss: 0.8360 - val_accuracy: 0.6956\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.6549 - accuracy: 0.7435 - val_loss: 0.8436 - val_accuracy: 0.6927\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 10s 96ms/step - loss: 0.6550 - accuracy: 0.7482 - val_loss: 0.8643 - val_accuracy: 0.6726\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 9s 82ms/step - loss: 0.6701 - accuracy: 0.7361 - val_loss: 0.8102 - val_accuracy: 0.6980\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.6762 - accuracy: 0.7343 - val_loss: 0.8175 - val_accuracy: 0.6998\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.6485 - accuracy: 0.7507 - val_loss: 0.8526 - val_accuracy: 0.6862\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 9s 82ms/step - loss: 0.6686 - accuracy: 0.7413 - val_loss: 0.8367 - val_accuracy: 0.6909\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 10s 96ms/step - loss: 0.6453 - accuracy: 0.7521 - val_loss: 0.8291 - val_accuracy: 0.6968\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 10s 96ms/step - loss: 0.6480 - accuracy: 0.7469 - val_loss: 0.8289 - val_accuracy: 0.6803\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 9s 82ms/step - loss: 0.6608 - accuracy: 0.7441 - val_loss: 0.8437 - val_accuracy: 0.6820\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 10s 96ms/step - loss: 0.6579 - accuracy: 0.7373 - val_loss: 0.8547 - val_accuracy: 0.6779\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 11s 100ms/step - loss: 0.6678 - accuracy: 0.7345 - val_loss: 0.8059 - val_accuracy: 0.6956\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 9s 82ms/step - loss: 0.6418 - accuracy: 0.7497 - val_loss: 0.8241 - val_accuracy: 0.6874\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.6384 - accuracy: 0.7426 - val_loss: 0.8258 - val_accuracy: 0.6868\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 11s 102ms/step - loss: 0.6491 - accuracy: 0.7450 - val_loss: 0.8233 - val_accuracy: 0.6862\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 9s 82ms/step - loss: 0.6395 - accuracy: 0.7540 - val_loss: 0.8250 - val_accuracy: 0.6921\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.6417 - accuracy: 0.7497 - val_loss: 0.8211 - val_accuracy: 0.6862\n",
            "56/56 [==============================] - 1s 20ms/step - loss: 0.7163 - accuracy: 0.6981\n",
            "Test Accuracy: 0.6980812549591064\n",
            "Shape of X after trimming: (1692, 22, 900)\n",
            "Shape of X after trimming: (423, 22, 900)\n",
            "Shape of X after trimming: (443, 22, 900)\n",
            "Shape of training set: (6768, 22, 450)\n",
            "Shape of validation set: (1692, 22, 450)\n",
            "Shape of training labels: (6768,)\n",
            "Shape of validation labels: (1692,)\n",
            "Shape of testing set: (1772, 22, 450)\n",
            "Shape of testing labels: (1772,)\n",
            "Shape of training labels after categorical conversion: (6768, 4)\n",
            "Shape of validation labels after categorical conversion: (1692, 4)\n",
            "Shape of test labels after categorical conversion: (1772, 4)\n",
            "Shape of training set after adding width info: (6768, 22, 450, 1)\n",
            "Shape of validation set after adding width info: (1692, 22, 450, 1)\n",
            "Shape of test set after adding width info: (1772, 22, 450, 1)\n",
            "Shape of training set after dimension reshaping: (6768, 450, 1, 22)\n",
            "Shape of validation set after dimension reshaping: (1692, 450, 1, 22)\n",
            "Shape of test set after dimension reshaping: (1772, 450, 1, 22)\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 14s 125ms/step - loss: 1.9665 - accuracy: 0.2741 - val_loss: 1.4401 - val_accuracy: 0.3327\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 11s 104ms/step - loss: 1.5817 - accuracy: 0.3174 - val_loss: 1.3152 - val_accuracy: 0.3623\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 11s 100ms/step - loss: 1.4080 - accuracy: 0.3551 - val_loss: 1.2494 - val_accuracy: 0.4232\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 10s 92ms/step - loss: 1.2974 - accuracy: 0.4006 - val_loss: 1.2197 - val_accuracy: 0.4232\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 11s 104ms/step - loss: 1.2376 - accuracy: 0.4360 - val_loss: 1.1866 - val_accuracy: 0.4397\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 11s 104ms/step - loss: 1.1990 - accuracy: 0.4573 - val_loss: 1.1790 - val_accuracy: 0.4710\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 10s 98ms/step - loss: 1.1770 - accuracy: 0.4676 - val_loss: 1.1976 - val_accuracy: 0.4604\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 10s 95ms/step - loss: 1.1491 - accuracy: 0.4898 - val_loss: 1.1560 - val_accuracy: 0.4923\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 11s 104ms/step - loss: 1.1289 - accuracy: 0.5040 - val_loss: 1.1222 - val_accuracy: 0.5095\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 11s 104ms/step - loss: 1.1137 - accuracy: 0.5114 - val_loss: 1.1226 - val_accuracy: 0.5213\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 1.0989 - accuracy: 0.5238 - val_loss: 1.0926 - val_accuracy: 0.5396\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 10s 96ms/step - loss: 1.0749 - accuracy: 0.5358 - val_loss: 1.0964 - val_accuracy: 0.5455\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 11s 104ms/step - loss: 1.0538 - accuracy: 0.5470 - val_loss: 1.0879 - val_accuracy: 0.5361\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 11s 104ms/step - loss: 1.0222 - accuracy: 0.5715 - val_loss: 1.0303 - val_accuracy: 0.5745\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 9s 89ms/step - loss: 1.0051 - accuracy: 0.5761 - val_loss: 0.9892 - val_accuracy: 0.6082\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 11s 103ms/step - loss: 0.9714 - accuracy: 0.5907 - val_loss: 0.9833 - val_accuracy: 0.6087\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 11s 104ms/step - loss: 0.9609 - accuracy: 0.6000 - val_loss: 0.9669 - val_accuracy: 0.6141\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.9387 - accuracy: 0.6170 - val_loss: 0.9082 - val_accuracy: 0.6608\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 9s 89ms/step - loss: 0.9063 - accuracy: 0.6281 - val_loss: 0.8917 - val_accuracy: 0.6566\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.9038 - accuracy: 0.6299 - val_loss: 0.9413 - val_accuracy: 0.6241\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 11s 104ms/step - loss: 0.8966 - accuracy: 0.6318 - val_loss: 0.9030 - val_accuracy: 0.6483\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 11s 103ms/step - loss: 0.8905 - accuracy: 0.6302 - val_loss: 0.9013 - val_accuracy: 0.6436\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 10s 89ms/step - loss: 0.8783 - accuracy: 0.6407 - val_loss: 0.8747 - val_accuracy: 0.6489\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 11s 104ms/step - loss: 0.8685 - accuracy: 0.6479 - val_loss: 0.8738 - val_accuracy: 0.6554\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 11s 104ms/step - loss: 0.8631 - accuracy: 0.6488 - val_loss: 0.8774 - val_accuracy: 0.6525\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 11s 99ms/step - loss: 0.8569 - accuracy: 0.6560 - val_loss: 0.8742 - val_accuracy: 0.6430\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 10s 94ms/step - loss: 0.8385 - accuracy: 0.6579 - val_loss: 0.8762 - val_accuracy: 0.6383\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 11s 104ms/step - loss: 0.8414 - accuracy: 0.6593 - val_loss: 0.8730 - val_accuracy: 0.6501\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 11s 104ms/step - loss: 0.8233 - accuracy: 0.6698 - val_loss: 0.8478 - val_accuracy: 0.6649\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 10s 96ms/step - loss: 0.8294 - accuracy: 0.6646 - val_loss: 0.8725 - val_accuracy: 0.6554\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.8187 - accuracy: 0.6693 - val_loss: 0.8587 - val_accuracy: 0.6495\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 11s 104ms/step - loss: 0.8340 - accuracy: 0.6662 - val_loss: 0.8412 - val_accuracy: 0.6649\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 11s 104ms/step - loss: 0.8080 - accuracy: 0.6738 - val_loss: 0.8489 - val_accuracy: 0.6684\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 9s 90ms/step - loss: 0.8003 - accuracy: 0.6767 - val_loss: 0.8669 - val_accuracy: 0.6667\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 11s 103ms/step - loss: 0.8126 - accuracy: 0.6673 - val_loss: 0.8491 - val_accuracy: 0.6548\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 11s 104ms/step - loss: 0.8015 - accuracy: 0.6745 - val_loss: 0.8334 - val_accuracy: 0.6743\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.7935 - accuracy: 0.6788 - val_loss: 0.8374 - val_accuracy: 0.6797\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 9s 89ms/step - loss: 0.7940 - accuracy: 0.6848 - val_loss: 0.7959 - val_accuracy: 0.6897\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.7673 - accuracy: 0.6910 - val_loss: 0.8082 - val_accuracy: 0.7021\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.7750 - accuracy: 0.6887 - val_loss: 0.7959 - val_accuracy: 0.6962\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 11s 101ms/step - loss: 0.7896 - accuracy: 0.6809 - val_loss: 0.8062 - val_accuracy: 0.6850\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 10s 91ms/step - loss: 0.7853 - accuracy: 0.6859 - val_loss: 0.7753 - val_accuracy: 0.7051\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.7680 - accuracy: 0.6952 - val_loss: 0.7896 - val_accuracy: 0.7110\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.7572 - accuracy: 0.6955 - val_loss: 0.8230 - val_accuracy: 0.6643\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 11s 99ms/step - loss: 0.7739 - accuracy: 0.6882 - val_loss: 0.7851 - val_accuracy: 0.7069\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 10s 94ms/step - loss: 0.7698 - accuracy: 0.6887 - val_loss: 0.7821 - val_accuracy: 0.7098\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 11s 104ms/step - loss: 0.7701 - accuracy: 0.6908 - val_loss: 0.7856 - val_accuracy: 0.7163\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 11s 104ms/step - loss: 0.7641 - accuracy: 0.6952 - val_loss: 0.7797 - val_accuracy: 0.7063\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.7415 - accuracy: 0.6986 - val_loss: 0.7971 - val_accuracy: 0.6974\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 10s 98ms/step - loss: 0.7527 - accuracy: 0.6949 - val_loss: 0.8267 - val_accuracy: 0.6915\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.7441 - accuracy: 0.7043 - val_loss: 0.7830 - val_accuracy: 0.7086\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.7456 - accuracy: 0.6943 - val_loss: 0.7611 - val_accuracy: 0.7305\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 10s 96ms/step - loss: 0.7469 - accuracy: 0.7033 - val_loss: 0.7665 - val_accuracy: 0.7234\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 10s 98ms/step - loss: 0.7475 - accuracy: 0.6999 - val_loss: 0.7732 - val_accuracy: 0.7246\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.7291 - accuracy: 0.7117 - val_loss: 0.7621 - val_accuracy: 0.7080\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.7333 - accuracy: 0.7020 - val_loss: 0.7670 - val_accuracy: 0.7116\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 10s 96ms/step - loss: 0.7298 - accuracy: 0.7080 - val_loss: 0.7733 - val_accuracy: 0.7157\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 11s 103ms/step - loss: 0.7213 - accuracy: 0.7104 - val_loss: 0.7680 - val_accuracy: 0.7151\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.7230 - accuracy: 0.7107 - val_loss: 0.7633 - val_accuracy: 0.7157\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.7197 - accuracy: 0.7072 - val_loss: 0.7880 - val_accuracy: 0.7092\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.7348 - accuracy: 0.7015 - val_loss: 0.7593 - val_accuracy: 0.7210\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.7187 - accuracy: 0.7153 - val_loss: 0.7615 - val_accuracy: 0.7240\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 11s 104ms/step - loss: 0.7108 - accuracy: 0.7148 - val_loss: 0.7663 - val_accuracy: 0.7134\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 11s 104ms/step - loss: 0.7219 - accuracy: 0.7095 - val_loss: 0.7670 - val_accuracy: 0.7175\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.7078 - accuracy: 0.7230 - val_loss: 0.7411 - val_accuracy: 0.7335\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 11s 99ms/step - loss: 0.7124 - accuracy: 0.7148 - val_loss: 0.7466 - val_accuracy: 0.7329\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.7095 - accuracy: 0.7181 - val_loss: 0.7687 - val_accuracy: 0.7145\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.7305 - accuracy: 0.7134 - val_loss: 0.7901 - val_accuracy: 0.6950\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 10s 96ms/step - loss: 0.6924 - accuracy: 0.7236 - val_loss: 0.7885 - val_accuracy: 0.6885\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 10s 98ms/step - loss: 0.7036 - accuracy: 0.7131 - val_loss: 0.7680 - val_accuracy: 0.7175\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.7005 - accuracy: 0.7163 - val_loss: 0.7440 - val_accuracy: 0.7181\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.7061 - accuracy: 0.7145 - val_loss: 0.7616 - val_accuracy: 0.7187\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.7032 - accuracy: 0.7193 - val_loss: 0.7397 - val_accuracy: 0.7187\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 11s 99ms/step - loss: 0.7057 - accuracy: 0.7234 - val_loss: 0.7578 - val_accuracy: 0.7063\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.6958 - accuracy: 0.7197 - val_loss: 0.7482 - val_accuracy: 0.7175\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 11s 104ms/step - loss: 0.6919 - accuracy: 0.7241 - val_loss: 0.7585 - val_accuracy: 0.7157\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 10s 91ms/step - loss: 0.6989 - accuracy: 0.7206 - val_loss: 0.7568 - val_accuracy: 0.7157\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 11s 104ms/step - loss: 0.6757 - accuracy: 0.7329 - val_loss: 0.7821 - val_accuracy: 0.7080\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.6828 - accuracy: 0.7278 - val_loss: 0.7572 - val_accuracy: 0.7145\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 11s 104ms/step - loss: 0.6969 - accuracy: 0.7270 - val_loss: 0.7474 - val_accuracy: 0.7287\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 10s 90ms/step - loss: 0.6784 - accuracy: 0.7272 - val_loss: 0.7191 - val_accuracy: 0.7340\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.6940 - accuracy: 0.7256 - val_loss: 0.7506 - val_accuracy: 0.7204\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.6749 - accuracy: 0.7317 - val_loss: 0.7686 - val_accuracy: 0.7069\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 11s 103ms/step - loss: 0.6874 - accuracy: 0.7298 - val_loss: 0.7375 - val_accuracy: 0.7157\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 10s 92ms/step - loss: 0.7051 - accuracy: 0.7187 - val_loss: 0.7581 - val_accuracy: 0.6980\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.6709 - accuracy: 0.7272 - val_loss: 0.7490 - val_accuracy: 0.7187\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.6702 - accuracy: 0.7354 - val_loss: 0.7485 - val_accuracy: 0.7275\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 11s 102ms/step - loss: 0.6653 - accuracy: 0.7366 - val_loss: 0.7357 - val_accuracy: 0.7193\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 10s 92ms/step - loss: 0.6913 - accuracy: 0.7246 - val_loss: 0.7592 - val_accuracy: 0.6980\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.6812 - accuracy: 0.7315 - val_loss: 0.7537 - val_accuracy: 0.7187\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.6758 - accuracy: 0.7299 - val_loss: 0.7083 - val_accuracy: 0.7329\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 11s 99ms/step - loss: 0.6801 - accuracy: 0.7317 - val_loss: 0.7259 - val_accuracy: 0.7240\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 10s 95ms/step - loss: 0.6685 - accuracy: 0.7343 - val_loss: 0.7330 - val_accuracy: 0.7240\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.6678 - accuracy: 0.7337 - val_loss: 0.7389 - val_accuracy: 0.7258\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.6851 - accuracy: 0.7281 - val_loss: 0.7520 - val_accuracy: 0.7080\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.6670 - accuracy: 0.7321 - val_loss: 0.7482 - val_accuracy: 0.7246\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 11s 99ms/step - loss: 0.6684 - accuracy: 0.7363 - val_loss: 0.7457 - val_accuracy: 0.7281\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.6788 - accuracy: 0.7303 - val_loss: 0.7611 - val_accuracy: 0.7092\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.6615 - accuracy: 0.7432 - val_loss: 0.7316 - val_accuracy: 0.7270\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 10s 90ms/step - loss: 0.6733 - accuracy: 0.7355 - val_loss: 0.7614 - val_accuracy: 0.7009\n",
            "56/56 [==============================] - 1s 16ms/step - loss: 0.7486 - accuracy: 0.7071\n",
            "Test Accuracy: 0.707110583782196\n",
            "Shape of X after trimming: (1692, 22, 1000)\n",
            "Shape of X after trimming: (423, 22, 1000)\n",
            "Shape of X after trimming: (443, 22, 1000)\n",
            "Shape of training set: (6768, 22, 500)\n",
            "Shape of validation set: (1692, 22, 500)\n",
            "Shape of training labels: (6768,)\n",
            "Shape of validation labels: (1692,)\n",
            "Shape of testing set: (1772, 22, 500)\n",
            "Shape of testing labels: (1772,)\n",
            "Shape of training labels after categorical conversion: (6768, 4)\n",
            "Shape of validation labels after categorical conversion: (1692, 4)\n",
            "Shape of test labels after categorical conversion: (1772, 4)\n",
            "Shape of training set after adding width info: (6768, 22, 500, 1)\n",
            "Shape of validation set after adding width info: (1692, 22, 500, 1)\n",
            "Shape of test set after adding width info: (1772, 22, 500, 1)\n",
            "Shape of training set after dimension reshaping: (6768, 500, 1, 22)\n",
            "Shape of validation set after dimension reshaping: (1692, 500, 1, 22)\n",
            "Shape of test set after dimension reshaping: (1772, 500, 1, 22)\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 18s 155ms/step - loss: 2.0238 - accuracy: 0.2796 - val_loss: 1.4280 - val_accuracy: 0.3428\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 12s 111ms/step - loss: 1.6231 - accuracy: 0.3087 - val_loss: 1.3247 - val_accuracy: 0.3824\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 12s 111ms/step - loss: 1.4487 - accuracy: 0.3326 - val_loss: 1.2832 - val_accuracy: 0.4060\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 1.3609 - accuracy: 0.3664 - val_loss: 1.2386 - val_accuracy: 0.4480\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 12s 112ms/step - loss: 1.2719 - accuracy: 0.4178 - val_loss: 1.1798 - val_accuracy: 0.4894\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 12s 112ms/step - loss: 1.2281 - accuracy: 0.4475 - val_loss: 1.1520 - val_accuracy: 0.5100\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 12s 113ms/step - loss: 1.1828 - accuracy: 0.4798 - val_loss: 1.0892 - val_accuracy: 0.5349\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 12s 109ms/step - loss: 1.1594 - accuracy: 0.4928 - val_loss: 1.0690 - val_accuracy: 0.5538\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 11s 101ms/step - loss: 1.1254 - accuracy: 0.5126 - val_loss: 1.0465 - val_accuracy: 0.5745\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 12s 113ms/step - loss: 1.0972 - accuracy: 0.5293 - val_loss: 1.0000 - val_accuracy: 0.5963\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 12s 112ms/step - loss: 1.0733 - accuracy: 0.5491 - val_loss: 0.9823 - val_accuracy: 0.6117\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 12s 113ms/step - loss: 1.0556 - accuracy: 0.5559 - val_loss: 0.9682 - val_accuracy: 0.5969\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 12s 110ms/step - loss: 1.0146 - accuracy: 0.5857 - val_loss: 0.9403 - val_accuracy: 0.6158\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 11s 100ms/step - loss: 1.0103 - accuracy: 0.5807 - val_loss: 0.9078 - val_accuracy: 0.6288\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 12s 112ms/step - loss: 0.9829 - accuracy: 0.5950 - val_loss: 0.8860 - val_accuracy: 0.6300\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 12s 113ms/step - loss: 0.9752 - accuracy: 0.5943 - val_loss: 0.8693 - val_accuracy: 0.6430\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 12s 112ms/step - loss: 0.9436 - accuracy: 0.6148 - val_loss: 0.8415 - val_accuracy: 0.6543\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 12s 112ms/step - loss: 0.9412 - accuracy: 0.6111 - val_loss: 0.8300 - val_accuracy: 0.6631\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 10s 98ms/step - loss: 0.9230 - accuracy: 0.6272 - val_loss: 0.8296 - val_accuracy: 0.6560\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 12s 111ms/step - loss: 0.8945 - accuracy: 0.6407 - val_loss: 0.8331 - val_accuracy: 0.6554\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 12s 113ms/step - loss: 0.8993 - accuracy: 0.6386 - val_loss: 0.8084 - val_accuracy: 0.6572\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 12s 113ms/step - loss: 0.8873 - accuracy: 0.6457 - val_loss: 0.8073 - val_accuracy: 0.6590\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 12s 114ms/step - loss: 0.8855 - accuracy: 0.6476 - val_loss: 0.8101 - val_accuracy: 0.6637\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 11s 104ms/step - loss: 0.8617 - accuracy: 0.6538 - val_loss: 0.8260 - val_accuracy: 0.6643\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 11s 107ms/step - loss: 0.8630 - accuracy: 0.6531 - val_loss: 0.7806 - val_accuracy: 0.6732\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 12s 114ms/step - loss: 0.8457 - accuracy: 0.6605 - val_loss: 0.8013 - val_accuracy: 0.6761\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 12s 113ms/step - loss: 0.8470 - accuracy: 0.6633 - val_loss: 0.7744 - val_accuracy: 0.6803\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 12s 112ms/step - loss: 0.8378 - accuracy: 0.6625 - val_loss: 0.7955 - val_accuracy: 0.6684\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.8432 - accuracy: 0.6588 - val_loss: 0.7893 - val_accuracy: 0.6684\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.8368 - accuracy: 0.6671 - val_loss: 0.7627 - val_accuracy: 0.6844\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 12s 113ms/step - loss: 0.8154 - accuracy: 0.6783 - val_loss: 0.7719 - val_accuracy: 0.6797\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 12s 114ms/step - loss: 0.8282 - accuracy: 0.6714 - val_loss: 0.7746 - val_accuracy: 0.6743\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 12s 113ms/step - loss: 0.8114 - accuracy: 0.6752 - val_loss: 0.7789 - val_accuracy: 0.6755\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 11s 107ms/step - loss: 0.8064 - accuracy: 0.6800 - val_loss: 0.7602 - val_accuracy: 0.6767\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 11s 103ms/step - loss: 0.7971 - accuracy: 0.6813 - val_loss: 0.7439 - val_accuracy: 0.6844\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 12s 113ms/step - loss: 0.7891 - accuracy: 0.6829 - val_loss: 0.7746 - val_accuracy: 0.6690\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 12s 113ms/step - loss: 0.7865 - accuracy: 0.6823 - val_loss: 0.7741 - val_accuracy: 0.6809\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 12s 112ms/step - loss: 0.7931 - accuracy: 0.6779 - val_loss: 0.7824 - val_accuracy: 0.6696\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 11s 108ms/step - loss: 0.7971 - accuracy: 0.6857 - val_loss: 0.7590 - val_accuracy: 0.6944\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 11s 102ms/step - loss: 0.7957 - accuracy: 0.6874 - val_loss: 0.7721 - val_accuracy: 0.6856\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 12s 114ms/step - loss: 0.7772 - accuracy: 0.6885 - val_loss: 0.7595 - val_accuracy: 0.6732\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 12s 113ms/step - loss: 0.7586 - accuracy: 0.6983 - val_loss: 0.7601 - val_accuracy: 0.6631\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 12s 113ms/step - loss: 0.7607 - accuracy: 0.7042 - val_loss: 0.7452 - val_accuracy: 0.6885\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 11s 107ms/step - loss: 0.7570 - accuracy: 0.7020 - val_loss: 0.7123 - val_accuracy: 0.7086\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 11s 104ms/step - loss: 0.7622 - accuracy: 0.6959 - val_loss: 0.7371 - val_accuracy: 0.6832\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 12s 113ms/step - loss: 0.7631 - accuracy: 0.6959 - val_loss: 0.7399 - val_accuracy: 0.6950\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 12s 113ms/step - loss: 0.7589 - accuracy: 0.7009 - val_loss: 0.7301 - val_accuracy: 0.6690\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 12s 112ms/step - loss: 0.7488 - accuracy: 0.7085 - val_loss: 0.7148 - val_accuracy: 0.6980\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 11s 108ms/step - loss: 0.7476 - accuracy: 0.7092 - val_loss: 0.7113 - val_accuracy: 0.7021\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 11s 102ms/step - loss: 0.7487 - accuracy: 0.7076 - val_loss: 0.7365 - val_accuracy: 0.6874\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 12s 113ms/step - loss: 0.7472 - accuracy: 0.7049 - val_loss: 0.7450 - val_accuracy: 0.6761\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 12s 113ms/step - loss: 0.7351 - accuracy: 0.7082 - val_loss: 0.7240 - val_accuracy: 0.6956\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 12s 113ms/step - loss: 0.7481 - accuracy: 0.7066 - val_loss: 0.7198 - val_accuracy: 0.7015\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 11s 108ms/step - loss: 0.7398 - accuracy: 0.7072 - val_loss: 0.7227 - val_accuracy: 0.6986\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 11s 103ms/step - loss: 0.7394 - accuracy: 0.7054 - val_loss: 0.7269 - val_accuracy: 0.6980\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 12s 113ms/step - loss: 0.7269 - accuracy: 0.7160 - val_loss: 0.7284 - val_accuracy: 0.6921\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 12s 113ms/step - loss: 0.7438 - accuracy: 0.7057 - val_loss: 0.7105 - val_accuracy: 0.6897\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 12s 113ms/step - loss: 0.7227 - accuracy: 0.7171 - val_loss: 0.7096 - val_accuracy: 0.7092\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 11s 108ms/step - loss: 0.7282 - accuracy: 0.7145 - val_loss: 0.7133 - val_accuracy: 0.7033\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 11s 103ms/step - loss: 0.7287 - accuracy: 0.7092 - val_loss: 0.7059 - val_accuracy: 0.6956\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 12s 113ms/step - loss: 0.7080 - accuracy: 0.7206 - val_loss: 0.7073 - val_accuracy: 0.7045\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 12s 114ms/step - loss: 0.7237 - accuracy: 0.7137 - val_loss: 0.6835 - val_accuracy: 0.7139\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 12s 118ms/step - loss: 0.7394 - accuracy: 0.7113 - val_loss: 0.7025 - val_accuracy: 0.7104\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 12s 111ms/step - loss: 0.7119 - accuracy: 0.7172 - val_loss: 0.7391 - val_accuracy: 0.6962\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 11s 100ms/step - loss: 0.7081 - accuracy: 0.7165 - val_loss: 0.7010 - val_accuracy: 0.7122\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 12s 114ms/step - loss: 0.6973 - accuracy: 0.7236 - val_loss: 0.6994 - val_accuracy: 0.7086\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 12s 113ms/step - loss: 0.7085 - accuracy: 0.7255 - val_loss: 0.7052 - val_accuracy: 0.6980\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 12s 114ms/step - loss: 0.7086 - accuracy: 0.7165 - val_loss: 0.6910 - val_accuracy: 0.7122\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 12s 110ms/step - loss: 0.7089 - accuracy: 0.7181 - val_loss: 0.7090 - val_accuracy: 0.6998\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 11s 101ms/step - loss: 0.6915 - accuracy: 0.7268 - val_loss: 0.6984 - val_accuracy: 0.6968\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 12s 113ms/step - loss: 0.6973 - accuracy: 0.7253 - val_loss: 0.6836 - val_accuracy: 0.7199\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 12s 113ms/step - loss: 0.7010 - accuracy: 0.7261 - val_loss: 0.6652 - val_accuracy: 0.7275\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 12s 114ms/step - loss: 0.6948 - accuracy: 0.7250 - val_loss: 0.7170 - val_accuracy: 0.6897\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 12s 110ms/step - loss: 0.7017 - accuracy: 0.7210 - val_loss: 0.7102 - val_accuracy: 0.6856\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 11s 101ms/step - loss: 0.6817 - accuracy: 0.7335 - val_loss: 0.7059 - val_accuracy: 0.6968\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 12s 114ms/step - loss: 0.6907 - accuracy: 0.7241 - val_loss: 0.7238 - val_accuracy: 0.6956\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 12s 113ms/step - loss: 0.7055 - accuracy: 0.7150 - val_loss: 0.6992 - val_accuracy: 0.7199\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 12s 114ms/step - loss: 0.7056 - accuracy: 0.7213 - val_loss: 0.6726 - val_accuracy: 0.7270\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 12s 110ms/step - loss: 0.6990 - accuracy: 0.7252 - val_loss: 0.7018 - val_accuracy: 0.7098\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 11s 100ms/step - loss: 0.6794 - accuracy: 0.7305 - val_loss: 0.7016 - val_accuracy: 0.7139\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 12s 114ms/step - loss: 0.6819 - accuracy: 0.7317 - val_loss: 0.6893 - val_accuracy: 0.7181\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 12s 113ms/step - loss: 0.6729 - accuracy: 0.7371 - val_loss: 0.6969 - val_accuracy: 0.7116\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 12s 113ms/step - loss: 0.6808 - accuracy: 0.7389 - val_loss: 0.6982 - val_accuracy: 0.7128\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 12s 112ms/step - loss: 0.6703 - accuracy: 0.7376 - val_loss: 0.6961 - val_accuracy: 0.7228\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 11s 102ms/step - loss: 0.6787 - accuracy: 0.7315 - val_loss: 0.7210 - val_accuracy: 0.7004\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 12s 114ms/step - loss: 0.6740 - accuracy: 0.7379 - val_loss: 0.6807 - val_accuracy: 0.7110\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 12s 113ms/step - loss: 0.6736 - accuracy: 0.7351 - val_loss: 0.7071 - val_accuracy: 0.7051\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 12s 114ms/step - loss: 0.6635 - accuracy: 0.7346 - val_loss: 0.6833 - val_accuracy: 0.7340\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 12s 114ms/step - loss: 0.6773 - accuracy: 0.7354 - val_loss: 0.6921 - val_accuracy: 0.7246\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 11s 104ms/step - loss: 0.6624 - accuracy: 0.7376 - val_loss: 0.7104 - val_accuracy: 0.7086\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 12s 108ms/step - loss: 0.6828 - accuracy: 0.7346 - val_loss: 0.6826 - val_accuracy: 0.7287\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 12s 114ms/step - loss: 0.6579 - accuracy: 0.7380 - val_loss: 0.6975 - val_accuracy: 0.7193\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 12s 114ms/step - loss: 0.6518 - accuracy: 0.7426 - val_loss: 0.7318 - val_accuracy: 0.7015\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 12s 114ms/step - loss: 0.6744 - accuracy: 0.7398 - val_loss: 0.6718 - val_accuracy: 0.7364\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 11s 108ms/step - loss: 0.6519 - accuracy: 0.7411 - val_loss: 0.7053 - val_accuracy: 0.7193\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 11s 104ms/step - loss: 0.6696 - accuracy: 0.7402 - val_loss: 0.6989 - val_accuracy: 0.7258\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 12s 114ms/step - loss: 0.6636 - accuracy: 0.7402 - val_loss: 0.6737 - val_accuracy: 0.7329\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 12s 114ms/step - loss: 0.6608 - accuracy: 0.7397 - val_loss: 0.6766 - val_accuracy: 0.7358\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 12s 114ms/step - loss: 0.6535 - accuracy: 0.7445 - val_loss: 0.6838 - val_accuracy: 0.7299\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 12s 110ms/step - loss: 0.6653 - accuracy: 0.7419 - val_loss: 0.6861 - val_accuracy: 0.7264\n",
            "56/56 [==============================] - 1s 19ms/step - loss: 0.7339 - accuracy: 0.6981\n",
            "Test Accuracy: 0.6980812549591064\n"
          ]
        }
      ],
      "source": [
        "accuracies = []\n",
        "for i, trim_ratio in enumerate(np.arange(0, 1.1, step=.1)):\n",
        "    if i == 0:\n",
        "        continue\n",
        "    cnn, cnn_training_results, cnn_test_score = cnn_model(trim_ratio=trim_ratio)\n",
        "    accuracies.append(cnn_test_score)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "x = list(range(100, 1100, 100))\n",
        "scores = []\n",
        "for i in range(len(accuracies)):\n",
        "  scores.append(accuracies[i][1])\n",
        "plt.plot(x, scores, '-o')\n",
        "plt.title('CNN Model Test Accuracy for Each Time Step')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('time')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "VOasGKp_Gk_3",
        "outputId": "2aec9cd0-18e5-4ab1-86b0-85282c85f157"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2WzgzC_GKSD"
      },
      "source": [
        "# Deeper exploration and analysis into other architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o90blBQLGKSE"
      },
      "source": [
        "## CRNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VTgXGrQGKSE"
      },
      "source": [
        "#### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "DeatquGHGKSE"
      },
      "outputs": [],
      "source": [
        "def preprocess():\n",
        "    X_test = np.load(\"X_test.npy\")\n",
        "    y_test = np.load(\"y_test.npy\")\n",
        "    person_train_valid = np.load(\"person_train_valid.npy\")\n",
        "    X_train_valid = np.load(\"X_train_valid.npy\")\n",
        "    y_train_valid = np.load(\"y_train_valid.npy\")\n",
        "    person_test = np.load(\"person_test.npy\")\n",
        "\n",
        "    ## Adjusting the labels so that \n",
        "\n",
        "    # Cue onset left - 0\n",
        "    # Cue onset right - 1\n",
        "    # Cue onset foot - 2\n",
        "    # Cue onset tongue - 3\n",
        "\n",
        "    y_train_valid -= 769\n",
        "    y_test -= 769\n",
        "    \n",
        "\n",
        "    # shuffle with 5 fold\n",
        "    indicies_valid = np.random.choice(X_train_valid.shape[0], X_train_valid.shape[0] // 5, replace=False)\n",
        "    indicies_train = np.array(list(set(range(X_train_valid.shape[0])).difference(set(indicies_valid))))\n",
        "\n",
        "    # Creating the training and validation sets using the generated indices\n",
        "    X_train, X_valid = X_train_valid[indicies_train], X_train_valid[indicies_valid] \n",
        "    y_train, y_valid = y_train_valid[indicies_train], y_train_valid[indicies_valid]\n",
        "\n",
        "\n",
        "    # Preprocessing the dataset\n",
        "    x_train,y_train = data_prep(X_train,y_train,2,2,True)\n",
        "    x_valid,y_valid = data_prep(X_valid,y_valid,2,2,True)\n",
        "    X_test_prep,y_test_prep = data_prep(X_test,y_test,2,2,True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Converting the labels to categorical variables for multiclass classification\n",
        "    y_train = to_categorical(y_train, 4)\n",
        "    y_valid = to_categorical(y_valid, 4)\n",
        "    y_test = to_categorical(y_test_prep, 4)\n",
        "    # print('Shape of training labels after categorical conversion:',y_train.shape)\n",
        "    # print('Shape of validation labels after categorical conversion:',y_valid.shape)\n",
        "    # print('Shape of test labels after categorical conversion:',y_test.shape)\n",
        "\n",
        "    # Adding width of the segment to be 1\n",
        "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "    x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
        "    x_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n",
        "    # print('Shape of training set after adding width info:',x_train.shape)\n",
        "    # print('Shape of validation set after adding width info:',x_valid.shape)\n",
        "    # print('Shape of test set after adding width info:',x_test.shape)\n",
        "\n",
        "\n",
        "    # Reshaping the training and validation dataset\n",
        "    x_train = np.swapaxes(x_train, 1,3)\n",
        "    x_train = np.swapaxes(x_train, 1,2)\n",
        "    x_valid = np.swapaxes(x_valid, 1,3)\n",
        "    x_valid = np.swapaxes(x_valid, 1,2)\n",
        "    x_test = np.swapaxes(x_test, 1,3)\n",
        "    x_test = np.swapaxes(x_test, 1,2)\n",
        "    # print('Shape of training set after dimension reshaping:',x_train.shape)\n",
        "    # print('Shape of validation set after dimension reshaping:',x_valid.shape)\n",
        "    # print('Shape of test set after dimension reshaping:',x_test.shape)\n",
        "\n",
        "    return (x_train, y_train, x_valid, y_valid, x_test, y_test)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlttvDj9GKSF"
      },
      "source": [
        "#### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ryZ6wA8kGKSF"
      },
      "outputs": [],
      "source": [
        "def cnn_lstm_model():    \n",
        "    # Building the CNN model using sequential class\n",
        "    cnn_lstm_model = Sequential()\n",
        "\n",
        "    # Conv. block 1\n",
        "    cnn_lstm_model.add(Conv2D(filters=20, kernel_size=(5,1), padding='same', activation='elu', input_shape=(250,1,22)))\n",
        "    cnn_lstm_model.add(MaxPooling2D(pool_size=(3,1), padding='same')) \n",
        "    cnn_lstm_model.add(BatchNormalization())\n",
        "    cnn_lstm_model.add(Dropout(0.5))\n",
        "\n",
        "    # Conv. block 2\n",
        "    cnn_lstm_model.add(Conv2D(filters=20, kernel_size=(15,1), padding='same', activation='elu'))\n",
        "    cnn_lstm_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
        "    cnn_lstm_model.add(BatchNormalization())\n",
        "    cnn_lstm_model.add(Dropout(0.5))\n",
        "\n",
        "    # Conv. block 3\n",
        "    cnn_lstm_model.add(Conv2D(filters=10, kernel_size=(10,1), padding='same', activation='elu'))\n",
        "    cnn_lstm_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
        "    cnn_lstm_model.add(BatchNormalization())\n",
        "    cnn_lstm_model.add(Dropout(0.5))\n",
        "\n",
        "    # Add LSTM layers\n",
        "    cnn_lstm_model.add(Permute((2, 3, 1)))\n",
        "    cnn_lstm_model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "    cnn_lstm_model.add(LSTM(250, return_sequences=True))\n",
        "    cnn_lstm_model.add(Dropout(0.5))\n",
        "    cnn_lstm_model.add(LSTM(100, return_sequences=True))\n",
        "    cnn_lstm_model.add(Dropout(0.5))\n",
        "    cnn_lstm_model.add(LSTM(50))\n",
        "\n",
        "    # Output layer with Softmax activation\n",
        "    cnn_lstm_model.add(Flatten()) # Flattens the input\n",
        "    cnn_lstm_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
        "\n",
        "\n",
        "    return cnn_lstm_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSVrfaYHGKSF"
      },
      "source": [
        "#### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "eG-vBkq8GKSG"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "epochs = 100\n",
        "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "noise_dim = 100\n",
        "num_classes = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJn0Lf-JGKSG"
      },
      "source": [
        "#### Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "g_1PoFDwGKSH",
        "outputId": "54e0bce8-c7af-497e-88f2-0451359939c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_40 (Conv2D)          (None, 250, 1, 20)        2220      \n",
            "                                                                 \n",
            " max_pooling2d_40 (MaxPoolin  (None, 84, 1, 20)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_40 (Bat  (None, 84, 1, 20)        80        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 84, 1, 20)         0         \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (None, 84, 1, 20)         6020      \n",
            "                                                                 \n",
            " max_pooling2d_41 (MaxPoolin  (None, 28, 1, 20)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_41 (Bat  (None, 28, 1, 20)        80        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 28, 1, 20)         0         \n",
            "                                                                 \n",
            " conv2d_42 (Conv2D)          (None, 28, 1, 10)         2010      \n",
            "                                                                 \n",
            " max_pooling2d_42 (MaxPoolin  (None, 10, 1, 10)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_42 (Bat  (None, 10, 1, 10)        40        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_44 (Dropout)        (None, 10, 1, 10)         0         \n",
            "                                                                 \n",
            " permute_1 (Permute)         (None, 1, 10, 10)         0         \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 1, 100)           0         \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 1, 250)            351000    \n",
            "                                                                 \n",
            " dropout_45 (Dropout)        (None, 1, 250)            0         \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 1, 100)            140400    \n",
            "                                                                 \n",
            " dropout_46 (Dropout)        (None, 1, 100)            0         \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 50)                30200     \n",
            "                                                                 \n",
            " flatten_16 (Flatten)        (None, 50)                0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 4)                 204       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 532,254\n",
            "Trainable params: 532,154\n",
            "Non-trainable params: 100\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 15s 82ms/step - loss: 1.3627 - accuracy: 0.3143 - val_loss: 1.3114 - val_accuracy: 0.3877\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 7s 69ms/step - loss: 1.2513 - accuracy: 0.4270 - val_loss: 1.1804 - val_accuracy: 0.4397\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 9s 86ms/step - loss: 1.1992 - accuracy: 0.4532 - val_loss: 1.1515 - val_accuracy: 0.4675\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 7s 66ms/step - loss: 1.1743 - accuracy: 0.4731 - val_loss: 1.1222 - val_accuracy: 0.4923\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 9s 81ms/step - loss: 1.1511 - accuracy: 0.4866 - val_loss: 1.1310 - val_accuracy: 0.4870\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 6s 60ms/step - loss: 1.1301 - accuracy: 0.4993 - val_loss: 1.1132 - val_accuracy: 0.4970\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 1.1120 - accuracy: 0.5177 - val_loss: 1.0716 - val_accuracy: 0.5307\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 6s 60ms/step - loss: 1.0888 - accuracy: 0.5325 - val_loss: 1.0575 - val_accuracy: 0.5538\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 1.0739 - accuracy: 0.5358 - val_loss: 1.0568 - val_accuracy: 0.5361\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 8s 76ms/step - loss: 1.0443 - accuracy: 0.5612 - val_loss: 1.0122 - val_accuracy: 0.5615\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 9s 87ms/step - loss: 1.0216 - accuracy: 0.5780 - val_loss: 1.0260 - val_accuracy: 0.5757\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 6s 60ms/step - loss: 1.0119 - accuracy: 0.5830 - val_loss: 0.9774 - val_accuracy: 0.5869\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 9s 81ms/step - loss: 1.0000 - accuracy: 0.5900 - val_loss: 0.9762 - val_accuracy: 0.6064\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 6s 61ms/step - loss: 0.9633 - accuracy: 0.6043 - val_loss: 0.9625 - val_accuracy: 0.5993\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 8s 80ms/step - loss: 0.9549 - accuracy: 0.6124 - val_loss: 0.9237 - val_accuracy: 0.6129\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 7s 68ms/step - loss: 0.9535 - accuracy: 0.6147 - val_loss: 0.9470 - val_accuracy: 0.5975\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 9s 82ms/step - loss: 0.9345 - accuracy: 0.6249 - val_loss: 0.9583 - val_accuracy: 0.6017\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 9s 83ms/step - loss: 0.9222 - accuracy: 0.6294 - val_loss: 0.8961 - val_accuracy: 0.6342\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 7s 70ms/step - loss: 0.9058 - accuracy: 0.6382 - val_loss: 0.9170 - val_accuracy: 0.6158\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 9s 84ms/step - loss: 0.8985 - accuracy: 0.6436 - val_loss: 0.9156 - val_accuracy: 0.6519\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 7s 66ms/step - loss: 0.8787 - accuracy: 0.6438 - val_loss: 0.9115 - val_accuracy: 0.6093\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 9s 81ms/step - loss: 0.8770 - accuracy: 0.6480 - val_loss: 0.9133 - val_accuracy: 0.6217\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 6s 61ms/step - loss: 0.8581 - accuracy: 0.6602 - val_loss: 0.8674 - val_accuracy: 0.6377\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.8479 - accuracy: 0.6705 - val_loss: 0.8970 - val_accuracy: 0.6324\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 7s 63ms/step - loss: 0.8375 - accuracy: 0.6684 - val_loss: 0.8629 - val_accuracy: 0.6495\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.8436 - accuracy: 0.6658 - val_loss: 0.8746 - val_accuracy: 0.6554\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 6s 60ms/step - loss: 0.8311 - accuracy: 0.6696 - val_loss: 0.8527 - val_accuracy: 0.6407\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.8204 - accuracy: 0.6751 - val_loss: 0.8522 - val_accuracy: 0.6353\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 6s 61ms/step - loss: 0.8146 - accuracy: 0.6789 - val_loss: 0.8696 - val_accuracy: 0.6206\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 8s 80ms/step - loss: 0.8049 - accuracy: 0.6842 - val_loss: 0.8359 - val_accuracy: 0.6661\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 7s 61ms/step - loss: 0.7877 - accuracy: 0.6865 - val_loss: 0.8025 - val_accuracy: 0.6749\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.8000 - accuracy: 0.6763 - val_loss: 0.8247 - val_accuracy: 0.6631\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 7s 66ms/step - loss: 0.7959 - accuracy: 0.6899 - val_loss: 0.8676 - val_accuracy: 0.6318\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 9s 84ms/step - loss: 0.7897 - accuracy: 0.6894 - val_loss: 0.8520 - val_accuracy: 0.6389\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 7s 69ms/step - loss: 0.7846 - accuracy: 0.6921 - val_loss: 0.8583 - val_accuracy: 0.6359\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 8s 72ms/step - loss: 0.7703 - accuracy: 0.6978 - val_loss: 0.8582 - val_accuracy: 0.6525\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 8s 77ms/step - loss: 0.7702 - accuracy: 0.6974 - val_loss: 0.8522 - val_accuracy: 0.6442\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 7s 68ms/step - loss: 0.7672 - accuracy: 0.7007 - val_loss: 0.8884 - val_accuracy: 0.6306\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.7418 - accuracy: 0.7092 - val_loss: 0.8394 - val_accuracy: 0.6608\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 7s 61ms/step - loss: 0.7612 - accuracy: 0.6981 - val_loss: 0.8633 - val_accuracy: 0.6466\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.7512 - accuracy: 0.7027 - val_loss: 0.8489 - val_accuracy: 0.6448\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 7s 61ms/step - loss: 0.7461 - accuracy: 0.7089 - val_loss: 0.8447 - val_accuracy: 0.6501\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.7467 - accuracy: 0.7103 - val_loss: 0.8444 - val_accuracy: 0.6448\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 7s 62ms/step - loss: 0.7351 - accuracy: 0.7043 - val_loss: 0.8617 - val_accuracy: 0.6442\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.7267 - accuracy: 0.7171 - val_loss: 0.8223 - val_accuracy: 0.6649\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 7s 62ms/step - loss: 0.7153 - accuracy: 0.7191 - val_loss: 0.8284 - val_accuracy: 0.6643\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 9s 84ms/step - loss: 0.7333 - accuracy: 0.7134 - val_loss: 0.8535 - val_accuracy: 0.6495\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 7s 68ms/step - loss: 0.7336 - accuracy: 0.7168 - val_loss: 0.8195 - val_accuracy: 0.6578\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 9s 84ms/step - loss: 0.7066 - accuracy: 0.7238 - val_loss: 0.8327 - val_accuracy: 0.6690\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 7s 68ms/step - loss: 0.7224 - accuracy: 0.7138 - val_loss: 0.8292 - val_accuracy: 0.6531\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 9s 82ms/step - loss: 0.7240 - accuracy: 0.7151 - val_loss: 0.8329 - val_accuracy: 0.6625\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 8s 76ms/step - loss: 0.7198 - accuracy: 0.7168 - val_loss: 0.8250 - val_accuracy: 0.6643\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 7s 67ms/step - loss: 0.7037 - accuracy: 0.7287 - val_loss: 0.8396 - val_accuracy: 0.6637\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 9s 87ms/step - loss: 0.6981 - accuracy: 0.7221 - val_loss: 0.8268 - val_accuracy: 0.6625\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 7s 62ms/step - loss: 0.7128 - accuracy: 0.7228 - val_loss: 0.8166 - val_accuracy: 0.6643\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 8s 80ms/step - loss: 0.6895 - accuracy: 0.7326 - val_loss: 0.8257 - val_accuracy: 0.6673\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 7s 62ms/step - loss: 0.6861 - accuracy: 0.7320 - val_loss: 0.8355 - val_accuracy: 0.6702\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 8s 80ms/step - loss: 0.6766 - accuracy: 0.7337 - val_loss: 0.8516 - val_accuracy: 0.6554\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 7s 62ms/step - loss: 0.6891 - accuracy: 0.7295 - val_loss: 0.8595 - val_accuracy: 0.6495\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 9s 84ms/step - loss: 0.7005 - accuracy: 0.7256 - val_loss: 0.8637 - val_accuracy: 0.6454\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.6948 - accuracy: 0.7252 - val_loss: 0.8577 - val_accuracy: 0.6495\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 9s 82ms/step - loss: 0.6731 - accuracy: 0.7349 - val_loss: 0.8365 - val_accuracy: 0.6649\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 7s 63ms/step - loss: 0.6935 - accuracy: 0.7351 - val_loss: 0.8425 - val_accuracy: 0.6797\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 8s 79ms/step - loss: 0.6803 - accuracy: 0.7354 - val_loss: 0.8088 - val_accuracy: 0.6797\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.6787 - accuracy: 0.7330 - val_loss: 0.8533 - val_accuracy: 0.6460\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 8s 80ms/step - loss: 0.6605 - accuracy: 0.7441 - val_loss: 0.8228 - val_accuracy: 0.6531\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.6653 - accuracy: 0.7405 - val_loss: 0.8541 - val_accuracy: 0.6436\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 9s 81ms/step - loss: 0.6636 - accuracy: 0.7469 - val_loss: 0.8286 - val_accuracy: 0.6897\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.6668 - accuracy: 0.7354 - val_loss: 0.8587 - val_accuracy: 0.6554\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 8s 78ms/step - loss: 0.6689 - accuracy: 0.7401 - val_loss: 0.8251 - val_accuracy: 0.6743\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 7s 66ms/step - loss: 0.6733 - accuracy: 0.7367 - val_loss: 0.8200 - val_accuracy: 0.6613\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 8s 75ms/step - loss: 0.6736 - accuracy: 0.7342 - val_loss: 0.8508 - val_accuracy: 0.6738\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 8s 74ms/step - loss: 0.6479 - accuracy: 0.7490 - val_loss: 0.8521 - val_accuracy: 0.6696\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 7s 69ms/step - loss: 0.6603 - accuracy: 0.7447 - val_loss: 0.8200 - val_accuracy: 0.6678\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 9s 81ms/step - loss: 0.6508 - accuracy: 0.7533 - val_loss: 0.8538 - val_accuracy: 0.6690\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.6478 - accuracy: 0.7481 - val_loss: 0.8211 - val_accuracy: 0.6820\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 9s 85ms/step - loss: 0.6491 - accuracy: 0.7469 - val_loss: 0.8567 - val_accuracy: 0.6714\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 7s 66ms/step - loss: 0.6444 - accuracy: 0.7525 - val_loss: 0.8617 - val_accuracy: 0.6566\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 9s 87ms/step - loss: 0.6466 - accuracy: 0.7491 - val_loss: 0.8464 - val_accuracy: 0.6696\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 7s 62ms/step - loss: 0.6505 - accuracy: 0.7543 - val_loss: 0.8320 - val_accuracy: 0.6673\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 9s 81ms/step - loss: 0.6364 - accuracy: 0.7528 - val_loss: 0.8542 - val_accuracy: 0.6749\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 7s 63ms/step - loss: 0.6664 - accuracy: 0.7342 - val_loss: 0.8156 - val_accuracy: 0.6726\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 9s 81ms/step - loss: 0.6468 - accuracy: 0.7451 - val_loss: 0.8297 - val_accuracy: 0.6708\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 7s 62ms/step - loss: 0.6629 - accuracy: 0.7457 - val_loss: 0.8229 - val_accuracy: 0.6749\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 9s 81ms/step - loss: 0.6457 - accuracy: 0.7503 - val_loss: 0.8091 - val_accuracy: 0.6862\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 7s 64ms/step - loss: 0.6400 - accuracy: 0.7499 - val_loss: 0.8566 - val_accuracy: 0.6590\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 8s 78ms/step - loss: 0.6219 - accuracy: 0.7546 - val_loss: 0.8506 - val_accuracy: 0.6655\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 8s 78ms/step - loss: 0.6334 - accuracy: 0.7519 - val_loss: 0.8533 - val_accuracy: 0.6537\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 8s 74ms/step - loss: 0.6315 - accuracy: 0.7583 - val_loss: 0.8629 - val_accuracy: 0.6755\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 9s 83ms/step - loss: 0.6394 - accuracy: 0.7544 - val_loss: 0.8438 - val_accuracy: 0.6779\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 7s 67ms/step - loss: 0.6297 - accuracy: 0.7522 - val_loss: 0.8257 - val_accuracy: 0.6785\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 9s 85ms/step - loss: 0.6229 - accuracy: 0.7621 - val_loss: 0.8410 - val_accuracy: 0.6779\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 7s 67ms/step - loss: 0.6339 - accuracy: 0.7568 - val_loss: 0.8665 - val_accuracy: 0.6868\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 9s 87ms/step - loss: 0.6155 - accuracy: 0.7598 - val_loss: 0.8394 - val_accuracy: 0.6720\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 7s 65ms/step - loss: 0.6137 - accuracy: 0.7611 - val_loss: 0.8515 - val_accuracy: 0.6649\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 9s 81ms/step - loss: 0.6339 - accuracy: 0.7553 - val_loss: 0.8482 - val_accuracy: 0.6649\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 8s 74ms/step - loss: 0.6079 - accuracy: 0.7652 - val_loss: 0.8525 - val_accuracy: 0.6566\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 8s 71ms/step - loss: 0.6104 - accuracy: 0.7634 - val_loss: 0.8630 - val_accuracy: 0.6779\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 8s 76ms/step - loss: 0.6013 - accuracy: 0.7702 - val_loss: 0.8693 - val_accuracy: 0.6832\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 7s 66ms/step - loss: 0.6277 - accuracy: 0.7612 - val_loss: 0.8765 - val_accuracy: 0.6572\n"
          ]
        }
      ],
      "source": [
        "# Printing the model summary\n",
        "x_train, y_train, x_valid, y_valid, x_test, y_test = preprocess()\n",
        "model = cnn_lstm_model()\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model_results = model.fit(x_train,\n",
        "            y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_data=(x_valid, y_valid), verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(model_results.history['accuracy'])\n",
        "plt.plot(model_results.history['val_accuracy'])\n",
        "plt.title('CRNN-LSTM Model Accuracy for All Subjects')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(model_results.history['loss'])\n",
        "plt.plot(model_results.history['val_loss'])\n",
        "plt.title('CRNN-LSTM Model Loss for All Subjects')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "C6_YQh03HLas",
        "outputId": "fd0275ae-b3df-490b-cfd4-4f2f7e9b6bae"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtkh5-hDGKSI"
      },
      "source": [
        "#### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "Ue7KdBBkGKSI",
        "outputId": "4f091f9a-875b-4c8c-981e-caca179681f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56/56 [==============================] - 1s 12ms/step - loss: 0.8570 - accuracy: 0.6744\n",
            "Test accuracy of the CNN-LSTM model: 0.6743792295455933\n"
          ]
        }
      ],
      "source": [
        "model_name = 'CNN-LSTM'\n",
        "model_score = model.evaluate(x_test, y_test, verbose=True)\n",
        "print(f'Test accuracy of the {model_name} model:',model_score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2K4QuXKkrSR"
      },
      "source": [
        "## GAN-CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li5SMRqLkrSR"
      },
      "source": [
        "#### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6U_RT9TdkrSR"
      },
      "outputs": [],
      "source": [
        "def data_prep_gan(X,y,sub_sample,average,noise, generators, trim_ratio=0.5):\n",
        "    \n",
        "    total_X = None\n",
        "    total_y = None\n",
        "    \n",
        "    # Trimming the data (sample,22,1000) -> (sample,22,500)\n",
        "    X = X[:,:, 0:(int(X.shape[2] * trim_ratio))]\n",
        "    print('Shape of X after trimming:',X.shape)\n",
        "    \n",
        "\n",
        "    \n",
        "    # Maxpooling the data (sample,22,1000) -> (sample,22,500/sub_sample)\n",
        "    X_max = np.max(X.reshape(X.shape[0], X.shape[1], -1, sub_sample), axis=3)\n",
        "    \n",
        "    \n",
        "    total_X = X_max\n",
        "    total_y = y\n",
        "    # print('Shape of X after maxpooling:',total_X.shape)\n",
        "    \n",
        "    # Averaging + noise \n",
        "    X_average = np.mean(X.reshape(X.shape[0], X.shape[1], -1, average), axis=3)\n",
        "    X_average = X_average + np.random.normal(0.0, 0.5, X_average.shape)\n",
        "    \n",
        "    total_X = np.vstack((total_X, X_average))\n",
        "    total_y = np.hstack((total_y, y))\n",
        "    # print('Shape of X after averaging+noise and concatenating:',total_X.shape)\n",
        "    \n",
        "    # Subsampling\n",
        "    \n",
        "    for i in range(sub_sample):\n",
        "        \n",
        "        X_subsample = X[:, :, i::sub_sample] + (np.random.normal(0.0, 0.5, X[:, :,i::sub_sample].shape) if noise else 0.0)\n",
        "        total_X = np.vstack((total_X, X_subsample))\n",
        "        total_y = np.hstack((total_y, y))\n",
        "        \n",
        "    \n",
        "    # GAN\n",
        "    # get generated samples from conditional gan\n",
        "    trimmed_off_data = 1000 - int(X.shape[2] * trim_ratio)\n",
        "    \n",
        "    noise = tf.random.normal([batch_size, noise_dim])\n",
        "\n",
        "    generated_eeg = generators[0](noise, training=False)\n",
        "    generated_samples = generated_eeg.shape[0]\n",
        "    generated_eeg = np.swapaxes(generated_eeg, 2, 3).reshape(-1, 22, 250)\n",
        "    total_X = np.vstack((total_X, generated_eeg))\n",
        "    total_y = np.hstack((total_y, np.full(shape=(generated_samples,), fill_value=0)))\n",
        "\n",
        "    generated_eeg = generators[1](noise, training=False)\n",
        "    generated_samples = generated_eeg.shape[0]\n",
        "    generated_eeg = np.swapaxes(generated_eeg, 2, 3).reshape(-1, 22, 250)\n",
        "    total_X = np.vstack((total_X, generated_eeg))\n",
        "    total_y = np.hstack((total_y, np.full(shape=(generated_samples,), fill_value=1)))\n",
        "\n",
        "    generated_eeg = generators[2](noise, training=False)\n",
        "    generated_samples = generated_eeg.shape[0]\n",
        "    generated_eeg = np.swapaxes(generated_eeg, 2, 3).reshape(-1, 22, 250)\n",
        "    total_X = np.vstack((total_X, generated_eeg))\n",
        "    total_y = np.hstack((total_y, np.full(shape=(generated_samples,), fill_value=2)))\n",
        "\n",
        "    generated_eeg = generators[3](noise, training=False)\n",
        "    generated_samples = generated_eeg.shape[0]\n",
        "    generated_eeg = np.swapaxes(generated_eeg, 2, 3).reshape(-1, 22, 250)\n",
        "    total_X = np.vstack((total_X, generated_eeg))\n",
        "    total_y = np.hstack((total_y, np.full(shape=(generated_samples,), fill_value=3)))\n",
        "\n",
        "\n",
        "    \n",
        "    print('Shape of X after GAN:',total_X.shape)\n",
        "    \n",
        "    return total_X,total_y\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "EcLBYTY_krSS"
      },
      "outputs": [],
      "source": [
        "def preprocess():\n",
        "    X_test = np.load(\"X_test.npy\")\n",
        "    y_test = np.load(\"y_test.npy\")\n",
        "    person_train_valid = np.load(\"person_train_valid.npy\")\n",
        "    X_train_valid = np.load(\"X_train_valid.npy\")\n",
        "    y_train_valid = np.load(\"y_train_valid.npy\")\n",
        "    person_test = np.load(\"person_test.npy\")\n",
        "\n",
        "    ## Adjusting the labels so that \n",
        "\n",
        "    # Cue onset left - 0\n",
        "    # Cue onset right - 1\n",
        "    # Cue onset foot - 2\n",
        "    # Cue onset tongue - 3\n",
        "\n",
        "    y_train_valid -= 769\n",
        "    y_test -= 769\n",
        "    \n",
        "\n",
        "    # shuffle with 5 fold\n",
        "    indicies_valid = np.random.choice(X_train_valid.shape[0], X_train_valid.shape[0] // 5, replace=False)\n",
        "    indicies_train = np.array(list(set(range(X_train_valid.shape[0])).difference(set(indicies_valid))))\n",
        "\n",
        "    # Creating the training and validation sets using the generated indices\n",
        "    X_train, X_valid = X_train_valid[indicies_train], X_train_valid[indicies_valid] \n",
        "    y_train, y_valid = y_train_valid[indicies_train], y_train_valid[indicies_valid]\n",
        "\n",
        "\n",
        "    # Preprocessing the dataset\n",
        "    x_train,y_train = data_prep(X_train,y_train,2,2,True)\n",
        "    x_valid,y_valid = data_prep(X_valid,y_valid,2,2,True)\n",
        "    X_test_prep,y_test_prep = data_prep(X_test,y_test,2,2,True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Converting the labels to categorical variables for multiclass classification\n",
        "    y_train = to_categorical(y_train, 4)\n",
        "    y_valid = to_categorical(y_valid, 4)\n",
        "    y_test = to_categorical(y_test_prep, 4)\n",
        "\n",
        "\n",
        "    # Adding width of the segment to be 1\n",
        "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "    x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
        "    x_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n",
        "\n",
        "\n",
        "\n",
        "    # Reshaping the training and validation dataset\n",
        "    x_train = np.swapaxes(x_train, 1,3)\n",
        "    x_train = np.swapaxes(x_train, 1,2)\n",
        "    x_valid = np.swapaxes(x_valid, 1,3)\n",
        "    x_valid = np.swapaxes(x_valid, 1,2)\n",
        "    x_test = np.swapaxes(x_test, 1,3)\n",
        "    x_test = np.swapaxes(x_test, 1,2)\n",
        "\n",
        "\n",
        "    return (x_train, y_train, x_valid, y_valid, x_test, y_test)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7_Fp0qqakrSS"
      },
      "outputs": [],
      "source": [
        "def preprocess_gan():\n",
        "    X_test = np.load(\"X_test.npy\")\n",
        "    y_test = np.load(\"y_test.npy\")\n",
        "    person_train_valid = np.load(\"person_train_valid.npy\")\n",
        "    X_train_valid = np.load(\"X_train_valid.npy\")\n",
        "    y_train_valid = np.load(\"y_train_valid.npy\")\n",
        "    person_test = np.load(\"person_test.npy\")\n",
        "\n",
        "    ## Adjusting the labels so that \n",
        "\n",
        "    # Cue onset left - 0\n",
        "    # Cue onset right - 1\n",
        "    # Cue onset foot - 2\n",
        "    # Cue onset tongue - 3\n",
        "\n",
        "    y_train_valid -= 769\n",
        "    y_test -= 769\n",
        "    \n",
        "\n",
        "    # print(f'X_test Shape for Subject {subject}: {subject_X_test.shape}')\n",
        "    # print(f'y_test Shape for Subject {subject}: {suject_y_test.shape}')\n",
        "    # print(f'X_train_valid Shape for Subject {subject}: {suject_X_train_valid.shape}')\n",
        "    # print(f'y_train_valid Shape for Subject {subject}: {suject_y_train_valid.shape}')\n",
        "\n",
        "    # shuffle with 5 fold\n",
        "    indicies_valid = np.random.choice(X_train_valid.shape[0], X_train_valid.shape[0] // 5, replace=False)\n",
        "    indicies_train = np.array(list(set(range(X_train_valid.shape[0])).difference(set(indicies_valid))))\n",
        "\n",
        "    # Creating the training and validation sets using the generated indices\n",
        "    X_train, X_valid = X_train_valid[indicies_train], X_train_valid[indicies_valid] \n",
        "    y_train, y_valid = y_train_valid[indicies_train], y_train_valid[indicies_valid]\n",
        "\n",
        "\n",
        "    # Preprocessing the dataset\n",
        "    x_train,y_train = data_prep_gan(X_train,y_train,2,2,True, generators)\n",
        "    x_valid,y_valid = data_prep_gan(X_valid,y_valid,2,2,True, generators)\n",
        "    X_test_prep,y_test_prep = data_prep_gan(X_test,y_test,2,2,True, generators)\n",
        "\n",
        "\n",
        "\n",
        "    # print('Shape of training set:',x_train.shape)\n",
        "    # print('Shape of validation set:',x_valid.shape)\n",
        "    # print('Shape of training labels:',y_train.shape)\n",
        "    # print('Shape of validation labels:',y_valid.shape)\n",
        "    # print('Shape of testing set:',X_test_prep.shape)\n",
        "    # print('Shape of testing labels:',y_test_prep.shape)\n",
        "\n",
        "\n",
        "    # Converting the labels to categorical variables for multiclass classification\n",
        "    y_train = to_categorical(y_train, 4)\n",
        "    y_valid = to_categorical(y_valid, 4)\n",
        "    y_test = to_categorical(y_test_prep, 4)\n",
        "    # print('Shape of training labels after categorical conversion:',y_train.shape)\n",
        "    # print('Shape of validation labels after categorical conversion:',y_valid.shape)\n",
        "    # print('Shape of test labels after categorical conversion:',y_test.shape)\n",
        "\n",
        "    # Adding width of the segment to be 1\n",
        "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "    x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
        "    x_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n",
        "    # print('Shape of training set after adding width info:',x_train.shape)\n",
        "    # print('Shape of validation set after adding width info:',x_valid.shape)\n",
        "    # print('Shape of test set after adding width info:',x_test.shape)\n",
        "\n",
        "\n",
        "    # Reshaping the training and validation dataset\n",
        "    x_train = np.swapaxes(x_train, 1,3)\n",
        "    x_train = np.swapaxes(x_train, 1,2)\n",
        "    x_valid = np.swapaxes(x_valid, 1,3)\n",
        "    x_valid = np.swapaxes(x_valid, 1,2)\n",
        "    x_test = np.swapaxes(x_test, 1,3)\n",
        "    x_test = np.swapaxes(x_test, 1,2)\n",
        "    # print('Shape of training set after dimension reshaping:',x_train.shape)\n",
        "    # print('Shape of validation set after dimension reshaping:',x_valid.shape)\n",
        "    # print('Shape of test set after dimension reshaping:',x_test.shape)\n",
        "\n",
        "    return (x_train, y_train, x_valid, y_valid, x_test, y_test)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnGeKFxwkrSS"
      },
      "source": [
        "#### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Jaepc3yDkrSS"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "epochs = 100\n",
        "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "noise_dim = 100\n",
        "num_classes = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA_xFVvwkrSS"
      },
      "source": [
        "#### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "vaogYdr5krST"
      },
      "outputs": [],
      "source": [
        "\n",
        "def make_generator_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64 * 125 * 1, use_bias=False, input_shape=(100,)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "\n",
        "    model.add(Reshape((125, 1, 64)))\n",
        "    assert model.output_shape == (None, 125, 1, 64)  # Note: None is the batch size\n",
        "\n",
        "    model.add(Conv2DTranspose(32, (3, 3), strides=(2, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 250, 1, 32)\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "\n",
        "    model.add(Conv2DTranspose(16, (3, 3), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 250, 1, 16)\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "\n",
        "    model.add(Conv2DTranspose(1, (3, 3), strides=(1, 1), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 250, 1, 1)\n",
        "\n",
        "    model.add(Reshape((250, 1, 1)))\n",
        "    assert model.output_shape == (None, 250, 1, 1)\n",
        "\n",
        "    model.add(Conv2DTranspose(22, (3, 3), strides=(1, 1), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 250, 1, 22)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_discriminator_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(16, (3, 3), strides=(1, 1), padding='same',\n",
        "                                     input_shape=[250, 1, 22]))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), strides=(2, 1), padding='same'))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), strides=(2, 1), padding='same'))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    return model\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6pdUteYkrST"
      },
      "source": [
        "#### Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "KPI-qdb1krST"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the generator and discriminator models\n",
        "generators = [make_generator_model() for _ in range(4)]\n",
        "discriminators = [make_discriminator_model() for _ in range(4)]\n",
        "\n",
        "# Define the optimizer for the generator and discriminator\n",
        "generator_optimizer = keras.optimizers.Adam(learning_rate)\n",
        "discriminator_optimizer = keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "def train_step(images, class_label):\n",
        "    noise = tf.random.normal([batch_size, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generators[class_label](noise, training=True)\n",
        "\n",
        "\n",
        "        real_output = discriminators[class_label](images, training=True)\n",
        "        fake_output = discriminators[class_label](generated_images, training=True)\n",
        "\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generators[class_label].trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminators[class_label].trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generators[class_label].trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminators[class_label].trainable_variables))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "HwXe6TEakrST"
      },
      "outputs": [],
      "source": [
        "def train_gan(dataset, labels, epochs):\n",
        "    dataset_0 = dataset[np.where(labels[:,0] == 1)[0]]\n",
        "    dataset_1 = dataset[np.where(labels[:,1] == 1)[0]]\n",
        "    dataset_2 = dataset[np.where(labels[:,2] == 1)[0]]\n",
        "    dataset_3 = dataset[np.where(labels[:,3] == 1)[0]]\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f'Epoch: {epoch}, Label: 0')\n",
        "        train_step(dataset_0,0)\n",
        "        print(f'Epoch: {epoch}, Label: 1')\n",
        "        train_step(dataset_1,1)\n",
        "        print(f'Epoch: {epoch}, Label: 2')\n",
        "        train_step(dataset_2,2)\n",
        "        print(f'Epoch: {epoch}, Label: 3')\n",
        "        train_step(dataset_3,3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "9GQM04jrkrST",
        "outputId": "be6ca5ff-cb59-4670-d991-8c36f26c33c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Label: 0\n",
            "Epoch: 0, Label: 1\n",
            "Epoch: 0, Label: 2\n",
            "Epoch: 0, Label: 3\n",
            "Epoch: 1, Label: 0\n",
            "Epoch: 1, Label: 1\n",
            "Epoch: 1, Label: 2\n",
            "Epoch: 1, Label: 3\n",
            "Epoch: 2, Label: 0\n",
            "Epoch: 2, Label: 1\n",
            "Epoch: 2, Label: 2\n",
            "Epoch: 2, Label: 3\n",
            "Epoch: 3, Label: 0\n",
            "Epoch: 3, Label: 1\n",
            "Epoch: 3, Label: 2\n",
            "Epoch: 3, Label: 3\n",
            "Epoch: 4, Label: 0\n",
            "Epoch: 4, Label: 1\n",
            "Epoch: 4, Label: 2\n",
            "Epoch: 4, Label: 3\n",
            "Epoch: 5, Label: 0\n",
            "Epoch: 5, Label: 1\n",
            "Epoch: 5, Label: 2\n",
            "Epoch: 5, Label: 3\n",
            "Epoch: 6, Label: 0\n",
            "Epoch: 6, Label: 1\n",
            "Epoch: 6, Label: 2\n",
            "Epoch: 6, Label: 3\n",
            "Epoch: 7, Label: 0\n",
            "Epoch: 7, Label: 1\n",
            "Epoch: 7, Label: 2\n",
            "Epoch: 7, Label: 3\n",
            "Epoch: 8, Label: 0\n",
            "Epoch: 8, Label: 1\n",
            "Epoch: 8, Label: 2\n",
            "Epoch: 8, Label: 3\n",
            "Epoch: 9, Label: 0\n",
            "Epoch: 9, Label: 1\n",
            "Epoch: 9, Label: 2\n",
            "Epoch: 9, Label: 3\n",
            "Epoch: 10, Label: 0\n",
            "Epoch: 10, Label: 1\n",
            "Epoch: 10, Label: 2\n",
            "Epoch: 10, Label: 3\n",
            "Epoch: 11, Label: 0\n",
            "Epoch: 11, Label: 1\n",
            "Epoch: 11, Label: 2\n",
            "Epoch: 11, Label: 3\n",
            "Epoch: 12, Label: 0\n",
            "Epoch: 12, Label: 1\n",
            "Epoch: 12, Label: 2\n",
            "Epoch: 12, Label: 3\n",
            "Epoch: 13, Label: 0\n",
            "Epoch: 13, Label: 1\n",
            "Epoch: 13, Label: 2\n",
            "Epoch: 13, Label: 3\n",
            "Epoch: 14, Label: 0\n",
            "Epoch: 14, Label: 1\n",
            "Epoch: 14, Label: 2\n",
            "Epoch: 14, Label: 3\n",
            "Epoch: 15, Label: 0\n",
            "Epoch: 15, Label: 1\n",
            "Epoch: 15, Label: 2\n",
            "Epoch: 15, Label: 3\n",
            "Epoch: 16, Label: 0\n",
            "Epoch: 16, Label: 1\n",
            "Epoch: 16, Label: 2\n",
            "Epoch: 16, Label: 3\n",
            "Epoch: 17, Label: 0\n",
            "Epoch: 17, Label: 1\n",
            "Epoch: 17, Label: 2\n",
            "Epoch: 17, Label: 3\n",
            "Epoch: 18, Label: 0\n",
            "Epoch: 18, Label: 1\n",
            "Epoch: 18, Label: 2\n",
            "Epoch: 18, Label: 3\n",
            "Epoch: 19, Label: 0\n",
            "Epoch: 19, Label: 1\n",
            "Epoch: 19, Label: 2\n",
            "Epoch: 19, Label: 3\n",
            "Epoch: 20, Label: 0\n",
            "Epoch: 20, Label: 1\n",
            "Epoch: 20, Label: 2\n",
            "Epoch: 20, Label: 3\n",
            "Epoch: 21, Label: 0\n",
            "Epoch: 21, Label: 1\n",
            "Epoch: 21, Label: 2\n",
            "Epoch: 21, Label: 3\n",
            "Epoch: 22, Label: 0\n",
            "Epoch: 22, Label: 1\n",
            "Epoch: 22, Label: 2\n",
            "Epoch: 22, Label: 3\n",
            "Epoch: 23, Label: 0\n",
            "Epoch: 23, Label: 1\n",
            "Epoch: 23, Label: 2\n",
            "Epoch: 23, Label: 3\n",
            "Epoch: 24, Label: 0\n",
            "Epoch: 24, Label: 1\n",
            "Epoch: 24, Label: 2\n",
            "Epoch: 24, Label: 3\n",
            "Epoch: 25, Label: 0\n",
            "Epoch: 25, Label: 1\n",
            "Epoch: 25, Label: 2\n",
            "Epoch: 25, Label: 3\n",
            "Epoch: 26, Label: 0\n",
            "Epoch: 26, Label: 1\n",
            "Epoch: 26, Label: 2\n",
            "Epoch: 26, Label: 3\n",
            "Epoch: 27, Label: 0\n",
            "Epoch: 27, Label: 1\n",
            "Epoch: 27, Label: 2\n",
            "Epoch: 27, Label: 3\n",
            "Epoch: 28, Label: 0\n",
            "Epoch: 28, Label: 1\n",
            "Epoch: 28, Label: 2\n",
            "Epoch: 28, Label: 3\n",
            "Epoch: 29, Label: 0\n",
            "Epoch: 29, Label: 1\n",
            "Epoch: 29, Label: 2\n",
            "Epoch: 29, Label: 3\n",
            "Epoch: 30, Label: 0\n",
            "Epoch: 30, Label: 1\n",
            "Epoch: 30, Label: 2\n",
            "Epoch: 30, Label: 3\n",
            "Epoch: 31, Label: 0\n",
            "Epoch: 31, Label: 1\n",
            "Epoch: 31, Label: 2\n",
            "Epoch: 31, Label: 3\n",
            "Epoch: 32, Label: 0\n",
            "Epoch: 32, Label: 1\n",
            "Epoch: 32, Label: 2\n",
            "Epoch: 32, Label: 3\n",
            "Epoch: 33, Label: 0\n",
            "Epoch: 33, Label: 1\n",
            "Epoch: 33, Label: 2\n",
            "Epoch: 33, Label: 3\n",
            "Epoch: 34, Label: 0\n",
            "Epoch: 34, Label: 1\n",
            "Epoch: 34, Label: 2\n",
            "Epoch: 34, Label: 3\n",
            "Epoch: 35, Label: 0\n",
            "Epoch: 35, Label: 1\n",
            "Epoch: 35, Label: 2\n",
            "Epoch: 35, Label: 3\n",
            "Epoch: 36, Label: 0\n",
            "Epoch: 36, Label: 1\n",
            "Epoch: 36, Label: 2\n",
            "Epoch: 36, Label: 3\n",
            "Epoch: 37, Label: 0\n",
            "Epoch: 37, Label: 1\n",
            "Epoch: 37, Label: 2\n",
            "Epoch: 37, Label: 3\n",
            "Epoch: 38, Label: 0\n",
            "Epoch: 38, Label: 1\n",
            "Epoch: 38, Label: 2\n",
            "Epoch: 38, Label: 3\n",
            "Epoch: 39, Label: 0\n",
            "Epoch: 39, Label: 1\n",
            "Epoch: 39, Label: 2\n",
            "Epoch: 39, Label: 3\n",
            "Epoch: 40, Label: 0\n",
            "Epoch: 40, Label: 1\n",
            "Epoch: 40, Label: 2\n",
            "Epoch: 40, Label: 3\n",
            "Epoch: 41, Label: 0\n",
            "Epoch: 41, Label: 1\n",
            "Epoch: 41, Label: 2\n",
            "Epoch: 41, Label: 3\n",
            "Epoch: 42, Label: 0\n",
            "Epoch: 42, Label: 1\n",
            "Epoch: 42, Label: 2\n",
            "Epoch: 42, Label: 3\n",
            "Epoch: 43, Label: 0\n",
            "Epoch: 43, Label: 1\n",
            "Epoch: 43, Label: 2\n",
            "Epoch: 43, Label: 3\n",
            "Epoch: 44, Label: 0\n",
            "Epoch: 44, Label: 1\n",
            "Epoch: 44, Label: 2\n",
            "Epoch: 44, Label: 3\n",
            "Epoch: 45, Label: 0\n",
            "Epoch: 45, Label: 1\n",
            "Epoch: 45, Label: 2\n",
            "Epoch: 45, Label: 3\n",
            "Epoch: 46, Label: 0\n",
            "Epoch: 46, Label: 1\n",
            "Epoch: 46, Label: 2\n",
            "Epoch: 46, Label: 3\n",
            "Epoch: 47, Label: 0\n",
            "Epoch: 47, Label: 1\n",
            "Epoch: 47, Label: 2\n",
            "Epoch: 47, Label: 3\n",
            "Epoch: 48, Label: 0\n",
            "Epoch: 48, Label: 1\n",
            "Epoch: 48, Label: 2\n",
            "Epoch: 48, Label: 3\n",
            "Epoch: 49, Label: 0\n",
            "Epoch: 49, Label: 1\n",
            "Epoch: 49, Label: 2\n",
            "Epoch: 49, Label: 3\n",
            "Epoch: 50, Label: 0\n",
            "Epoch: 50, Label: 1\n",
            "Epoch: 50, Label: 2\n",
            "Epoch: 50, Label: 3\n",
            "Epoch: 51, Label: 0\n",
            "Epoch: 51, Label: 1\n",
            "Epoch: 51, Label: 2\n",
            "Epoch: 51, Label: 3\n",
            "Epoch: 52, Label: 0\n",
            "Epoch: 52, Label: 1\n",
            "Epoch: 52, Label: 2\n",
            "Epoch: 52, Label: 3\n",
            "Epoch: 53, Label: 0\n",
            "Epoch: 53, Label: 1\n",
            "Epoch: 53, Label: 2\n",
            "Epoch: 53, Label: 3\n",
            "Epoch: 54, Label: 0\n",
            "Epoch: 54, Label: 1\n",
            "Epoch: 54, Label: 2\n",
            "Epoch: 54, Label: 3\n",
            "Epoch: 55, Label: 0\n",
            "Epoch: 55, Label: 1\n",
            "Epoch: 55, Label: 2\n",
            "Epoch: 55, Label: 3\n",
            "Epoch: 56, Label: 0\n",
            "Epoch: 56, Label: 1\n",
            "Epoch: 56, Label: 2\n",
            "Epoch: 56, Label: 3\n",
            "Epoch: 57, Label: 0\n",
            "Epoch: 57, Label: 1\n",
            "Epoch: 57, Label: 2\n",
            "Epoch: 57, Label: 3\n",
            "Epoch: 58, Label: 0\n",
            "Epoch: 58, Label: 1\n",
            "Epoch: 58, Label: 2\n",
            "Epoch: 58, Label: 3\n",
            "Epoch: 59, Label: 0\n",
            "Epoch: 59, Label: 1\n",
            "Epoch: 59, Label: 2\n",
            "Epoch: 59, Label: 3\n",
            "Epoch: 60, Label: 0\n",
            "Epoch: 60, Label: 1\n",
            "Epoch: 60, Label: 2\n",
            "Epoch: 60, Label: 3\n",
            "Epoch: 61, Label: 0\n",
            "Epoch: 61, Label: 1\n",
            "Epoch: 61, Label: 2\n",
            "Epoch: 61, Label: 3\n",
            "Epoch: 62, Label: 0\n",
            "Epoch: 62, Label: 1\n",
            "Epoch: 62, Label: 2\n",
            "Epoch: 62, Label: 3\n",
            "Epoch: 63, Label: 0\n",
            "Epoch: 63, Label: 1\n",
            "Epoch: 63, Label: 2\n",
            "Epoch: 63, Label: 3\n",
            "Epoch: 64, Label: 0\n",
            "Epoch: 64, Label: 1\n",
            "Epoch: 64, Label: 2\n",
            "Epoch: 64, Label: 3\n",
            "Epoch: 65, Label: 0\n",
            "Epoch: 65, Label: 1\n",
            "Epoch: 65, Label: 2\n",
            "Epoch: 65, Label: 3\n",
            "Epoch: 66, Label: 0\n",
            "Epoch: 66, Label: 1\n",
            "Epoch: 66, Label: 2\n",
            "Epoch: 66, Label: 3\n",
            "Epoch: 67, Label: 0\n",
            "Epoch: 67, Label: 1\n",
            "Epoch: 67, Label: 2\n",
            "Epoch: 67, Label: 3\n",
            "Epoch: 68, Label: 0\n",
            "Epoch: 68, Label: 1\n",
            "Epoch: 68, Label: 2\n",
            "Epoch: 68, Label: 3\n",
            "Epoch: 69, Label: 0\n",
            "Epoch: 69, Label: 1\n",
            "Epoch: 69, Label: 2\n",
            "Epoch: 69, Label: 3\n",
            "Epoch: 70, Label: 0\n",
            "Epoch: 70, Label: 1\n",
            "Epoch: 70, Label: 2\n",
            "Epoch: 70, Label: 3\n",
            "Epoch: 71, Label: 0\n",
            "Epoch: 71, Label: 1\n",
            "Epoch: 71, Label: 2\n",
            "Epoch: 71, Label: 3\n",
            "Epoch: 72, Label: 0\n",
            "Epoch: 72, Label: 1\n",
            "Epoch: 72, Label: 2\n",
            "Epoch: 72, Label: 3\n",
            "Epoch: 73, Label: 0\n",
            "Epoch: 73, Label: 1\n",
            "Epoch: 73, Label: 2\n",
            "Epoch: 73, Label: 3\n",
            "Epoch: 74, Label: 0\n",
            "Epoch: 74, Label: 1\n",
            "Epoch: 74, Label: 2\n",
            "Epoch: 74, Label: 3\n",
            "Epoch: 75, Label: 0\n",
            "Epoch: 75, Label: 1\n",
            "Epoch: 75, Label: 2\n",
            "Epoch: 75, Label: 3\n",
            "Epoch: 76, Label: 0\n",
            "Epoch: 76, Label: 1\n",
            "Epoch: 76, Label: 2\n",
            "Epoch: 76, Label: 3\n",
            "Epoch: 77, Label: 0\n",
            "Epoch: 77, Label: 1\n",
            "Epoch: 77, Label: 2\n",
            "Epoch: 77, Label: 3\n",
            "Epoch: 78, Label: 0\n",
            "Epoch: 78, Label: 1\n",
            "Epoch: 78, Label: 2\n",
            "Epoch: 78, Label: 3\n",
            "Epoch: 79, Label: 0\n",
            "Epoch: 79, Label: 1\n",
            "Epoch: 79, Label: 2\n",
            "Epoch: 79, Label: 3\n",
            "Epoch: 80, Label: 0\n",
            "Epoch: 80, Label: 1\n",
            "Epoch: 80, Label: 2\n",
            "Epoch: 80, Label: 3\n",
            "Epoch: 81, Label: 0\n",
            "Epoch: 81, Label: 1\n",
            "Epoch: 81, Label: 2\n",
            "Epoch: 81, Label: 3\n",
            "Epoch: 82, Label: 0\n",
            "Epoch: 82, Label: 1\n",
            "Epoch: 82, Label: 2\n",
            "Epoch: 82, Label: 3\n",
            "Epoch: 83, Label: 0\n",
            "Epoch: 83, Label: 1\n",
            "Epoch: 83, Label: 2\n",
            "Epoch: 83, Label: 3\n",
            "Epoch: 84, Label: 0\n",
            "Epoch: 84, Label: 1\n",
            "Epoch: 84, Label: 2\n",
            "Epoch: 84, Label: 3\n",
            "Epoch: 85, Label: 0\n",
            "Epoch: 85, Label: 1\n",
            "Epoch: 85, Label: 2\n",
            "Epoch: 85, Label: 3\n",
            "Epoch: 86, Label: 0\n",
            "Epoch: 86, Label: 1\n",
            "Epoch: 86, Label: 2\n",
            "Epoch: 86, Label: 3\n",
            "Epoch: 87, Label: 0\n",
            "Epoch: 87, Label: 1\n",
            "Epoch: 87, Label: 2\n",
            "Epoch: 87, Label: 3\n",
            "Epoch: 88, Label: 0\n",
            "Epoch: 88, Label: 1\n",
            "Epoch: 88, Label: 2\n",
            "Epoch: 88, Label: 3\n",
            "Epoch: 89, Label: 0\n",
            "Epoch: 89, Label: 1\n",
            "Epoch: 89, Label: 2\n",
            "Epoch: 89, Label: 3\n",
            "Epoch: 90, Label: 0\n",
            "Epoch: 90, Label: 1\n",
            "Epoch: 90, Label: 2\n",
            "Epoch: 90, Label: 3\n",
            "Epoch: 91, Label: 0\n",
            "Epoch: 91, Label: 1\n",
            "Epoch: 91, Label: 2\n",
            "Epoch: 91, Label: 3\n",
            "Epoch: 92, Label: 0\n",
            "Epoch: 92, Label: 1\n",
            "Epoch: 92, Label: 2\n",
            "Epoch: 92, Label: 3\n",
            "Epoch: 93, Label: 0\n",
            "Epoch: 93, Label: 1\n",
            "Epoch: 93, Label: 2\n",
            "Epoch: 93, Label: 3\n",
            "Epoch: 94, Label: 0\n",
            "Epoch: 94, Label: 1\n",
            "Epoch: 94, Label: 2\n",
            "Epoch: 94, Label: 3\n",
            "Epoch: 95, Label: 0\n",
            "Epoch: 95, Label: 1\n",
            "Epoch: 95, Label: 2\n",
            "Epoch: 95, Label: 3\n",
            "Epoch: 96, Label: 0\n",
            "Epoch: 96, Label: 1\n",
            "Epoch: 96, Label: 2\n",
            "Epoch: 96, Label: 3\n",
            "Epoch: 97, Label: 0\n",
            "Epoch: 97, Label: 1\n",
            "Epoch: 97, Label: 2\n",
            "Epoch: 97, Label: 3\n",
            "Epoch: 98, Label: 0\n",
            "Epoch: 98, Label: 1\n",
            "Epoch: 98, Label: 2\n",
            "Epoch: 98, Label: 3\n",
            "Epoch: 99, Label: 0\n",
            "Epoch: 99, Label: 1\n",
            "Epoch: 99, Label: 2\n",
            "Epoch: 99, Label: 3\n"
          ]
        }
      ],
      "source": [
        "x_train, y_train, x_valid, y_valid, x_test, y_test = preprocess()\n",
        "train_gan(x_train, y_train, epochs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "PjEDUnDVkrST",
        "outputId": "3853dd0f-bc09-44b1-c30e-702088cf3aff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X after trimming: (1692, 22, 500)\n",
            "Shape of X after GAN: (7024, 22, 250)\n",
            "Shape of X after trimming: (423, 22, 500)\n",
            "Shape of X after GAN: (1948, 22, 250)\n",
            "Shape of X after trimming: (443, 22, 500)\n",
            "Shape of X after GAN: (2028, 22, 250)\n",
            "Shape of X after trimming: (1692, 22, 1000)\n",
            "Shape of X after trimming: (423, 22, 1000)\n",
            "Shape of X after trimming: (443, 22, 1000)\n",
            "Shape of training set: (6768, 22, 500)\n",
            "Shape of validation set: (1692, 22, 500)\n",
            "Shape of training labels: (6768,)\n",
            "Shape of validation labels: (1692,)\n",
            "Shape of testing set: (1772, 22, 500)\n",
            "Shape of testing labels: (1772,)\n",
            "Shape of training labels after categorical conversion: (6768, 4)\n",
            "Shape of validation labels after categorical conversion: (1692, 4)\n",
            "Shape of test labels after categorical conversion: (1772, 4)\n",
            "Shape of training set after adding width info: (6768, 22, 500, 1)\n",
            "Shape of validation set after adding width info: (1692, 22, 500, 1)\n",
            "Shape of test set after adding width info: (1772, 22, 500, 1)\n",
            "Shape of training set after dimension reshaping: (6768, 500, 1, 22)\n",
            "Shape of validation set after dimension reshaping: (1692, 500, 1, 22)\n",
            "Shape of test set after dimension reshaping: (1772, 500, 1, 22)\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 12s 109ms/step - loss: 2.0290 - accuracy: 0.2723 - val_loss: 1.4846 - val_accuracy: 0.2931\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 1.5583 - accuracy: 0.3271 - val_loss: 1.3794 - val_accuracy: 0.3469\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 10s 99ms/step - loss: 1.3959 - accuracy: 0.3692 - val_loss: 1.3309 - val_accuracy: 0.3918\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 10s 93ms/step - loss: 1.2808 - accuracy: 0.4198 - val_loss: 1.2964 - val_accuracy: 0.4356\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 1.2147 - accuracy: 0.4554 - val_loss: 1.2297 - val_accuracy: 0.4574\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 1.1651 - accuracy: 0.4792 - val_loss: 1.2095 - val_accuracy: 0.4947\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 9s 86ms/step - loss: 1.1252 - accuracy: 0.5047 - val_loss: 1.1783 - val_accuracy: 0.5071\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 1.0956 - accuracy: 0.5242 - val_loss: 1.1575 - val_accuracy: 0.5296\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 1.0681 - accuracy: 0.5368 - val_loss: 1.1475 - val_accuracy: 0.5230\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 11s 99ms/step - loss: 1.0640 - accuracy: 0.5473 - val_loss: 1.1297 - val_accuracy: 0.5591\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 10s 91ms/step - loss: 1.0475 - accuracy: 0.5462 - val_loss: 1.1247 - val_accuracy: 0.5384\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 1.0212 - accuracy: 0.5640 - val_loss: 1.1042 - val_accuracy: 0.5449\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 1.0142 - accuracy: 0.5739 - val_loss: 1.1068 - val_accuracy: 0.5467\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 10s 92ms/step - loss: 0.9830 - accuracy: 0.5921 - val_loss: 1.0647 - val_accuracy: 0.5650\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 11s 100ms/step - loss: 0.9737 - accuracy: 0.5898 - val_loss: 1.0615 - val_accuracy: 0.5626\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.9584 - accuracy: 0.6034 - val_loss: 1.0318 - val_accuracy: 0.5674\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.9427 - accuracy: 0.6108 - val_loss: 1.0678 - val_accuracy: 0.5508\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 9s 86ms/step - loss: 0.9358 - accuracy: 0.6147 - val_loss: 1.0649 - val_accuracy: 0.5561\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.8977 - accuracy: 0.6287 - val_loss: 1.0278 - val_accuracy: 0.5733\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.8970 - accuracy: 0.6331 - val_loss: 1.0217 - val_accuracy: 0.5810\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 10s 95ms/step - loss: 0.8839 - accuracy: 0.6495 - val_loss: 1.0069 - val_accuracy: 0.5969\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 10s 96ms/step - loss: 0.8611 - accuracy: 0.6546 - val_loss: 0.9897 - val_accuracy: 0.6005\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.8588 - accuracy: 0.6594 - val_loss: 0.9940 - val_accuracy: 0.6028\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 11s 107ms/step - loss: 0.8641 - accuracy: 0.6473 - val_loss: 0.9891 - val_accuracy: 0.6082\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 9s 87ms/step - loss: 0.8406 - accuracy: 0.6590 - val_loss: 0.9692 - val_accuracy: 0.6105\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.8402 - accuracy: 0.6599 - val_loss: 0.9585 - val_accuracy: 0.6152\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.8269 - accuracy: 0.6653 - val_loss: 0.9279 - val_accuracy: 0.6194\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 11s 102ms/step - loss: 0.8265 - accuracy: 0.6671 - val_loss: 0.9390 - val_accuracy: 0.6330\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 10s 90ms/step - loss: 0.8117 - accuracy: 0.6718 - val_loss: 0.9441 - val_accuracy: 0.6082\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.8102 - accuracy: 0.6749 - val_loss: 0.9364 - val_accuracy: 0.6330\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.7983 - accuracy: 0.6857 - val_loss: 0.9478 - val_accuracy: 0.6271\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 10s 92ms/step - loss: 0.7971 - accuracy: 0.6797 - val_loss: 0.9373 - val_accuracy: 0.6288\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 11s 99ms/step - loss: 0.7903 - accuracy: 0.6863 - val_loss: 0.9202 - val_accuracy: 0.6265\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.7894 - accuracy: 0.6816 - val_loss: 0.9152 - val_accuracy: 0.6389\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.7726 - accuracy: 0.6946 - val_loss: 0.9306 - val_accuracy: 0.6312\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 9s 87ms/step - loss: 0.7599 - accuracy: 0.7005 - val_loss: 0.9130 - val_accuracy: 0.6365\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.7759 - accuracy: 0.6903 - val_loss: 0.8949 - val_accuracy: 0.6466\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.7532 - accuracy: 0.7017 - val_loss: 0.9256 - val_accuracy: 0.6407\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 11s 100ms/step - loss: 0.7570 - accuracy: 0.6986 - val_loss: 0.8843 - val_accuracy: 0.6377\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 10s 92ms/step - loss: 0.7438 - accuracy: 0.7080 - val_loss: 0.9059 - val_accuracy: 0.6448\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.7589 - accuracy: 0.6973 - val_loss: 0.9407 - val_accuracy: 0.6294\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.7428 - accuracy: 0.7042 - val_loss: 0.9308 - val_accuracy: 0.6407\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 10s 93ms/step - loss: 0.7369 - accuracy: 0.7054 - val_loss: 0.8901 - val_accuracy: 0.6554\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 11s 99ms/step - loss: 0.7329 - accuracy: 0.7060 - val_loss: 0.8886 - val_accuracy: 0.6436\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.7304 - accuracy: 0.7111 - val_loss: 0.9413 - val_accuracy: 0.6152\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.7449 - accuracy: 0.7008 - val_loss: 0.8764 - val_accuracy: 0.6442\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 9s 86ms/step - loss: 0.7294 - accuracy: 0.7137 - val_loss: 0.9190 - val_accuracy: 0.6436\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.7343 - accuracy: 0.7063 - val_loss: 0.8767 - val_accuracy: 0.6525\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.7336 - accuracy: 0.7125 - val_loss: 0.8850 - val_accuracy: 0.6495\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 10s 98ms/step - loss: 0.7288 - accuracy: 0.7142 - val_loss: 0.8869 - val_accuracy: 0.6478\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 10s 95ms/step - loss: 0.7364 - accuracy: 0.7058 - val_loss: 0.8734 - val_accuracy: 0.6537\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.7254 - accuracy: 0.7114 - val_loss: 0.8945 - val_accuracy: 0.6507\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.7121 - accuracy: 0.7193 - val_loss: 0.8902 - val_accuracy: 0.6413\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 10s 93ms/step - loss: 0.7072 - accuracy: 0.7204 - val_loss: 0.8912 - val_accuracy: 0.6548\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 11s 100ms/step - loss: 0.7115 - accuracy: 0.7166 - val_loss: 0.8906 - val_accuracy: 0.6424\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.6966 - accuracy: 0.7212 - val_loss: 0.9119 - val_accuracy: 0.6401\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 13s 127ms/step - loss: 0.7008 - accuracy: 0.7190 - val_loss: 0.8964 - val_accuracy: 0.6430\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 10s 98ms/step - loss: 0.7035 - accuracy: 0.7233 - val_loss: 0.9198 - val_accuracy: 0.6478\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 10s 95ms/step - loss: 0.7116 - accuracy: 0.7187 - val_loss: 0.8643 - val_accuracy: 0.6720\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.6993 - accuracy: 0.7240 - val_loss: 0.8538 - val_accuracy: 0.6631\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 11s 107ms/step - loss: 0.6792 - accuracy: 0.7323 - val_loss: 0.8855 - val_accuracy: 0.6489\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 9s 87ms/step - loss: 0.6816 - accuracy: 0.7354 - val_loss: 0.8713 - val_accuracy: 0.6578\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.7041 - accuracy: 0.7179 - val_loss: 0.8712 - val_accuracy: 0.6602\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.6948 - accuracy: 0.7259 - val_loss: 0.9089 - val_accuracy: 0.6365\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 10s 98ms/step - loss: 0.6735 - accuracy: 0.7374 - val_loss: 0.8674 - val_accuracy: 0.6637\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 10s 92ms/step - loss: 0.6737 - accuracy: 0.7360 - val_loss: 0.8823 - val_accuracy: 0.6543\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.6949 - accuracy: 0.7237 - val_loss: 0.9216 - val_accuracy: 0.6418\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 11s 107ms/step - loss: 0.6823 - accuracy: 0.7281 - val_loss: 0.8838 - val_accuracy: 0.6543\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 10s 93ms/step - loss: 0.6806 - accuracy: 0.7355 - val_loss: 0.9137 - val_accuracy: 0.6548\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 11s 101ms/step - loss: 0.6874 - accuracy: 0.7278 - val_loss: 0.8799 - val_accuracy: 0.6525\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.6749 - accuracy: 0.7337 - val_loss: 0.8762 - val_accuracy: 0.6655\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.6751 - accuracy: 0.7352 - val_loss: 0.8803 - val_accuracy: 0.6602\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 9s 86ms/step - loss: 0.6826 - accuracy: 0.7329 - val_loss: 0.8628 - val_accuracy: 0.6578\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.6806 - accuracy: 0.7401 - val_loss: 0.8644 - val_accuracy: 0.6673\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.6751 - accuracy: 0.7317 - val_loss: 0.8572 - val_accuracy: 0.6749\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 10s 97ms/step - loss: 0.6831 - accuracy: 0.7308 - val_loss: 0.8681 - val_accuracy: 0.6501\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 10s 94ms/step - loss: 0.6766 - accuracy: 0.7380 - val_loss: 0.8689 - val_accuracy: 0.6566\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.6794 - accuracy: 0.7368 - val_loss: 0.8382 - val_accuracy: 0.6755\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.6782 - accuracy: 0.7244 - val_loss: 0.8690 - val_accuracy: 0.6560\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 9s 86ms/step - loss: 0.6491 - accuracy: 0.7448 - val_loss: 0.8585 - val_accuracy: 0.6554\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.6701 - accuracy: 0.7364 - val_loss: 0.8791 - val_accuracy: 0.6643\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 11s 107ms/step - loss: 0.6625 - accuracy: 0.7419 - val_loss: 0.8667 - val_accuracy: 0.6554\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 11s 105ms/step - loss: 0.6547 - accuracy: 0.7416 - val_loss: 0.8572 - val_accuracy: 0.6702\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 10s 89ms/step - loss: 0.6735 - accuracy: 0.7327 - val_loss: 0.8954 - val_accuracy: 0.6424\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.6486 - accuracy: 0.7473 - val_loss: 0.8854 - val_accuracy: 0.6572\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.6583 - accuracy: 0.7457 - val_loss: 0.8573 - val_accuracy: 0.6661\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 10s 95ms/step - loss: 0.6539 - accuracy: 0.7488 - val_loss: 0.8514 - val_accuracy: 0.6749\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 10s 98ms/step - loss: 0.6422 - accuracy: 0.7414 - val_loss: 0.8866 - val_accuracy: 0.6531\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.6481 - accuracy: 0.7467 - val_loss: 0.8336 - val_accuracy: 0.6720\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.6522 - accuracy: 0.7453 - val_loss: 0.8449 - val_accuracy: 0.6696\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 9s 86ms/step - loss: 0.6496 - accuracy: 0.7435 - val_loss: 0.8545 - val_accuracy: 0.6619\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.6472 - accuracy: 0.7407 - val_loss: 0.8402 - val_accuracy: 0.6625\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 11s 107ms/step - loss: 0.6549 - accuracy: 0.7407 - val_loss: 0.8466 - val_accuracy: 0.6655\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 11s 100ms/step - loss: 0.6370 - accuracy: 0.7444 - val_loss: 0.8591 - val_accuracy: 0.6572\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 10s 92ms/step - loss: 0.6385 - accuracy: 0.7485 - val_loss: 0.8366 - val_accuracy: 0.6791\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.6526 - accuracy: 0.7423 - val_loss: 0.8497 - val_accuracy: 0.6655\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.6523 - accuracy: 0.7438 - val_loss: 0.8725 - val_accuracy: 0.6708\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 10s 92ms/step - loss: 0.6500 - accuracy: 0.7441 - val_loss: 0.8479 - val_accuracy: 0.6743\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 11s 100ms/step - loss: 0.6557 - accuracy: 0.7450 - val_loss: 0.8561 - val_accuracy: 0.6649\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 11s 106ms/step - loss: 0.6391 - accuracy: 0.7516 - val_loss: 0.9114 - val_accuracy: 0.6478\n",
            "56/56 [==============================] - 1s 18ms/step - loss: 0.7603 - accuracy: 0.7065\n",
            "Test Accuracy: 0.7065462470054626\n",
            "Test Accuracy for CNN-GAN: 0.7065462470054626\n"
          ]
        }
      ],
      "source": [
        "# Printing the model summary\n",
        "x_train, y_train, x_valid, y_valid, x_test, y_test = preprocess_gan()\n",
        "cnn_gan, cnn_gan_results, accuracy = cnn_model(trim_ratio=1)\n",
        "print(f\"Test Accuracy for CNN-GAN: {accuracy[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(cnn_gan_results.history['accuracy'])\n",
        "plt.plot(cnn_gan_results.history['val_accuracy'])\n",
        "plt.title('CNN-GAN Model Accuracy for All Subjects')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(cnn_gan_results.history['loss'])\n",
        "plt.plot(cnn_gan_results.history['val_loss'])\n",
        "plt.title('CNN-GAN Model Loss for All Subjects')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "kidU4DFGHYJG",
        "outputId": "ebc09b99-05a7-4ff5-d395-ee60f69cb5b0"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4mtY_eBkrSU"
      },
      "source": [
        "#### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "vWAhzbSRkrSU",
        "outputId": "59279170-2cbd-4cc0-f46d-29d571bfef8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy for CNN-GAN: 0.7065462470054626\n"
          ]
        }
      ],
      "source": [
        "print(f\"Test Accuracy for CNN-GAN: {accuracy[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wws_tK7ZkrSU"
      },
      "source": [
        "## Attention & Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzRek6t9krSU"
      },
      "source": [
        "#### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "dHXQSXYbkrSU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7741db9-f6ae-4002-9b67-1387fc19d99e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras-position-wise-feed-forward in /usr/local/lib/python3.9/dist-packages (0.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from keras-position-wise-feed-forward) (1.22.4)\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 250, 1, 22)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " permute_2 (Permute)            (None, 250, 22, 1)   0           ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " reshape_10 (Reshape)           (None, 250, 22)      0           ['permute_2[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_14 (LayerN  (None, 250, 22)     44          ['reshape_10[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_16 (Dense)               (None, 250, 250)     5750        ['layer_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_15 (LayerN  (None, 250, 250)    500         ['dense_16[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " patch_encoder_2 (PatchEncoder)  (None, 250, 22)     11022       ['layer_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_16 (LayerN  (None, 250, 22)     44          ['patch_encoder_2[0][0]']        \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_4 (MultiH  (None, 250, 22)     8030        ['layer_normalization_16[0][0]', \n",
            " eadAttention)                                                    'layer_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 250, 22)      0           ['multi_head_attention_4[0][0]', \n",
            "                                                                  'patch_encoder_2[0][0]']        \n",
            "                                                                                                  \n",
            " layer_normalization_17 (LayerN  (None, 250, 22)     44          ['add_8[0][0]']                  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " feed_forward_6 (FeedForward)   (None, 250, 22)      1012        ['layer_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 250, 22)      0           ['feed_forward_6[0][0]',         \n",
            "                                                                  'add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_18 (LayerN  (None, 250, 22)     44          ['add_9[0][0]']                  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_5 (MultiH  (None, 250, 22)     8030        ['layer_normalization_18[0][0]', \n",
            " eadAttention)                                                    'layer_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 250, 22)      0           ['multi_head_attention_5[0][0]', \n",
            "                                                                  'add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_19 (LayerN  (None, 250, 22)     44          ['add_10[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " feed_forward_7 (FeedForward)   (None, 250, 22)      1012        ['layer_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 250, 22)      0           ['feed_forward_7[0][0]',         \n",
            "                                                                  'add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_20 (LayerN  (None, 250, 22)     44          ['add_11[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " flatten_8 (Flatten)            (None, 5500)         0           ['layer_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_19 (Dropout)           (None, 5500)         0           ['flatten_8[0][0]']              \n",
            "                                                                                                  \n",
            " feed_forward_8 (FeedForward)   (None, 5500)         247522      ['dropout_19[0][0]']             \n",
            "                                                                                                  \n",
            " dense_18 (Dense)               (None, 4)            22004       ['feed_forward_8[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 305,146\n",
            "Trainable params: 305,146\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.python.ops.array_ops import expand_dims_eager_fallback\n",
        "from keras.layers import Lambda\n",
        "import keras.backend as K\n",
        "!pip install keras-position-wise-feed-forward\n",
        "\n",
        "from keras_position_wise_feed_forward import FeedForward\n",
        "\n",
        "# hyperparameters\n",
        "dim = 250\n",
        "num_heads = 4\n",
        "dim_heads = 22\n",
        "dropout = 0.1\n",
        "mlp_dim = 22\n",
        "transformer_layers = 2\n",
        "\n",
        "class PatchEncoder(keras.layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super().__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = keras.layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = keras.layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
        "        return encoded\n",
        "\n",
        "def create_vit_classifier(batch_size=64):\n",
        "    inputs = keras.Input(shape=(250,1,22))\n",
        "\n",
        "    # preprocessing\n",
        "    x = keras.layers.Permute((1,3,2), input_shape=(250,1,22)) (inputs) # shape = (250, 22, 1)\n",
        "    x = keras.layers.Reshape((250,22), input_shape=(250,22,1)) (x) # shape = (250,22)\n",
        "\n",
        "    # Patches\n",
        "\n",
        "    x = keras.layers.LayerNormalization()(x)\n",
        "    x = keras.layers.Dense(dim)(x)\n",
        "    residual2 = keras.layers.LayerNormalization()(x)\n",
        "\n",
        "    #residual2 = keras.layers.Embedding(dim, dim_heads)(x)\n",
        "\n",
        "    residual2 = PatchEncoder(250, 22) (residual2)\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for _ in range(transformer_layers):\n",
        "        # Layer normalization 1.\n",
        "        x1 = keras.layers.LayerNormalization(epsilon=1e-6)(residual2)\n",
        "        # Create a multi-head attention layer.\n",
        "        attention_output = keras.layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=dim_heads, dropout=0.1\n",
        "        )(x1, x1)\n",
        "        # Skip connection 1.\n",
        "        x2 = keras.layers.Add()([attention_output, residual2])\n",
        "        # Layer normalization 2.\n",
        "        x3 = keras.layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        # MLP.\n",
        "        #x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
        "        x3 = FeedForward(mlp_dim)(x3)\n",
        "        # Skip connection 2.\n",
        "        residual2 = keras.layers.Add()([x3, x2])\n",
        "\n",
        "    # Create a [batch_size, projection_dim] tensor.\n",
        "    representation = keras.layers.LayerNormalization(epsilon=1e-6)(residual2)\n",
        "    representation = keras.layers.Flatten()(representation)\n",
        "    representation = keras.layers.Dropout(0.5)(representation)\n",
        "    # Add MLP.\n",
        "    features = FeedForward(mlp_dim)(representation)\n",
        "    # Classify outputs.\n",
        "    logits = keras.layers.Dense(4)(features) # 4 is num_classes\n",
        "    # Create the Keras model.\n",
        "    model = keras.Model(inputs=inputs, outputs=logits)\n",
        "    return model\n",
        "\n",
        "vitmodel = create_vit_classifier()\n",
        "vitmodel.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxrdFeeWkrSU"
      },
      "source": [
        "#### Training & Validation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_valid, y_valid, x_test, y_test = preprocess()"
      ],
      "metadata": {
        "id": "8w-AhxYPW8or"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ddev67SSkrSU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dd9c0dd-32e4-4644-bd16-1d4c4909e286"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "106/106 [==============================] - 8s 44ms/step - loss: 3.2634 - accuracy: 0.2270 - val_loss: 1.5782 - val_accuracy: 0.2417\n",
            "Epoch 2/50\n",
            "106/106 [==============================] - 4s 39ms/step - loss: 1.7261 - accuracy: 0.2439 - val_loss: 1.4481 - val_accuracy: 0.2281\n",
            "Epoch 3/50\n",
            "106/106 [==============================] - 4s 41ms/step - loss: 1.5030 - accuracy: 0.2326 - val_loss: 1.4029 - val_accuracy: 0.2335\n",
            "Epoch 4/50\n",
            "106/106 [==============================] - 4s 39ms/step - loss: 1.4345 - accuracy: 0.2337 - val_loss: 1.3955 - val_accuracy: 0.2299\n",
            "Epoch 5/50\n",
            "106/106 [==============================] - 4s 39ms/step - loss: 1.4262 - accuracy: 0.2370 - val_loss: 1.3897 - val_accuracy: 0.2275\n",
            "Epoch 6/50\n",
            "106/106 [==============================] - 5s 43ms/step - loss: 1.4081 - accuracy: 0.2259 - val_loss: 1.3860 - val_accuracy: 0.2293\n",
            "Epoch 7/50\n",
            "106/106 [==============================] - 4s 39ms/step - loss: 1.3964 - accuracy: 0.2256 - val_loss: 1.3837 - val_accuracy: 0.2293\n",
            "Epoch 8/50\n",
            "106/106 [==============================] - 4s 39ms/step - loss: 1.3978 - accuracy: 0.2233 - val_loss: 1.3825 - val_accuracy: 0.2281\n",
            "Epoch 9/50\n",
            "106/106 [==============================] - 5s 43ms/step - loss: 1.3813 - accuracy: 0.2132 - val_loss: 1.3820 - val_accuracy: 0.2293\n",
            "Epoch 10/50\n",
            "106/106 [==============================] - 4s 40ms/step - loss: 1.3825 - accuracy: 0.2142 - val_loss: 1.3844 - val_accuracy: 0.2370\n",
            "Epoch 11/50\n",
            "106/106 [==============================] - 4s 39ms/step - loss: 1.3792 - accuracy: 0.2157 - val_loss: 1.3822 - val_accuracy: 0.2329\n",
            "Epoch 12/50\n",
            "106/106 [==============================] - 4s 40ms/step - loss: 1.3769 - accuracy: 0.2060 - val_loss: 1.3807 - val_accuracy: 0.2323\n",
            "Epoch 13/50\n",
            "106/106 [==============================] - 5s 42ms/step - loss: 1.3771 - accuracy: 0.2007 - val_loss: 1.3793 - val_accuracy: 0.2246\n",
            "Epoch 14/50\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 1.3754 - accuracy: 0.1978 - val_loss: 1.3780 - val_accuracy: 0.2228\n",
            "Epoch 15/50\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 1.3710 - accuracy: 0.2038 - val_loss: 1.3769 - val_accuracy: 0.2228\n",
            "Epoch 16/50\n",
            "106/106 [==============================] - 4s 40ms/step - loss: 1.3720 - accuracy: 0.1868 - val_loss: 1.3757 - val_accuracy: 0.2175\n",
            "Epoch 17/50\n",
            "106/106 [==============================] - 4s 39ms/step - loss: 1.3728 - accuracy: 0.1958 - val_loss: 1.3742 - val_accuracy: 0.2116\n",
            "Epoch 18/50\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 1.3677 - accuracy: 0.1983 - val_loss: 1.3728 - val_accuracy: 0.2051\n",
            "Epoch 19/50\n",
            "106/106 [==============================] - 4s 40ms/step - loss: 1.3675 - accuracy: 0.1859 - val_loss: 1.3713 - val_accuracy: 0.1986\n",
            "Epoch 20/50\n",
            "106/106 [==============================] - 4s 40ms/step - loss: 1.3655 - accuracy: 0.1953 - val_loss: 1.3698 - val_accuracy: 0.1968\n",
            "Epoch 21/50\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 1.3603 - accuracy: 0.1822 - val_loss: 1.3684 - val_accuracy: 0.1956\n",
            "Epoch 22/50\n",
            "106/106 [==============================] - 4s 41ms/step - loss: 1.3597 - accuracy: 0.1745 - val_loss: 1.3667 - val_accuracy: 0.1909\n",
            "Epoch 23/50\n",
            "106/106 [==============================] - 4s 39ms/step - loss: 1.3608 - accuracy: 0.1795 - val_loss: 1.3655 - val_accuracy: 0.1879\n",
            "Epoch 24/50\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 1.3532 - accuracy: 0.1727 - val_loss: 1.3618 - val_accuracy: 0.1832\n",
            "Epoch 25/50\n",
            "106/106 [==============================] - 4s 40ms/step - loss: 1.3536 - accuracy: 0.1773 - val_loss: 1.3588 - val_accuracy: 0.1755\n",
            "Epoch 26/50\n",
            "106/106 [==============================] - 4s 39ms/step - loss: 1.3502 - accuracy: 0.1693 - val_loss: 1.3567 - val_accuracy: 0.1726\n",
            "Epoch 27/50\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 1.3476 - accuracy: 0.1630 - val_loss: 1.3530 - val_accuracy: 0.1726\n",
            "Epoch 28/50\n",
            "106/106 [==============================] - 4s 40ms/step - loss: 1.3407 - accuracy: 0.1578 - val_loss: 1.3499 - val_accuracy: 0.1714\n",
            "Epoch 29/50\n",
            "106/106 [==============================] - 4s 39ms/step - loss: 1.3381 - accuracy: 0.1532 - val_loss: 1.3464 - val_accuracy: 0.1702\n",
            "Epoch 30/50\n",
            "106/106 [==============================] - 4s 39ms/step - loss: 1.3444 - accuracy: 0.1550 - val_loss: 1.3712 - val_accuracy: 0.1708\n",
            "Epoch 31/50\n",
            "106/106 [==============================] - 4s 41ms/step - loss: 1.3596 - accuracy: 0.1741 - val_loss: 1.3581 - val_accuracy: 0.1655\n",
            "Epoch 32/50\n",
            "106/106 [==============================] - 4s 39ms/step - loss: 1.3418 - accuracy: 0.1652 - val_loss: 1.3516 - val_accuracy: 0.1619\n",
            "Epoch 33/50\n",
            "106/106 [==============================] - 4s 39ms/step - loss: 1.3356 - accuracy: 0.1645 - val_loss: 1.3466 - val_accuracy: 0.1608\n",
            "Epoch 34/50\n",
            "106/106 [==============================] - 5s 43ms/step - loss: 1.3284 - accuracy: 0.1566 - val_loss: 1.3425 - val_accuracy: 0.1572\n",
            "Epoch 35/50\n",
            "106/106 [==============================] - 4s 39ms/step - loss: 1.3315 - accuracy: 0.1645 - val_loss: 1.3402 - val_accuracy: 0.1531\n",
            "Epoch 36/50\n",
            "106/106 [==============================] - 4s 39ms/step - loss: 1.3203 - accuracy: 0.1426 - val_loss: 1.3351 - val_accuracy: 0.1507\n",
            "Epoch 37/50\n",
            "106/106 [==============================] - 5s 43ms/step - loss: 1.3099 - accuracy: 0.1340 - val_loss: 1.3295 - val_accuracy: 0.1513\n",
            "Epoch 38/50\n",
            "106/106 [==============================] - 4s 39ms/step - loss: 1.3139 - accuracy: 0.1404 - val_loss: 1.3257 - val_accuracy: 0.1489\n",
            "Epoch 39/50\n",
            "106/106 [==============================] - 4s 39ms/step - loss: 1.3037 - accuracy: 0.1345 - val_loss: 1.3251 - val_accuracy: 0.1424\n",
            "Epoch 40/50\n",
            "106/106 [==============================] - 5s 43ms/step - loss: 1.2972 - accuracy: 0.1263 - val_loss: 1.3276 - val_accuracy: 0.1389\n",
            "Epoch 41/50\n",
            "106/106 [==============================] - 4s 40ms/step - loss: 1.2984 - accuracy: 0.1271 - val_loss: 1.3239 - val_accuracy: 0.1348\n",
            "Epoch 42/50\n",
            "106/106 [==============================] - 4s 39ms/step - loss: 1.2844 - accuracy: 0.1184 - val_loss: 1.3166 - val_accuracy: 0.1324\n",
            "Epoch 43/50\n",
            "106/106 [==============================] - 5s 43ms/step - loss: 1.2709 - accuracy: 0.1176 - val_loss: 1.3128 - val_accuracy: 0.1336\n",
            "Epoch 44/50\n",
            "106/106 [==============================] - 4s 39ms/step - loss: 1.2772 - accuracy: 0.1127 - val_loss: 1.3129 - val_accuracy: 0.1401\n",
            "Epoch 45/50\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 1.2555 - accuracy: 0.1056 - val_loss: 1.3134 - val_accuracy: 0.1424\n",
            "Epoch 46/50\n",
            "106/106 [==============================] - 4s 40ms/step - loss: 1.2634 - accuracy: 0.1098 - val_loss: 1.3148 - val_accuracy: 0.1395\n",
            "Epoch 47/50\n",
            "106/106 [==============================] - 4s 40ms/step - loss: 1.2558 - accuracy: 0.1030 - val_loss: 1.3568 - val_accuracy: 0.1383\n",
            "Epoch 48/50\n",
            "106/106 [==============================] - 4s 39ms/step - loss: 1.2503 - accuracy: 0.1039 - val_loss: 1.3438 - val_accuracy: 0.1318\n",
            "Epoch 49/50\n",
            "106/106 [==============================] - 4s 42ms/step - loss: 1.2599 - accuracy: 0.1037 - val_loss: 1.3604 - val_accuracy: 0.1353\n",
            "Epoch 50/50\n",
            "106/106 [==============================] - 4s 40ms/step - loss: 1.2403 - accuracy: 0.0943 - val_loss: 1.3456 - val_accuracy: 0.1235\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 1e-5\n",
        "epochs = 50\n",
        "batch_size = 64\n",
        "\n",
        "vitmodel = create_vit_classifier(batch_size)\n",
        "\n",
        "cnn_optimizer = keras.optimizers.Adam(lr=learning_rate)\n",
        "\n",
        "# Compiling the model\n",
        "vitmodel.compile(loss='categorical_crossentropy',\n",
        "                 optimizer=cnn_optimizer,\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "# Training and validating the model\n",
        "vitmodel_results = vitmodel.fit(x_train,\n",
        "             y_train,\n",
        "             batch_size=batch_size,\n",
        "             epochs=epochs,\n",
        "             validation_data=(x_valid, y_valid), verbose=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(vitmodel_results.history['accuracy'])\n",
        "plt.plot(vitmodel_results.history['val_accuracy'])\n",
        "plt.title('Transformer Model Accuracy for All Subjects')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(vitmodel_results.history['loss'])\n",
        "plt.plot(vitmodel_results.history['val_loss'])\n",
        "plt.title('Transformer Model Loss for All Subjects')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "TwCdavv3JRdT",
        "outputId": "19912666-a37b-4c59-e53b-c43685435726"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'Transformer'\n",
        "model_score = vitmodel.evaluate(x_test, y_test, verbose=True)\n",
        "print(f'Test accuracy of the {model_name} model:',model_score[1])"
      ],
      "metadata": {
        "id": "TdSZWg1Xk0RX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b20c681f-2c52-40ef-9d61-06ea69d71d22"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56/56 [==============================] - 1s 10ms/step - loss: 1.2633 - accuracy: 0.1202\n",
            "Test accuracy of the Transformer model: 0.1202031597495079\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ee147",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}